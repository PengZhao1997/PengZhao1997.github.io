<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>未知2018 | 北理、旷视、北大联合提出PAN，用于语义分割</title>
      <link href="/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/%E6%9C%AA%E7%9F%A52018-%E5%8C%97%E7%90%86%E3%80%81%E6%97%B7%E8%A7%86%E3%80%81%E5%8C%97%E5%A4%A7%E8%81%94%E5%90%88%E6%8F%90%E5%87%BAPAN%EF%BC%8C%E7%94%A8%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
      <url>/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/%E6%9C%AA%E7%9F%A52018-%E5%8C%97%E7%90%86%E3%80%81%E6%97%B7%E8%A7%86%E3%80%81%E5%8C%97%E5%A4%A7%E8%81%94%E5%90%88%E6%8F%90%E5%87%BAPAN%EF%BC%8C%E7%94%A8%E4%BA%8E%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/PAN/1.png" alt=""><br><strong>Pyramid Attention Network for Semantic Segmentation</strong><br><strong>KeyWords Plus</strong>: 未知2018 金字塔注意力网络<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1805.10180.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1805.10180.pdf</a><br><strong>reference</strong>: Li, Hanchao, et al. “Pyramid attention network for semantic segmentation.” arXiv preprint arXiv:1805.10180 (2018).<br><strong>Github</strong>: <a href="https://github.com/JaveyWang/Pyramid-Attention-Networks-pytorch" target="_blank" rel="noopener">https://github.com/JaveyWang/Pyramid-Attention-Networks-pytorch</a></p><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>　　随着卷积神经网络 (CNN) 的发展，层次特征的丰富性及端到端的训练框架可用性，逐像素（pixel-wise）的语义分割问题的研究取得了显著的进步。但是，现有的研究对于高维度特征表征的编码效果仍不理想，导致原始场景中上下文像素的空间分辨率遭受损失。<br><img src="/images/PAN/2.png" alt=""></p><center><font color="#0099ff" face="黑体">图1：VOC 数据集的可视化结果</font></center><p>　　在图1中，正如我们所看到的，FCN 模型难以对小目标和细节进行预测。在第一排中自行车的手柄在预测中丢失了，而第二排中出现了错误的动物类别预测。我们的特征金字塔注意力模块 (FPA) 和全局注意力上采样 (GAU) 模块旨在扩大目标感受野并有效地恢复像素的定位细节。<br>　　如图１所示，全卷积神经网络 (Full Convolutional Network，FCN) 缺乏对场景中小部件的预测能力，图中第一排自行车的手柄消失了，而第二排中的羊被误认为牛。这对语义分割任务提出了挑战。<br>　　首先是多尺度目标的存在会加大语义分割任务中类别分类的困难。为了解决这个问题，PSPNet 或 DeepLab 系统提出空间金字塔结构，旨在不同的网格尺度或扩张率下 (称之为空间金字塔池化，ASPP)，融合多尺度的特征信息。在 ASPP 模块中，扩张卷积是一种稀疏计算，这可能会导致产生网格伪像 (grid artifacts)。而 PSPNet 中提出的金字塔池化模块则可能会丢失像素级别的定位信息。受 SENet 和 Parsenet 的启发，本文尝试从 CNN 的高层次特征中提取出准确的像素级注意力特征。图2展示了本文提出的特征金字塔注意力模块 (Feature Pyramid Attention，FPA)的能力，它能够扩大感受野的范围并有效地实现小目标的分类。<br>　　另一个问题是，高层次的特征在对类别进行准确分类时非常有效，但在重组原始分辨率的二类预测问题方面比较薄弱。一些 U 型网络，如 SegNet，Refinenet 以及 Large Kernel Matters 能够在复杂的解码器模块中使用低层次信息来帮助高层次特征恢复图像细节。但是，这些方法都很耗时，运行效率不高。为解决这个问题，本文提出了一种称为 Global Attention Upsample (GAU) 方法，这是一个有效的解码器模块，在不需要耗费过多计算资源的情况下，它可以提取高层次特征的全局上下文信息，作为低阶特征的加权计算的指导。<br>　　总的来说，本文主要有以下三个贡献：</p><ol><li>提出了一个特征金字塔注意力模块 FPA，可以在基于 FCN 的像素预测框架中嵌入不同尺度的上下文特征信息。</li><li>开发了一个高效的解码器模块 Global Attention Upsample（GAU），用于处理图像的语义分割问题。</li><li>结合特征金字塔注意力模块和全局注意力上采样模块，本文提出的金字塔注意力网络在 VOC2012 和 cityscapes 的测试基准中取得了当前最佳的性能。</li></ol><h3 id="模型方法"><a href="#模型方法" class="headerlink" title="模型方法"></a>模型方法</h3><h4 id="特征金字塔注意力模块FPA"><a href="#特征金字塔注意力模块FPA" class="headerlink" title="特征金字塔注意力模块FPA"></a>特征金字塔注意力模块FPA</h4><p>　　基于以上观察，本文提出了特征金字塔注意力模块 (FPA)，该模块能够融合来自 U 型网络 (如特征金字塔网络 FPN) 所提取的三种不同尺度的金字塔特征。为了更好地提取不同尺度下金字塔特征的上下文信息，分别在金字塔结构中使用 3×3, 5×5, 7×7 的卷积核。由于高层次特征图的分辨率较小，因此使用较大的内核并不会带来太多的计算负担。随后，金字塔结构逐步集成不同尺度下的特征信息，这样可以更准确地结合相邻尺度的上下文特征。然后，经过 1×1 卷积处理后，由 CNN 所提取的原始特征通过金字塔注意力特征进行逐像素相乘。此外，还引入了全局池化分支来联结输出的特征，这将进一步提高 FPA 模块的性能。整体的模块结构如下图所示。得益于空间金字塔结构，FPA 模块可以融合不同尺度的上下文信息，同时还能为高层次的特征图提供更好的像素级注意力。<br><img src="/images/PAN/3.png" alt=""></p><center><font color="#0099ff" face="黑体">图2：特征金字塔注意力模块结构</font></center><p>　　在图2中，(a) 空间金字塔池结构。(b) 特征金字塔注意力模块。 ‘4×4，8×8，16×16，32×32’ 分别代表特征映射的不同分辨率。虚线框表示全局池化分支。蓝色和红色的线条分别代表下采样和上采样运算符。</p><h4 id="全局注意力上采样模块GAU"><a href="#全局注意力上采样模块GAU" class="headerlink" title="全局注意力上采样模块GAU"></a>全局注意力上采样模块GAU</h4><p>　　本文提出的全局注意力上采样模块 (Global Attention Upsample，GAU)，通过全局池化过程将全局上下文信息作为低层特征的指导，来选择类别的定位细节。具体地说，本文对低层次特征执行 3×3 的卷积操作，以减少 CNN 特征图的通道数。从高层次特征生成的全局上下文信息依次经过 1×1 卷积、批量归一化 (batch normalization) 和非线性变换操作 (nonlinearity)，然后再与低层次特征相乘。最后，高层次特征与加权后的低层次特征相加并进行逐步的上采样过程。本文的 GAU 模块不仅能够更有效地适应不同尺度下的特征映射，还能以简单的方式为低层次的特征映射提供指导信息。模块的结构示意图如图3所示。<br><img src="/images/PAN/4.png" alt=""></p><center><font color="#0099ff" face="黑体">图3：全局注意力上采样模块</font></center><h4 id="金字塔注意力网络PAN"><a href="#金字塔注意力网络PAN" class="headerlink" title="金字塔注意力网络PAN"></a>金字塔注意力网络PAN</h4><p>　　结合特征金字塔注意力模块 (FPA) 和全局注意力上采样模块 (GAU)，本文提出金字塔注意力网络 (PAN)，其结构示意图如下图所示。本文使用在 ImageNet 数据集上预训练好的 ResNet-101 模型，辅以扩张（空洞）卷积策略来提取特征图。具体地说，本文在 res5b 模块上应用扩张率为 2 的扩张卷积，以便 ResNet 输出的特征图大小为原输入图像的1/16，这与 DeepLabv3+ 模型中的设置是一致的。正如 PSPNet 和 DUC 模型那样，本文用三个 3×3 卷积层来取代原 ResNet-101 模型中的 7×7 卷积。此外，本文使用 FPA 模块来收集 ResNet 的输出中密集的像素级注意力信息。结合全局的上下文信息，经 GAU 模块后，生成最终的预测图。<br><img src="/images/PAN/5.png" alt=""></p><center><font color="#0099ff" face="黑体">图4：金字塔注意力网络结构</font></center><p>　　在图4中，本文使用 ResNet-101 模型来提取密集的特征。然后，分别执行 FPA 模块和 GAU 模块进行准确的像素预测并获取目标定位的细节。蓝线和红线分别代表下采样和上采样运算符。<br>　　本文将 FPA 模块视为编码器和解码器结构之间的中心模块。即使没有全局注意上采样模块，FPA 模块也能够进行足够准确的像素级预测和类别分类。在实现 FPA 模块后，将 GAU 模块视为一种快速有效的解码器结构，它使用高层次的特征来指导低层次的信息，并将二者结合起来。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>　　在 PASCAL VOC2012 和 cityscapes 数据集上分别评估了本文提出的方法。</p><h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><h5 id="FPA-模块"><a href="#FPA-模块" class="headerlink" title="FPA 模块"></a>FPA 模块</h5><p>　　表1中，实验分别对池化类型、金字塔结构、卷积核大小、全局池化四种设置进行了 Ablation Experiments 分析，结果如下：其中 AVE 表示平均池化策略，MAX 表示最大池化，C333 代表全部使用 3×3 的卷积核，C357 表示所使用的卷积核分别为 3×3、5×5 和 7×7，GP 代表全局池化分支，SE 表示使用 SENet 注意力模块。</p><ul><li><strong>池化类型：</strong>在这项工作中，作者发现 AVE 的性能要优于 MAX：对于 3×3 的卷积核设置，AVE 的性能能达到 77.54%，优于 MAX 所取得的77.13%。</li><li><strong>金字塔结构：</strong>作者提出的模型在验证集上能取得 72.60％ 的 mIoU。此外，使用 C333 和 AVE 时，模型的性能能够从 72.6％ 提升至 77.54％。还使用 SENet 注意力模块来取代金字塔结构，进一步对比评估二者的性能。实验结果如下表1所示，与 SENet 注意力模块相比，C333 和 AVE 设置能将性能提高了近1.8％。</li><li><strong>卷积核大小：</strong>对于使用平均池化的金字塔结构，本文使用 C357 取代 C333 卷积核设置，金字塔结构中特征映射的分辨率为 16×16，8×8，4×4。实验结果表明，模型性能能够从 77.54％ 提高至 78.19％。</li><li><strong>全局池化：</strong>本文进一步在金字塔结构中添加全局池化分支以提高模型性能。实验结果表明，在最佳设置下模型能够取得 78.37 的 mIoU 和 95.03% 的 Pixel Acc。</li></ul><p><img src="/images/PAN/6.png" alt=""></p><center><font color="#0099ff" face="黑体">表1：不同设置下 FPA 模块的性能</font></center><h5 id="GAU-模块"><a href="#GAU-模块" class="headerlink" title="GAU 模块"></a>GAU 模块</h5><p>　　首先，评估 ResNet101+GAU 模型，然后将 FPA 和 GAU 模块结合并在 VOC 2012 验证集中评估我们的模型。作者分别在三种不同的解码器设置下评估模型：(1) 仅使用跳跃连接的低级特征而没有全局上下文注意力分支。(2) 使用 1×1 卷积来减少 GAU 模块中的低层次特征的通道数。(3) 用 3×3 卷积代替 1×1 卷积减少通道数。实验结果如表2所示。<br><img src="/images/PAN/7.png" alt=""></p><center><font color="#0099ff" face="黑体">表2：不同解码器设置下的模型性能</font></center><p>　　此外，作者还比较了ResNet101+GAU 模型、Global Convolution Network 和 Discriminate Feature Network，实验结果如表3所示。<br><img src="/images/PAN/8.png" alt=""></p><center><font color="#0099ff" face="黑体">表3：作者提出的模型与其他模型的比较结果</font></center><h4 id="PASVAL-VOC-2012-数据集"><a href="#PASVAL-VOC-2012-数据集" class="headerlink" title="PASVAL VOC 2012 数据集"></a>PASVAL VOC 2012 数据集</h4><p>　　结合 FPA 模块和 GAU 模块的最佳设置，本文在 PASVAL VOC 2012 数据集上评估了作者提出的金字塔注意力网络 (PAN)。实验结果如表4和表5所示。可以看到，PAN 取得了84.0% mIoU，超过现有的所有方法。<br><img src="/images/PAN/9.png" alt=""></p><center><font color="#0099ff" face="黑体">表4：在 VOC 2012 数据集上模型的性能</font></center><p><img src="/images/PAN/10.png" alt=""></p><center><font color="#0099ff" face="黑体">表5：在 PASVAL VOC 2012 测试集上单类别的实验结果</font></center><h4 id="Cityscapes-数据集"><a href="#Cityscapes-数据集" class="headerlink" title="Cityscapes 数据集"></a>Cityscapes 数据集</h4><p>　　Cityscapes 数据集包含 30 个类别，其中 19 个用于我们的模型训练和评估。整个数据集 5000 个带细粒度标注的图像和 19998 个带粗粒度标注的图像。具体地说，作者将细粒度图像分为训练集、验证集和测试集，分别有 2979、500 和 1525 张图像。在训练期间，作者没有使用带粗粒度标注的数据集，所使用的图像尺寸为 768×768。同样地，作者以 ResNet101 作为基础模型，实验结果如表6列出。<br><img src="/images/PAN/11.png" alt=""></p><center><font color="#0099ff" face="黑体">表6：Cityscapes 测试集上模型的性能</font></center><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>　　在本文中，作者提出了一种金字塔注意力网络，用于处理图像语义分割问题。作者设计了特征金字塔注意力模块 (FPA) 和全局注意力上采样模块 (GAU)。FPA 模块能够提供像素级注意力信息并通过金字塔结构来扩大感受野的范围。GAU 模块能够利用高层次特征图来指导低层次特征恢复图像像素的定位。实验结果表明，作者所提出的方法在 PASCAL VOC 2012 语义分割任务实现了当前最佳的性能。</p>]]></content>
      
      <categories>
          
          <category> 语义分割 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 旷视 </tag>
            
            <tag> PAN </tag>
            
            <tag> 语义分割 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>WACV2018 | 微软亚研院提出带PAN的基于Mask R-CNN的场景文本检测方法</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/WACV2018-%E5%BE%AE%E8%BD%AF%E4%BA%9A%E7%A0%94%E9%99%A2%E6%8F%90%E5%87%BA%E5%B8%A6PAN%E7%9A%84%E5%9F%BA%E4%BA%8EMask-R-CNN%E7%9A%84%E5%9C%BA%E6%99%AF%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/WACV2018-%E5%BE%AE%E8%BD%AF%E4%BA%9A%E7%A0%94%E9%99%A2%E6%8F%90%E5%87%BA%E5%B8%A6PAN%E7%9A%84%E5%9F%BA%E4%BA%8EMask-R-CNN%E7%9A%84%E5%9C%BA%E6%99%AF%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/Mask_PAN/1.png" alt=""><br><strong>Mask R-CNN with Pyramid Attention Network for Scene Text Detection</strong><br><strong>KeyWords Plus</strong>: WACV2018 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1811.09058.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1811.09058.pdf</a><br><strong>reference</strong>: Huang Z , Zhong Z , Sun L , et al. Mask R-CNN with Pyramid Attention Network for Scene Text Detection[J]. 2018.<br><strong>Github</strong>: 未开源</p><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><p>　　本文提出了一种新的基于Mask R-CNN的文本检测方法，该方法能够以统一的方式鲁棒地检测来自自然场景图像的多方向和弯曲文本。为了增强Mask R-CNN用于文本检测任务的特征表示能力，使用金字塔注意力网络（PAN）作为Mask R-CNN的新主干网络。</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>　　基于Mask R-CNN的文本检测网络由四个模块组成：</p><ol><li>PAN特征金字塔主干网络，负责在整个图像上计算多尺度卷积特征金字塔；</li><li>产生矩形文本proposal的区域提议网络（RPN）；</li><li>Fast R-CNN检测器，对提取的proposal进行分类并输出相应的四边形边界框；</li><li>Mask预测网络，用于预测输入proposal的文本掩模。</li></ol><p><img src="/images/Mask_PAN/2.png" alt=""></p><h3 id="PAN金字塔注意力网络"><a href="#PAN金字塔注意力网络" class="headerlink" title="PAN金字塔注意力网络"></a>PAN金字塔注意力网络</h3><p>　　金字塔注意力网络（PAN）主要由两个模块组成，即Feature Pyramid Attention（FPA）模块和Global Attention Up-sample（GAU）模块。FPA模块对高级特征执行空间金字塔注意力，并结合全局池化以学习更好的高级特征表示。GAU模块附加在每个解码器层上，以提供全局上下文作为低级特征的指导，来选择类别局部细节。</p><h4 id="FPA结构"><a href="#FPA结构" class="headerlink" title="FPA结构"></a>FPA结构</h4><p><img src="/images/Mask_PAN/3.png" alt=""></p><ol><li>在ResNet50或ResNeXt50之上构建PAN；</li><li>将ResNet50或ResNeXt50中Res-4层的输出特征图作为输入，在其上分别以3,6,12的采样率执行3×3扩张（空洞）卷积，以更好地提取上下文信息。将这三个特征图连接起来，并通过1×1卷积层降维处理。</li><li>FPA在输入Res-4上进一步形成1×1卷积，其输出与上述上下文特征图对应位置相乘。</li><li>提取的特征与全局池化分支的输出特征加在一起，以获得最终的金字塔注意特征。</li></ol><h4 id="GAU结构"><a href="#GAU结构" class="headerlink" title="GAU结构"></a>GAU结构</h4><p><img src="/images/Mask_PAN/4.png" alt=""></p><ol><li>对低级特征执行3×3卷积，以减少来自CNN的特征图的通道。</li><li>对高级特征进行全局池化后，通过1×1卷积与实例归一化和ReLU非线性，然后乘以低级特征。</li><li>通过上采样的高级特征与加权的低级特征相加，以生成GAU特征。</li></ol><p>　　通过上述FPA和GAU模块，构建了一个具有三个级别的强大特征金字塔，即P2、P3和P4，其大小分别为原图的1/4、1/8和1/16。整体PAN架构为：<br><img src="/images/Mask_PAN/5.png" alt=""></p><h3 id="RPN区域提议网络"><a href="#RPN区域提议网络" class="headerlink" title="RPN区域提议网络"></a>RPN区域提议网络</h3><p><img src="/images/Mask_PAN/6.png" alt=""></p><ul><li>三个RPN分别连接到P2、P3和P4，每个RPN在相应的金字塔等级上密集地滑动一个小网络，以执行文本/非文本分类和边界框回归。</li><li>小网络实现为3×3卷积层，后面是两个1×1卷积层，分别用于预测文本分数和矩形边界框位置。</li><li>具体来说：<ul><li>通过使用6个纵横比{0.2, 0.5, 1.0, 2.0, 4.0, 8.0}和一个尺度{32,64,128}，在{P2，P3，P4}的每个金字塔级别上的每个滑动位置设计6个anchor。将所有三个RPN的检测结果聚合在一起以构建proposal集{D}。</li><li>然后，使用标准的非极大抑制（NMS）算法，其IoU阈值为0.7，以删除{D}中的冗余提议。</li><li>最后，为Faster R-CNN和Mask预测网络选择评分 Top-N 的 propoasl。在训练和测试阶段 N 均设为2000。</li></ul></li></ul><h3 id="Fast-R-CNN-amp-Mask预测网络"><a href="#Fast-R-CNN-amp-Mask预测网络" class="headerlink" title="Fast R-CNN &amp; Mask预测网络"></a>Fast R-CNN &amp; Mask预测网络</h3><p><img src="/images/Mask_PAN/7.png" alt=""><br>　　为实现这一目标，提出了一种<strong>Skip-RoIAlign</strong>方法来融合P2、P3和P4级别的特征。<br>　　具体来说：</p><ul><li>首先，对于每个propoasl，分别在P2、P3和P4金字塔等级上应用ROIAlign，得到三个固定大小为7×7的特征图；</li><li>然后，连接这些特征图，并且用1×1卷积层进行降维处理，以获得最终的ROI特征；</li><li>最后，将这些ROI特征送到Fast RCNN和Mask预测网络中进行预测。<ul><li>对于Fast RCNN，将ROI特征进行全局平均池化后，进行文本/非文本分类、四边形边界框回归。</li><li>对于Mask预测网络，在ROI特征后进行四个连续的3×3卷积层，之后上采样到14×14大小的特征图，进行Mask预测。</li></ul></li></ul><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><h4 id="RPN的的多任务损失函数"><a href="#RPN的的多任务损失函数" class="headerlink" title="RPN的的多任务损失函数"></a>RPN的的多任务损失函数</h4><p>　　每个单独的RPN有两个兄弟输出层，即文本/非文本分类层和矩形边界框回归层。多任务损失函数可表示如下：<br><img src="/images/Mask_PAN/8.png" alt=""></p><ul><li>文本/非文本分类loss为一个softmax loss；</li><li>矩形边界框回归loss为一个smooth-L1 loss；</li><li>Lambda_loc为平衡参数，设置为3；</li><li>RPN网络的总损失LRPN为三个单独的RPN网络的总和。</li></ul><h4 id="Fast-R-CNN的多任务损失函数"><a href="#Fast-R-CNN的多任务损失函数" class="headerlink" title="Fast R-CNN的多任务损失函数"></a>Fast R-CNN的多任务损失函数</h4><p>　　有两个输出层，即文本和非文本分类层和四边形边界框回归层。<br><img src="/images/Mask_PAN/9.png" alt=""></p><ul><li>文本/非文本分类loss为一个softmax loss；</li><li>矩形边界框回归loss为一个smooth-L1 loss；</li><li>Lambda_loc为平衡参数，设置为1。</li></ul><h4 id="Mask预测网络的损失函数"><a href="#Mask预测网络的损失函数" class="headerlink" title="Mask预测网络的损失函数"></a>Mask预测网络的损失函数</h4><p>　　采用标准的二值交叉熵损失:<br><img src="/images/Mask_PAN/10.png" alt=""></p><h4 id="全局损失函数"><a href="#全局损失函数" class="headerlink" title="全局损失函数"></a>全局损失函数</h4><p><img src="/images/Mask_PAN/11.png" alt=""></p><ul><li>Lambda_mask为Mask分支的平衡参数，设置为0.03125。</li></ul><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><ul><li>ICDAR-2017 MLT 用于多方向文本检测；</li><li>ICDAR-2015 用于多方向文本检测；</li><li>SCUT-CTW 1500 用于曲线文本检测。</li></ul><h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><ul><li>对于ICDAR-2017 MLT和ICDAR-2015数据集，直接使用Fast R-CNN模块预测的四边形边界框作为最终检测结果，</li><li>对于弯曲文本检测数据集SCUT-CTW 1500，使用由Mask预测网络预测的文本Mask为最终检测结果。</li></ul><h4 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h4><ul><li>ResNeXt50比ResNet50的效果更好；</li><li>PAN比FPN的效果更好。</li></ul><p><img src="/images/Mask_PAN/12.png" alt=""></p><h4 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h4><p><img src="/images/Mask_PAN/13.png" alt=""><br><img src="/images/Mask_PAN/14.png" alt=""></p><h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="/images/Mask_PAN/15.png" alt=""><br><img src="/images/Mask_PAN/16.png" alt=""><br><img src="/images/Mask_PAN/17.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> 曲线文本 </tag>
            
            <tag> Mask R-CNN </tag>
            
            <tag> PAN </tag>
            
            <tag> WACV2018 </tag>
            
            <tag> 微软亚研院 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>曲文检测论文汇总（2018.12.26）</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/%E6%9B%B2%E6%96%87%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB%EF%BC%882018-12-26%EF%BC%89/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/%E6%9B%B2%E6%96%87%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E6%B1%87%E6%80%BB%EF%BC%882018-12-26%EF%BC%89/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="方法和思路总结"><a href="#方法和思路总结" class="headerlink" title="方法和思路总结"></a>方法和思路总结</h3><ol><li>从趋势和效果来看，基本确定：用instance-segmentation思路来做</li><li>目前已用的框架来看<ul><li>检测：Faster RCNN、R-FCN</li><li>分割：Mask R-CNN、FPN、FCIS</li></ul></li><li>目前在这个方面，探讨的比较多的两个instance-segmentation用在文字上的问题<ul><li>多边形表示mask</li><li>多scale（FPN，低高层特征进行fusion）</li><li>黏连</li></ul></li><li>可以参考的几个点<ul><li>对gt做shrink</li><li>attention</li><li>PAN</li><li>FCIS的PSROI也不错</li></ul></li><li>用于做实验对比的数据集<ul><li>CTW1500</li><li>Total-Text</li><li>ICDAR15</li><li>ICDAR17-MLT</li><li>MSRA-TD500</li></ul></li></ol><h3 id="论文列表"><a href="#论文列表" class="headerlink" title="论文列表"></a>论文列表</h3><ol><li>Yuliang Liu_2017_Detecting Curve Text in the Wild_New Dataset and New Solution<ul><li>方法名称：CTD+TLOC</li></ul></li><li>Shangbang Long_ECCV2018_TextSnake_A Flexible Representation for Detecting Text of Arbitrary Shapes<ul><li>方法名称：TextSnake</li></ul></li><li>Yuchen Dai——【2017】Fused Text Segmentation Networks for Multi-Oriented Scene Text Detection<ul><li>方法名称：FTSN</li></ul></li><li>Jun Du——【ICPR2018】Sliding Line Point Regression for Shape Robust Scene Text Detection<ul><li>方法名称：SLPR</li></ul></li><li>XiangLi——【2018】Shape Robust Text Detection with Progressive Scale Expansion Network<ul><li>方法名称：PSENet</li></ul></li><li>Zhida Huang——【2018】Mask R-CNN with Pyramid Attention Network for Scene Text Detection<ul><li>方法名称：Mask-PAN</li></ul></li><li>Yongchao Xu——【2018】TextField_Learning A Deep Direction Field for Irregular Scene Text Detection<ul><li>方法名称：TextField</li></ul></li><li>Enze Xie——【AAAI2019】Scene Text Detection with Supervised Pyramid Context Network<ul><li>方法名称：SPCNET</li></ul></li><li>Jiaming Liu——【2019】Detecting Text in the Wild with Deep Character Embedding Network<ul><li>方法名称：CENet</li></ul></li><li>Chuhui Xue——【arxiv2019】MSR_Multi-Scale Shape Regression for Scene Text Detection<ul><li>方法名称：MSR</li></ul></li></ol><h3 id="方法详细描述"><a href="#方法详细描述" class="headerlink" title="方法详细描述"></a>方法详细描述</h3><h4 id="CTD-TLOC"><a href="#CTD-TLOC" class="headerlink" title="CTD+TLOC"></a>CTD+TLOC</h4><p><strong>论文</strong>：Yuliang Liu_2017_Detecting Curve Text in the Wild_New Dataset and New Solution<br><strong>亮点</strong>：</p><ul><li>第一篇做曲文检测，还提出一个数据集CTW1500</li><li>使用14个点的多边形来表示曲文</li><li>提出了一个结合CNN-RPN+RNN的检测方法专门做曲文检测<br><img src="/images/文本检测1_1.png" alt=""></li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，基于RPN进行修改，除了学习text/non-text分类，多边形的bounding box回归（x1,y1,x2,y2），增加了14个点的回归，最后再进行后处理（去噪+nms），得到最终输出。<br><img src="/images/文本检测1_2.png" alt=""></p><h4 id="TextSnake"><a href="#TextSnake" class="headerlink" title="TextSnake"></a>TextSnake</h4><p><strong>论文</strong>：Shangbang Long_ECCV2018_TextSnake_A Flexible Representation for Detecting Text of Arbitrary Shapes<br><strong>亮点</strong>：</p><ul><li>提出一个新的曲线文本表示方法TextSnake（由圆盘序列组成）</li><li>提出了一个新的曲文检测方法，并且精度比之前的高40%+（Total-Text数据集）<br><img src="/images/文本检测2_1.png" alt=""><br>Fig. 2. Illustration of the proposed TextSnake representation. Text region (in yellow) is represented as a series of ordered disks (in blue), each of which is located at the center line (in green, a.k.a symmetric axis or skeleton) and associated with a radius r and an orientation θ. In contrast to conventional representations (e.g., axis-aligned rectangles, rotated rectangles and quadrangles), TextSnake is more flexible and general, since it can precisely describe text of different forms, regardless of shapes and lengths.</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，提出一个新的曲线文本表示方法TextSnake：用一个有序的圆盘序列来表示文字，先用FCN检测文本区域、文本中心线、以及每个点的圆盘半径、方向，然后利用文本区域mask和中心线mask得到text instance segmentation。在每个text-instance上，交替进行点中心化和点扩展，得到文本中心点序列。最后结合圆盘半径，得到文本区域的TextSnake表示并进行union得到最终的文本区域。<br><img src="/images/文本检测2_2.png" alt=""></p><h4 id="FTSN"><a href="#FTSN" class="headerlink" title="FTSN"></a>FTSN</h4><p><strong>论文</strong>：Yuchen Dai——【2017】Fused Text Segmentation Networks for Multi-Oriented Scene Text Detection<br><strong>亮点</strong>：</p><ul><li>比较早的一篇用FCIS做曲文检测的方法</li><li>提出Mask NMS</li></ul><p><strong>方法概述</strong></p><ul><li>针对曲文检测，采用instance-segmentation思路，基于FCIS框架，基本没特别改动，增加了一个Mask NMS。</li><li>检测流程是：使用FCIS得到instance-segmentation mask，然后再用Mask NMS，最后利用Mask得到多边形。<br><img src="/images/文本检测3_1.png" alt=""><br>Fig. 2. The proposed framework consists of three parts: feature extraction, feature fusion along with region proposing and text instance prediction. The dashed line represents a convolution with 1x1 kernel size and 1024 output channels. The line in red is for upsampling operation and blue lines indicate on which feature maps PSROIPooling are performed using given ROIs.</li></ul><p>　　Mask NMS实际上就是把IOU-overlap换成两个Mask的Intersection的像素点总数，分母的union area换成两个polygon的max_area。mask maximum-intersection (MMI):<br><img src="/images/文本检测3_2.png" alt=""></p><h4 id="SLPR"><a href="#SLPR" class="headerlink" title="SLPR"></a>SLPR</h4><p><strong>论文</strong>：Jun Du——【ICPR2018】Sliding Line Point Regression for Shape Robust Scene Text Detection<br><strong>亮点</strong>：</p><ul><li>基于检测框架进行修改，只需增加回归点的纵坐标或横坐标，是对CTD+TLOC的简化和改进。</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，采用object-detection思路，基于Faster R-CNN/R-FCN框架，增加了沿x/y轴均匀划线与多边形交点的纵/横坐标的回归（14个点，仅回归x或y坐标），最后把点串起来得到多边形。<br><img src="/images/文本检测4_1.png" alt=""></p><h4 id="PSENet"><a href="#PSENet" class="headerlink" title="PSENet"></a>PSENet</h4><p><strong>论文</strong>：XiangLi——【2018】Shape Robust Text Detection with Progressive Scale Expansion Network<br><strong>亮点</strong>：</p><ul><li>利用不同shrink的segmentation来解决text-instance的黏连问题，很有新意；</li><li>提出一个自己设计的多个score map逐步扩展算法</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，采用instance-segmentation思路，基于FPN框架进行修改，将其用在曲线文本检测上。<br>　　文章提出了曲文检测的当前两大问题：</p><ol><li>目前已有的文本表示方法（正矩形，斜矩形，四边形）无法满足任意形状的文本检测；<ul><li>解决思路：用分割来做。</li></ul></li><li>已有的分割方法的最大问题在于紧邻的text instance容易黏连。<ul><li>解决思路：对文本区域（gt-dt）进行不同程度的shrink，然后逐步扩展。<br><img src="/images/文本检测5_1.png" alt=""><br>Figure 1: The results of different methods, best viewed in color. (a) is the original image. (b) refers to the result of bounding box regression-based method, which displays disappointing detections as the red box covers nearly more than half of the context in the green box. (c) is the result of semantic segmentation, which mistakes the 3 text instances for 1 instance since their boundary pixels are partially connected. (d) is the result of our proposed PSENet, which successfully distinguishs and detects the 4 unique text instances.</li></ul></li></ol><p>　　整个检测方法的流程是：使用FPN网络得到多个shrink程度不一样的segmentation map，再把多个map进行逐步扩展得到最终的map。<br><img src="/images/文本检测5_2.png" alt=""><br>Figure 2: Illustration of our overall pipeline. The left part is implemented from FPN [16]. The right part denotes the feature fusion and the progressive scale expansion algorithm</p><h4 id="Mask-PAN"><a href="#Mask-PAN" class="headerlink" title="Mask-PAN"></a>Mask-PAN</h4><p><strong>论文</strong>：Zhida Huang——【2018】Mask R-CNN with Pyramid Attention Network for Scene Text Detection<br><strong>亮点</strong>：</p><ul><li>基于Mask RCNN进行修改，可做四边形回归</li><li>首次将PAN用在文本检测上</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，采用Instance-segmentation思路，基于Mask-RCNN进行修改，将其用在曲线文本检测上。<br>　　改进的点在于三个：</p><ol><li>在backbone网络中加入PAN（Pyramid Attention Network，由Feature Pyramid Attention和Global Attention Up-Sample两个部分组成），使得特征对scale大小鲁棒性更强；</li><li>将Mask-RCNN的regression分支由box回归（4个值）改为polygon回归（8个值），使其可以用做四边形回归（但还是不能用来做曲文的回归，曲文用的是mask的多边形框；</li><li>参照ION的思想，提出Skip-RoiAlign在多层进行融合<br><img src="/images/文本检测6_1.png" alt=""><br>Figure 1: Architecture of our Mask R-CNN based text detector, which consists of a PAN backbone network, a region proposal network, a Fast R-CNN detector and a mask prediction network.</li></ol><h4 id="TextField"><a href="#TextField" class="headerlink" title="TextField"></a>TextField</h4><p><strong>论文</strong>：Yongchao Xu——【2018】TextField_Learning A Deep Direction Field for Irregular Scene Text Detection<br><strong>亮点</strong>：</p><ul><li>提出的TextField方法非常新颖，用点到最近boundary点的向量来区分不同instance</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，采用Instance-segmentation思路，提出一种对于分割点的新的表示方法TextField，旨在解决text instance的黏连问题。<br>　　TextField是一个二维的向量v，用来表示分割score map上的每一个点，它的含义是：每个text像素点到离自己最近的boundary点的向量。它的属性包括：</p><ul><li>非text像素点=(0, 0)，text像素点!=(0, 0)</li><li>向量的magnitude，可以用来区分是文字/非文字像素点</li><li>向量的direction，可以用来进行后处理帮助形成文本块</li></ul><p>　　具体检测流程是：用一个VGG+FPN网络学习TextField的两张score map图，然后这两张图上做关于超像素、合并、形态学等后处理来得到text instance。<br><img src="/images/文本检测7_1.png" alt=""><br>Fig. 3: Pipeline of the proposed method. Given an image, the network learns a novel direction field in terms of a two-channel map, which can be regarded as an image of two-dimensional vectors. To better show the predicted direction field, we calculate and visualize its magnitude and direction information. Text instances are then obtained based on these information via the proposed post-processing using some morphological tools.</p><h4 id="SPCNET"><a href="#SPCNET" class="headerlink" title="SPCNET"></a>SPCNET</h4><p><strong>论文</strong>：Enze Xie——【AAAI2019】Scene Text Detection with Supervised Pyramid Context Network<br><strong>亮点</strong>：</p><ul><li>基于Mask R-CNN进行修改，加Attention机制，结合global信息</li><li>利用Mask的分数来进行Re-score</li></ul><p><strong>方法概述</strong><br>　　针对曲文检测，采用Instance-segmentation思路，基于Mask R-CNN进行修改，将其用在曲线文本检测上。<br>　　文章的motivation认为，已有的Mask R-CNN用在文本检测上有两个问题：</p><ul><li>第一，每个ROI单独做box regression等，缺乏不同region间的context信息（例如，盘子经常出现在桌子上）；</li><li>第二，Mask R-CNN的box针对水平文字，不利于倾斜文本，因为背景像素点占了很大比例（还有，比如用box后两行text的box会有较大覆盖）。</li></ul><p>　　作者提出的解决办法是：</p><ul><li>针对问题一，提出一个Text Context Module，加入SSTD的Attention机制并把global信息和local信息进行fusion；</li><li>针对问题二，提出一种Re-score Mechanism，利用Mask的score和box的score进行平均来解决倾斜文本的分类分数错误问题。</li></ul><p>　　整个检测流程是：用Mask-RCNN+Attention网络进行inference，后处理用Mask的分数Re-socre，利用得到的mask来得到最后的检测结果（minAreaRect）。<br><img src="/images/文本检测8_1.png" alt=""><br>Figure 2: The architecture of our method. (a) The Feature Pyramid Network (FPN) architecture. (b) Pyramid Feature fusion via TCM. (c) Mask R-CNN branch for text classification, bounding box regression and instance segmentation. (d) The proposed Text-Context Module(TCM). Dotted line indicates the text semantic segmentation branch. The text segmentation map is upsampled to the input image size and calculates the loss with Ground Truth.</p><h4 id="CENet"><a href="#CENet" class="headerlink" title="CENet"></a>CENet</h4><p><strong>论文</strong>：Jiaming Liu——【2019】Detecting Text in the Wild with Deep Character Embedding Network<br><strong>亮点</strong>：</p><ul><li>通过将文本的字符合并问题转成字符embedding问题，利用一个网络来学习字符间的连接关系<br><strong>方法概述</strong><br>　　针对任意文本检测（水平、倾斜、曲文），采用从字符到文本行的自底向上的pipeline。先用一个网络CENet学习两个任务，包括单个字符的检测，以及一个字符对的embedding向量（表示两个字符是否可以构成一个pair）。然后再用一个字符分类阈值提取检测到的字符，和一个合并阈值提取group的字符对。最后利用WordSup中的文本线生成算法（图模型+一阶线性模型）得到文本行。<br>实际test时步骤：</li><li>运行CENet，得到字符候选集合+字符对候选集合</li><li>利用分数阈值s过滤非字符噪声</li><li>对每个字符运用r-KNN，查找local的character pairs（参数d、k）</li><li>使用piecewise linear model（分段线性拟合）来得到character group的最外接任意多边形<br><img src="/images/文本检测9_1.png" alt=""><br>Fig. 2. Overall process of the model. Blue bounding boxes in \character proposals” are character candidates with high confidence scores. \Character Clusters” is the character clusters in embedding space, where candidates in the same cluster use the same color. The final detected words represented in quadrangles are shown in \Detected text”. Better view in color.</li></ul><h4 id="MSR"><a href="#MSR" class="headerlink" title="MSR"></a>MSR</h4><p><strong>论文</strong>：Chuhui Xue——【arxiv2019】MSR_Multi-Scale Shape Regression for Scene Text Detection<br><strong>亮点</strong>：</p><ul><li>multi-scale网络中利用FPN的up-sampling把多个不同scale得到的结果进行融合（concat + uppooling）</li><li>boundary-point regression部分直接预测点与最近的boundary point的dx和dy，思路清晰且易实现<br><strong>方法概述</strong><br>　　针对任意文本检测（水平、倾斜、曲文），通过网络来regress文字的边界像素点来得到text region。<br>整个检测的流程包括：</li></ul><ol><li>特征提取：通过一个类似于Image Pyramid的多通道多尺度网络来提取不同scale的图像特征（FPN框架）</li><li>目标预测：预测包括三个分支<ul><li>text region的classification分支</li><li>与nearest boundary point之间的x的dis</li><li>与nearest boundary point之间的y的dis</li></ul></li><li>结果输出：利用Alpha-Shape Algorithm从boundary point set中得到外边界凸多边形<br><img src="/images/文本检测10_1.png" alt=""><br>Fig. 1: Scene text detection using the proposed multi-scale shape regression network (MSR): For scene texts with arbitrary orientations and shapes in (a), MSR first predicts dense text boundary points (in red color) as shown in (b) and then locates texts by a polygon (in green color) that encloses all boundary points of each text instance as shown in (c).</li></ol><h3 id="总结NMS方法"><a href="#总结NMS方法" class="headerlink" title="总结NMS方法"></a>总结NMS方法</h3><ol><li><strong>locality-aware NMS</strong> ：X. Zhou, C. Yao, H. Wen, Y. Wang, S. Zhou, W. He, and J. Liang, “East: An efficient and accurate scene text detector,” arXiv preprint arXiv:1704.03155, 2017.</li><li><strong>inclined NMS</strong> ：Y. Jiang, X. Zhu, X. Wang, S. Yang, W. Li, H. Wang, P. Fu, and Z. Luo, “R2cnn: Rotational region cnn for orientation robust scene text detection,” arXiv preprint arXiv:1706.09579, 2017.</li><li><strong>Mask-NMS</strong> ：Y. Dai, Z. Huang, Y. Gao, and K. Chen, “Fused text segmentation networks for multi-oriented scene text detection,” arXiv preprint arXiv:1709.03272, 2017.</li><li><strong>polygonal NMS(PNMS)</strong> ：L. Yuliang, J. Lianwen, Z. Shuaitao, and Z. Sheng, “Detecting curve text in the wild: New dataset and new solution,” arXiv preprint arXiv:1712.02170, 2017.</li></ol><h3 id="PlusPS"><a href="#PlusPS" class="headerlink" title="PlusPS"></a>PlusPS</h3><ol><li><strong>Vatti clipping algorithm用于对多边形进行shrink</strong> ：Bala R Vatti. A generic solution to polygon clipping. Communications of the ACM, 1992.</li><li><strong>RamerDouglas-Peucker algorithm用于利用mask得到多边形</strong> ：Urs Ramer. An iterative procedure for the polygonal approximation of plane curves. CGIP, 1972.</li></ol>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> 曲线文本 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2018 | 旷视科技提出通过角点定位与区域分割来检测多方向的文本</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E9%80%9A%E8%BF%87%E8%A7%92%E7%82%B9%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%96%B9%E5%90%91%E7%9A%84%E6%96%87%E6%9C%AC/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E9%80%9A%E8%BF%87%E8%A7%92%E7%82%B9%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%96%B9%E5%90%91%E7%9A%84%E6%96%87%E6%9C%AC/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/CLRS/1.png" alt=""><br><strong>Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation</strong><br><strong>KeyWords Plus</strong>: CVPR2018 Multi-Oriented Text<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1802.08948.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1802.08948.pdf</a><br><strong>reference</strong>: Lyu P, Yao C, Wu W, et al. Multi-oriented scene text detection via corner localization and region segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7553-7563.<br><strong>Github</strong>: <a href="https://github.com/lvpengyuan/corner" target="_blank" rel="noopener">https://github.com/lvpengyuan/corner</a></p><h3 id="方法概括"><a href="#方法概括" class="headerlink" title="方法概括"></a>方法概括</h3><h4 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h4><p>　　该方法用一个端到端的网络实现文本检测整个过程。除了基础卷积网络（backbone）外，包括两个并行分支和一个后处理过程。第一个分支是通过一个DSSD网络进行角点检测来提取候选文本区域，第二个分支是利用类似于RFCN进行网格划分的方式来做position-sensitive的segmentation。后处理过程是利用segmentation的score map来综合得分，过滤角点检测得到的候选区域中的噪声。</p><h4 id="背景（文本检测三大难点）"><a href="#背景（文本检测三大难点）" class="headerlink" title="背景（文本检测三大难点）"></a>背景（文本检测三大难点）</h4><ul><li>多方向</li><li>长宽比多变</li><li>文本的粒度多样（包括字符、单词、文本行等多种形式）</li></ul><h4 id="文章亮点"><a href="#文章亮点" class="headerlink" title="文章亮点"></a>文章亮点</h4><ul><li>检测不是用一般的object detection的框架来做，而是用corner point detection来做，可以更好地解决文本方向任意、文本长宽比多变的问题。</li><li>分割用的是<strong>position sensitive segmentation</strong>，仿照RFCN划分网格的思路，把位置信息融合进去，对于检测单词这种细粒度的更有帮助。</li><li>把检测和分割两大类的方法整合起来，进行综合打分的pipeline，这可以使检测精度更高。</li></ul><h3 id="方法细节"><a href="#方法细节" class="headerlink" title="方法细节"></a>方法细节</h3><h4 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h4><p>　　用一个检测网络完成整个检测过程，该网络分为以下几个部分：<br><img src="/images/CLRS/2.png" alt=""></p><ul><li><strong>backbone</strong>：基础网络，用于特征提取（不同分支特征共享）。</li><li><strong>corner detection</strong>：用来生成候选检测框，是一个独立的检测模块，类似于RPN的功能。</li><li><strong>Position Sensitive Segmentation</strong>：整张图逐像素的打分，和一般分割不同的是输出4个score map，分别对应左上、右上、右下、左下四个不同位置的得分。</li><li><strong>Scoring + NMS</strong>：综合打分，利用（2）的框和（3）的score map综合打分，去掉非文本框，最后再接一个NMS。</li></ul><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/images/CLRS/3.png" alt=""></p><ul><li>Backbone取自DSSD = VGG16(pool5) + conv6(fc6) + conv7(fc7) + 4conv + 6 deconv (with 6 residual block)。</li><li>Corner Point Detection是类似于SSD，从多个deconv的feature map上单独做detection得到候选框，然后多层的检测结果串起来，nms后为最后的结果。</li><li>损失：<br><img src="/images/CLRS/4.png" alt=""></li></ul><h4 id="Corner-Detection"><a href="#Corner-Detection" class="headerlink" title="Corner Detection"></a>Corner Detection</h4><h5 id="思路说明"><a href="#思路说明" class="headerlink" title="思路说明"></a>思路说明</h5><ul><li>Step1: 用DSSD框架（任何一个目标检测的框架都可以）找到一个框的四个角点，然后整张图的所有角点都放到一个集合中。</li><li>Step2: 把集合中的所有角点进行组合得到所有候选框。</li></ul><h5 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h5><p><img src="/images/CLRS/5.png" alt=""></p><ul><li>Fi表示backbone结构中的后面几个deconv得到的feature map（每层都单独做了detection）。</li><li>w, h是feature map大小，k是defalt box的个数，q表示角点类型，这里q = 4，即每个位置（左上、右上、右下、左下）都能单独得到2个score map和4个offset map。</li></ul><h5 id="角点信息"><a href="#角点信息" class="headerlink" title="角点信息"></a>角点信息</h5><p><img src="/images/CLRS/6.png" alt=""></p><ul><li>实际上是一个正方形，正方形中心为gt框（指的是文本框）的顶点，正方形的边长 = gt框的最短边。</li><li>corner detection对每一种角点（四种）单独输出corner box，可以看做是一个四类的目标检测问题。</li></ul><h5 id="角点如何组合成文本框？"><a href="#角点如何组合成文本框？" class="headerlink" title="角点如何组合成文本框？"></a>角点如何组合成文本框？</h5><ul><li>由于角点不但有顶点位置信息，也有边长信息，所以满足条件的两个corner point组合起来可以确定一个文字框。</li><li>具体组合思路如下： 一个rotated rectangle可以由两个顶点+垂直于两个顶点组成的边且已知长度的边来确定。<ul><li>由于角点的顶点类型确定，所以短边方向也是确定的，例如左上-左下连边确定短边在右边。</li><li>垂直的边的长度可以取两个角点的正方形边长的平均值。</li></ul></li><li>可以组合的两个corner point满足条件如下：<ul><li>角点分数阈值&gt;0.5；</li><li>角点的正方形边长大小相似（边长比&lt;1.5）；</li><li>框的顶点类型和位置先验信息（例如，“左上”、“左下”的角点的x应该比“右上”、“右下”小）。</li></ul></li></ul><h5 id="损失"><a href="#损失" class="headerlink" title="损失"></a>损失</h5><ul><li>得分分支（score branch）的损失：Cross Entropy损失。<br><img src="/images/CLRS/7.png" alt=""></li><li>偏移分支（offset branch）的损失：Smooth L1损失。<br><img src="/images/CLRS/8.png" alt=""></li></ul><h4 id="Poosition-Sensitive-Segmentation"><a href="#Poosition-Sensitive-Segmentation" class="headerlink" title="Poosition Sensitive Segmentation"></a>Poosition Sensitive Segmentation</h4><ul><li>思路说明<ul><li>把一个文字框划分成g * g个网格的小框（一个bin），每个bin做为一类，把一个text/non-text的二类问题变成g * g个二类问题。</li></ul></li><li>网络结构<br><img src="/images/CLRS/9.png" alt=""></li><li>损失：dice损失<br><img src="/images/CLRS/10.png" alt=""></li></ul><h4 id="Scoring"><a href="#Scoring" class="headerlink" title="Scoring"></a>Scoring</h4><p><img src="/images/CLRS/11.png" alt=""></p><ul><li>目的<ul><li>利用segmentation得到的g * g张score map来进一步判断corner detection得到的那些候选框是否是文字，过滤噪声框。</li></ul></li><li>思路说明<ul><li>把detection得到的框先划分成g * g个网格（bin），每个bin对应各自的segmentation score map，然后把对应的score map里对应bin位置的那些前景点的像素值取平均（底下P的分母是C，不是直接R的面积，或者bin的面积可以看出只取前景点，即score&gt;0的点）作为每个bin的分数，最后把g * g个bin的分数取平均为初始文字框的分数。</li></ul></li><li><p>算法伪代码<br><img src="/images/CLRS/12.png" alt=""></p></li><li><p>为什么scoring这么复杂，不直接用区域的像素平均值？</p><ul><li>采用position sensitive segmentation的思路决定了最后scoring的时候也必须划网格单独取值再平均。至于之所以只取前像素点是为了平均时不受背景点影响，更加精确。</li></ul></li><li>注意一点<ul><li>该文章的分割分支与角点分支（也可以叫做回归分支，候选目标检测分支，作用类似于RPN，用来回归候选框）的组合方式与其他的目标检测方法（例如RPN，SSD）中分割与回归分支的组合方式完全不同。对于RPN或SSD，其回归分支与分割分支共同作用才能得到候选框，分割分支的score map上的每个像素点值决定了回归分支中某几个框是否是有效的（目标框还是背景框）。而这篇文章的分割分支和回归分支除了共用特征外，以及最后把损失都加到损失层外，两个分支是完全独立的！也就是说，回归分支可以换成任何一个可以生成候选框的目标检测分支（RPN，SSD，甚至Faster R-CNN），分割分支可以换成任何一个可以生成目标置信概率图的分支，而把这两个分支加上最后的综合打分就可以让分割分支去帮助目标检测分支进一步过滤噪声（但对框的生成没有影响）。这种框架是把目前的两大类文字检测方法（基于目标检测的框架，和基于分割的框架）综合起来，可以提高检测精度。</li></ul></li></ul><h4 id="问题搜集"><a href="#问题搜集" class="headerlink" title="问题搜集"></a>问题搜集</h4><ul><li>为什么要用position-sensitive segmentation？从结果来讲，和普通的segmentation而言，到底好在哪里？是否是更适合各种粒度的文字（字符，单词，文本行）?</li><li>文章中用角点检测来检测文字和一般用目标检测的方法来检测文字，其优势和劣势在哪里?<ul><li>优势</li><li>角点检测里每个角点都是独立的，所以在多个特征层上的detection的角点可以全部放到一个集合里再去两两组合获得文字框，而不采用每个特征层单独做直接得到文字框后再多层融合。这样好处在于，同一个框的不同角点可以是从不同的特征层上检测到的，即使在某一层上某个角点漏了，但有其他层可以帮忙将其找回来。</li><li>角点检测不用考虑方向性，所以可以用任何一般的目标检测框架而无需修改（加方向参数等）直接用于检测角点。</li><li>角点检测不用考虑文字框的长宽比大小，对于类似RPN等基于anchor的其defaut box的长宽比和scale不好设置，尤其针对长文本，角点检测则不用考虑这个问题。</li><li>可能潜在的问题</li><li>如果角点很多，那么这种两两组合的可能性很多，使得检测框特别多，对后续nms等压力较大。</li><li>由于任意两个角点都组合，所以可能导致很多无关的框、没有意义的框都被当做候选框（比如从左上顶点和右下顶点组成的框）。</li></ul></li><li>我认为文章中疑问或者有问题的点<ul><li>Corner Point Prediction的offset输出没有必要是4维的，因为已知是正方形的情况下，只需x1，y1，s三维就好了（w = h = s）。</li><li>部分存在歧义，没有说清楚：We determine the relative position of a rotated rectangle by the following rules: 1) the x-coordinates of top left and bottom-left corner points must less than the x coordinates of top-right and bottom-right corner points; 2)the y-coordinates of top-left and top-right corner points must less than the y-coordinates of bottom-left and bottom right corner points.<br><img src="/images/CLRS/13.png" alt=""></li></ul></li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/CLRS/14.png" alt=""></p><ul><li>深度框架：Pytorch</li><li>结果与速度说明<ul><li>Nvidia Titan Pascal GPU</li><li>ICDAR2013：图像大小resize成512 * 512，100ms/每张图，F值=85.5%/88.0%（多尺度）。</li><li>MSRA-TD500：图像大小768 * 768，5.7FPS，F值=81.5%。</li><li>MLT：768 * 768，F值=72.4%。</li><li>ICDAR2015：768 * 1280，1FPS，F值= 84.3%。</li><li>COCO-Text：768 * 768，IOU=0.5，F值=42.5%。</li></ul></li><li>ICDAR2013<br><img src="/images/CLRS/15.png" alt=""></li><li>ICDAR2015<br><img src="/images/CLRS/16.png" alt=""></li><li>MSRA-TD500<br><img src="/images/CLRS/17.png" alt=""></li><li>COCO-Text<br><img src="/images/CLRS/18.png" alt=""></li><li>MLT<br><img src="/images/CLRS/19.png" alt=""></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>用角点检测来做目标检测问题很有新意。</li><li>Position-sensitive segmentation和一般的segmentation不太一样，虽然不是完全理解用这个的原因（融合位置信息？）。</li><li>做一次分割，再做一次目标检测，两个共同来打分，这个思路很有意思，不管是用什么做分割或检测，不管分割和检测是否共用网络基础结构，不管分割和检测之间是否有关系，这个框架都很可取。</li></ul>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> 四边形文本 </tag>
            
            <tag> 旷视 </tag>
            
            <tag> 角点定位与区域分割 </tag>
            
            <tag> CVPR2018 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNN网络结构的发展：从LeNet到EfficientNet</title>
      <link href="/CNN/CNN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%EF%BC%9A%E4%BB%8ELeNet%E5%88%B0EfficientNet/"/>
      <url>/CNN/CNN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%EF%BC%9A%E4%BB%8ELeNet%E5%88%B0EfficientNet/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="CNN基本部件介绍"><a href="#CNN基本部件介绍" class="headerlink" title="CNN基本部件介绍"></a>CNN基本部件介绍</h3><h4 id="局部感受野"><a href="#局部感受野" class="headerlink" title="局部感受野"></a>局部感受野</h4><p>　　在图像中局部像素之间的联系较为紧密，而距离较远的像素联系相对较弱。因此，其实每个神经元没必要对图像全局进行感知，只需要感知局部信息，然后在更高层局部信息综合起来即可得到全局信息。卷积操作即是局部感受野的实现，并且卷积操作因为能够权值共享，所以也减少了参数量。</p><h4 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h4><p>　　池化是将输入图像进行缩小，减少像素信息，只保留重要信息，主要是为了减少计算量。主要包括最大池化和均值池化。</p><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>　　激活函数的作用是用来加入非线性。常见的激活函数有sigmod，tanh，relu，前两者常用在全连接层，relu常见于卷积层。</p><h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>　　全连接层在整个卷积神经网络中起分类器的作用。在全连接层之前需要将之前的输出展平。</p><h3 id="经典网络结构"><a href="#经典网络结构" class="headerlink" title="经典网络结构"></a>经典网络结构</h3><h4 id="1、LeNet5"><a href="#1、LeNet5" class="headerlink" title="1、LeNet5"></a>1、LeNet5</h4><p>　　由两个卷积层，两个池化层，两个全连接层组成。卷积核都是5×5，stride=1，池化层使用maxpooling。<br><img src="/images/CNN/1.png" alt=""></p><h4 id="2、AlexNet"><a href="#2、AlexNet" class="headerlink" title="2、AlexNet"></a>2、AlexNet</h4><p>　　模型共八层（不算input层），包含五个卷积层、三个全连接层。最后一层使用softmax做分类输出。AlexNet使用了ReLU做激活函数；防止过拟合使用dropout和数据增强；双GPU实现；使用LRN。<br><img src="/images/CNN/2.png" alt=""><br><img src="/images/CNN/3.png" alt=""></p><h4 id="3、VGG"><a href="#3、VGG" class="headerlink" title="3、VGG"></a>3、VGG</h4><p>　　全部使用3×3卷积核的堆叠，来模拟更大的感受野，并且网络层数更深。VGG有五段卷积，每段卷积后接一层最大池化。卷积核数目逐渐增加。<br>　　总结：LRN作用不大；越深的网络效果越好；1×1的卷积也很有效但是没有3×3好。<br><img src="/images/CNN/4.png" alt=""></p><h4 id="4、GoogLeNet-inception-v1"><a href="#4、GoogLeNet-inception-v1" class="headerlink" title="4、GoogLeNet(inception v1)"></a>4、GoogLeNet(inception v1)</h4><p>　　从VGG中了解到，网络层数越深效果越好。但是随着模型越深参数越来越多，这就导致网络比较容易过拟合，需要提供更多的训练数据；另外，复杂的网络意味更多的计算量，更大的模型存储，需要更多的资源，且速度不够快。GoogLeNet就是从减少参数的角度来设计网络结构的。<br>　　GoogLeNet通过增加网络宽度的方式来增加网络复杂度，让网络可以自己去应该如何选择卷积核。这种设计减少了参数 ，同时提高了网络对多种尺度的适应性。使用了1×1卷积可以使网络在不增加参数的情况下增加网络复杂度。<br><img src="/images/CNN/5.png" alt=""></p><p><strong>Inception-v2</strong><br>　　在v1的基础上加入batch normalization技术，在tensorflow中，使用BN在激活函数之前效果更好；将5×5卷积替换成两个连续的3×3卷积，使网络更深，参数更少。</p><p><strong>Inception-v3</strong><br>　　核心思想是将卷积核分解成更小的卷积，如将7×7分解成1×7和7×1两个卷积核，使网络参数减少，深度加快。</p><p><strong>Inception-v4</strong><br>　　引入了ResNet，使训练加速，性能提升。但是当滤波器的数目过大（&gt;1000）时，训练很不稳定，可以加入activate scaling因子来缓解。</p><h4 id="5、Xception"><a href="#5、Xception" class="headerlink" title="5、Xception"></a>5、Xception</h4><p>　　在Inception-v3的基础上提出，基本思想是通道分离式卷积，但是又有区别。模型参数稍微减少，但是精度更高。Xception先做1×1卷积再做3×3卷积，即先将通道合并，再进行空间卷积。depthwise正好相反，先进行空间3×3卷积，再进行通道1×1卷积。核心思想是遵循一个假设：卷积的时候要将通道的卷积与空间的卷积进行分离。而MobileNet-v1用的就是depthwise的顺序，并且加了BN和ReLU。Xception的参数量与Inception-v3相差不大，其增加了网络宽度，旨在提升网络准确率，而MobileNet-v1旨在减少网络参数，提高效率。<br><img src="/images/CNN/6.png" alt=""><br><img src="/images/CNN/7.png" alt=""></p><h4 id="6、MobileNet系列"><a href="#6、MobileNet系列" class="headerlink" title="6、MobileNet系列"></a>6、MobileNet系列</h4><p><strong>V1</strong><br>　　使用depthwise separable convolutions；放弃pooling层，而使用stride=2的卷积。标准卷积的卷积核的通道数等于输入特征图的通道数；而depthwise卷积核通道数是1；还有两个参数可以控制，a控制输入输出通道数；p控制图像（特征图）分辨率。<br><img src="/images/CNN/8.png" alt=""><br><img src="/images/CNN/9.png" alt=""></p><p><strong>V2</strong><br>　　相比v1有三点不同：</p><ol><li>引入了残差结构；</li><li>在dw之前先进行1×1卷积增加feature map通道数，与一般的residual block是不同的；</li><li>pointwise结束之后弃用ReLU，改为linear激活函数，来防止ReLU对特征的破环。这样做是因为dw层提取的特征受限于输入的通道数，若采用传统的residual block，先压缩那dw可提取的特征就更少了，因此一开始不压缩，反而先扩张。但是当采用扩张-卷积-压缩时，在压缩之后会碰到一个问题，ReLU会破环特征，而特征本来就已经被压缩，再经过ReLU还会损失一部分特征，应该采用linear。</li></ol><p><img src="/images/CNN/10.png" alt=""><br><img src="/images/CNN/11.png" alt=""></p><p><strong>V3</strong><br>　　互补搜索技术组合：由资源受限的NAS执行模块集搜索，NetAdapt执行局部搜索；网络结构改进：将最后一步的平均池化层前移并移除最后一个卷积层，引入h-swish激活函数，修改了开始的滤波器组。<br>　　V3综合了v1的深度可分离卷积，v2的具有线性瓶颈的反残差结构，SE结构的轻量级注意力模型。<br><img src="/images/CNN/12.png" alt=""><br><img src="/images/CNN/13.png" alt=""><br><img src="/images/CNN/14.png" alt=""></p><h4 id="7、EffNet"><a href="#7、EffNet" class="headerlink" title="7、EffNet"></a>7、EffNet</h4><p>　　EffNet是对MobileNet-v1的改进，主要思想是：将MobileNet-1的dw层分解成两个3×1和1×3的dw层，这样，第一层之后就采用pooling，从而减少第二层的计算量。EffNet比MobileNet-v1和ShuffleNet-v1模型更小，精度更高。<br><img src="/images/CNN/15.png" alt=""><br><img src="/images/CNN/16.png" alt=""></p><h4 id="8、EfficientNet"><a href="#8、EfficientNet" class="headerlink" title="8、EfficientNet"></a>8、EfficientNet</h4><p>　　研究网络设计时在<strong><em>depth, width, resolution</em></strong>上进行扩展的方式，以及之间的相互关系。可以取得更高的效率和准确率。<br><img src="/images/CNN/17.png" alt=""></p><h4 id="9、ResNet"><a href="#9、ResNet" class="headerlink" title="9、ResNet"></a>9、ResNet</h4><p>　　VGG证明更深的网络层数是提高精度的有效手段，但是更深的网络极易导致梯度弥散，从而导致网络无法收敛。经测试，20层以上会随着层数增加收敛效果越来越差。ResNet可以很好的解决梯度消失的问题（其实是缓解，并不能真正解决），ResNet增加了<strong><em>shortcut连边</em></strong>。<br><img src="/images/CNN/18.png" alt=""></p><h4 id="10、ResNeXt"><a href="#10、ResNeXt" class="headerlink" title="10、ResNeXt"></a>10、ResNeXt</h4><p>　　基于ResNet和Inception的split+transform+concate结合。但效果却比ResNet、Inception、Inception-ResNet效果都要好。可以使用<strong><em>group convolution</em></strong>。一般来说增加网络表达能力的途径有三种：1.增加网络深度，如从AlexNet到ResNet，但是实验结果表明由网络深度带来的提升越来越小；2.增加网络模块的宽度，但是宽度的增加必然带来指数级的参数规模提升，也非主流CNN设计；3.改善CNN网络结构设计，如Inception系列和ResNeXt等。且实验发现增加Cardinatity即一个block中所具有的相同分支的数目可以更好的提升模型表达能力。<br><img src="/images/CNN/19.png" alt=""><br><img src="/images/CNN/20.png" alt=""></p><h4 id="11、DenseNet"><a href="#11、DenseNet" class="headerlink" title="11、DenseNet"></a>11、DenseNet</h4><p>　　DenseNet通过<strong><em>特征重用</em></strong>来大幅减少网络的参数量，又在一定程度上缓解了梯度消失问题。<br><img src="/images/CNN/21.png" alt=""></p><h4 id="12、SqueezeNet"><a href="#12、SqueezeNet" class="headerlink" title="12、SqueezeNet"></a>12、SqueezeNet</h4><p>　　提出了fire-module：squeeze层+expand层。Squeeze层就是1×1卷积，expand层用1×1和3×3分别卷积，然后concatenation。squeezeNet参数是alexnet的1/50，经过压缩之后是1/510，但是准确率和alexnet相当。<br><img src="/images/CNN/22.png" alt=""></p><h4 id="13、ShuffleNet系列"><a href="#13、ShuffleNet系列" class="headerlink" title="13、ShuffleNet系列"></a>13、ShuffleNet系列</h4><p><strong>V1</strong><br>　　通过分组卷积与1×1的逐点群卷积核来降低计算量，通过重组通道来丰富各个通道的信息。Xception和ResNeXt在小型网络模型中效率较低，因为大量的1×1卷积很耗资源，因此提出逐点群卷积来降低计算复杂度，但是使用逐点群卷积会有副作用，故在此基础上提出通道shuffle来帮助信息流通。虽然dw可以减少计算量和参数量，但是在低功耗设备上，与密集的操作相比，计算、存储访问的效率更差，故shufflenet上旨在bottleneck上使用深度卷积，尽可能减少开销。<br><img src="/images/CNN/23.png" alt=""></p><p><strong>V2</strong><br>　　使神经网络更加高效的CNN网络结构设计准则：</p><ol><li>输入通道数与输出通道数保持相等可以最小化内存访问成本。</li><li>分组卷积中使用过多的分组会增加内存访问成本。</li><li>网络结构太复杂（分支和基本单元过多）会降低网络的并行程度。</li><li>element-wise的操作消耗也不可忽略。</li></ol><p><img src="/images/CNN/24.png" alt=""></p><h4 id="14、SENet"><a href="#14、SENet" class="headerlink" title="14、SENet"></a>14、SENet</h4><p><img src="/images/CNN/25.png" alt=""></p><h4 id="15、SKNet"><a href="#15、SKNet" class="headerlink" title="15、SKNet"></a>15、SKNet</h4><p><img src="/images/CNN/26.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> CNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 商汤提出金字塔掩模文本检测器：PMTD</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E5%95%86%E6%B1%A4%E6%8F%90%E5%87%BA%E9%87%91%E5%AD%97%E5%A1%94%E6%8E%A9%E6%A8%A1%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E5%99%A8%EF%BC%9APMTD/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E5%95%86%E6%B1%A4%E6%8F%90%E5%87%BA%E9%87%91%E5%AD%97%E5%A1%94%E6%8E%A9%E6%A8%A1%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E5%99%A8%EF%BC%9APMTD/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/PMTD/1.png" alt=""><br><strong>Pyramid Mask Text Detector</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Quadrilateral Text<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1903.11800.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1903.11800.pdf</a><br><strong>reference</strong>: Liu, Jingchao &amp; Liu, Xuebo &amp; Sheng, Jie &amp; Liang, Ding &amp; Li, Xin &amp; Liu, Qingjie. (2019). Pyramid Mask Text Detector.<br><strong>Github</strong>: 未开源</p><p>　　本文是商汤和香港中文大学联合发表并于 2019.03.28 挂在 arXiv 上，本文的方法在 ICDAR2017 MIT 数据集上，相比于之前最高的精确率提升了 5.83% 百分点，达到 80.13%；在 ICDAR2015 数据集上，提升了 1.34% 个百分点，达到 89.33%。</p><h4 id="论文主要思想"><a href="#论文主要思想" class="headerlink" title="论文主要思想"></a>论文主要思想</h4><p>　　本文提出了 Pyramid Mask 文本检测器，简称 PMTD。它主要做了如下工作：</p><ol><li>提出了软语义分割的训练数据标签。与现有的基于 Mask RCNN 方法（文本区域内的像素标签为 0 或 1）不同，本文针对文本区域和背景区域提出了软语义分割（soft semantic segmentation），文本行区域内的像素标签值范围在 0-1 之间，不同位置的像素标签值是由其当前位置到文本边界框的距离决定的，这样做的好处是可以考虑训练数据的形状和位置信息，同时可以一定程度上缓解文本边界区域的一些背景干扰；</li><li>提出通过平面聚类的方法构建最终的文本行。通过像素坐标及对应像素点的得分构建 3D 点集合，然后通过金字塔平面聚类的迭代方法得到最终的文本行。</li></ol><p><img src="/images/PMTD/2.png" alt=""></p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>　　文中做了两个实验：baseline 和 PMTD。baseline 是基于 Mask RCNN 的，主干提取特征网络采用的是 ResNet50，网络结构采用了 FPN。相比原生的 Mask RCNN，做了 3 方面修改：1）数据增广；2）RPN anchor；3）OHEM。</p><h4 id="baseline存在的问题"><a href="#baseline存在的问题" class="headerlink" title="baseline存在的问题"></a>baseline存在的问题</h4><ol><li>没有考虑普通文本一般是四边形，仅按照像素进行分类，丢失了与形状相关的信息；</li><li>将文本行的四边形的标定转换为像素级别的 groundtruth 会造成 groundtruth 不准的问题；</li><li>在 Mask R-CNN 中是先得到检测的框，然后对框内的物体进行分割，如果框的位置不准确，这样会导致分割出来的结果也不会准确。</li></ol><h4 id="PMTD所做的改进"><a href="#PMTD所做的改进" class="headerlink" title="PMTD所做的改进"></a>PMTD所做的改进</h4><p>　　PMTD 是针对 baseline 中存在的问题提出的改进，主要包括：</p><ol><li>网络结构的改进：PMTD 采用了更大的感受野来获取更高的准确率，为了获取更大的感受野，本文通过改变 mask 分支，将该分支中的前 4 个卷积层改成步长为 2 的空洞卷积，因为反卷积操作会带来棋盘效应，所以这里采用双线性采样＋卷积层来替换反卷积层；</li><li>对于训练标签生成部分，使用了金字塔标签生成，具体做法是：文本行的中心点为金字塔的顶点（score=1），文本行的边为金字塔的底边，对金字塔的每个面中应该包含哪些像素点采用双线性插值的方法。</li></ol><p><img src="/images/PMTD/3.png" alt=""></p><h4 id="最终文本行的生成"><a href="#最终文本行的生成" class="headerlink" title="最终文本行的生成"></a>最终文本行的生成</h4><p>　　文中使用了平面聚类的方法，用于迭代回归从已学习到的 soft text mask 寻找最佳的文本行的边界框。在具体操作时，可以看成与金字塔标签生成的反过程。<br><img src="/images/PMTD/4.png" alt=""><br><img src="/images/PMTD/5.png" alt=""><br><img src="/images/PMTD/6.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> PMTD </tag>
            
            <tag> 商汤 </tag>
            
            <tag> 四边形文本 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ECCV2018 | 旷视科技提出弯曲文本表示TextSnake</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/ECCV2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E5%BC%AF%E6%9B%B2%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BATextSnake/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/ECCV2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E5%BC%AF%E6%9B%B2%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BATextSnake/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes</strong><br><strong>KeyWords Plus</strong>: ECCV2018 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1807.01544" target="_blank" rel="noopener">https://arxiv.org/abs/1807.01544</a><br><strong>reference</strong>: Long S, Ruan J, Zhang W, et al. Textsnake: A flexible representation for detecting text of arbitrary shapes[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 20-36.<br><strong>Github</strong>: <a href="https://github.com/princewang1994/TextSnake.pytorch" target="_blank" rel="noopener">https://github.com/princewang1994/TextSnake.pytorch</a></p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> 曲线文本 </tag>
            
            <tag> 旷视 </tag>
            
            <tag> TextSnake </tag>
            
            <tag> ECCV2018 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | NAVER提出字符级别的文本检测网络：CRAFT</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-NAVER%E6%8F%90%E5%87%BA%E5%AD%97%E7%AC%A6%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%EF%BC%9ACRAFT/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-NAVER%E6%8F%90%E5%87%BA%E5%AD%97%E7%AC%A6%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%EF%BC%9ACRAFT/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/CRAFT/1.png" alt=""><br><strong>Character Region Awareness for Text Detection</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1904.01941" target="_blank" rel="noopener">https://arxiv.org/abs/1904.01941</a><br><strong>reference</strong>: Baek Y, Lee B, Han D, et al. Character Region Awareness for Text Detection[J]. arXiv preprint arXiv:1904.01941, 2019.<br><strong>NAVER</strong>：line的母公司，韩国的最大的互联网公司，字符级别的文字检测，采用了CAM热力图的操作去检测每一个字符。<br><strong>Github</strong>: 未开源</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>　　字符级别的文本检测网络，用分水岭算法生成label，采用heatmaps去得到激活值最大的目标区域，有点类似attention。</p><h4 id="1、论文创新点"><a href="#1、论文创新点" class="headerlink" title="1、论文创新点"></a>1、论文创新点</h4><ol><li>提出了一种字符级别的文本检测算法;</li><li>预测得到:1.<strong>The character region score</strong> 2. <strong>Affinity score</strong>. The region score is used to <strong>localize individual characters</strong> in the image, and the affinity score is used to <strong>group each character into a single instance</strong>.</li><li>Propose a <strong>weakly-supervised learning framework</strong> that estimates character-level groundtruths in existing real word-level datasets.</li></ol><p><img src="/images/CRAFT/2.png" alt=""></p><h4 id="2、算法主体"><a href="#2、算法主体" class="headerlink" title="2、算法主体"></a>2、算法主体</h4><p>　　该论文主要预测<strong>每个字符区域和字符之间的紧密程度</strong>，因为没有字符级别的标注，所以模型训练是在<strong>弱监督的方式</strong>下。网络的backbone采用VGG16，之后接上采样，最终输出两个通道：<strong>the region score and the affinity score</strong>。<br><img src="/images/CRAFT/3.png" alt=""><br>　　训练在<strong>弱监督学习的方式</strong>下，首先有人造合成的数据集，具有字符级别的label；然后real image没有字符级别的标注时，网络检测合成产生label再进行训练。如上图所示，对真实场景中的数据集和人造合成的数据集分别有不同的训练方式。</p><h4 id="3、label-generation"><a href="#3、label-generation" class="headerlink" title="3、label generation"></a>3、label generation</h4><p><img src="/images/CRAFT/4.png" alt=""><br>　　分别产生<strong>Region Score GT和Affinity Score GT</strong>。<br>　　The following steps to approximate and generate the ground truth for both the region score and the affinity score:<br>1) prepare a <strong>2-dimensional isotropic Gaussian map</strong>;<br>2) compute <strong>perspective transform</strong> between the Gaussian map region and each character box;<br>3) <strong>warp Gaussian map</strong> to the box area.<br>　　使用小感受野也能预测大文本和长文本，只需要关注字符级别的内容而不需要关注整个文本实例。<br><img src="/images/CRAFT/5.png" alt=""><br>　　分三步产生字符级别的label： </p><ol><li>抠出文本级别的内容；</li><li>预测region score区域；</li><li>运用分水岭算法；</li><li>得到字符基本的文字框;</li><li>贴上文字框;</li></ol><p>　　为了防止在弱监督方式下产生的错误label带偏网络，该论文提出了一种评价方式:<br><img src="/images/CRAFT/6.png" alt=""></p><h4 id="4、Post-processing"><a href="#4、Post-processing" class="headerlink" title="4、Post-processing"></a>4、Post-processing</h4><p>　　规则文本后处理可以分为以下几步：</p><ol><li>首先对0-1之间的概率图进行取阈值计算；</li><li>使用 Connected Component Labeling(CCL) 进行区域连接；</li><li>最后使用 OpenCV 的 MinAreaRect 框出最小的四边形区域。</li></ol><p><img src="/images/CRAFT/7.png" alt=""><br>　　不规则文本检测后处理可以分为以下几步（如上图所示）：</p><ol><li>先找到扫描方向的局部最大值（blue line）；</li><li>连接所有the local maxima上的中心点叫做中心线；</li><li>然后将the local maxima lines旋转至于中心线垂直 </li><li>the local maxima lines上的端点是文本控制点的候选点，为了能更好的覆盖文本，将文本最外端的两个控制点分别向外移动the local maxima lines的半径长度最为最终的控制点。</li></ol><h4 id="5、Experiment-Results"><a href="#5、Experiment-Results" class="headerlink" title="5、Experiment Results"></a>5、Experiment Results</h4><p><img src="/images/CRAFT/8.png" alt=""><br><img src="/images/CRAFT/9.png" alt=""><br><img src="/images/CRAFT/10.png" alt=""><br><img src="/images/CRAFT/11.png" alt=""></p><h4 id="6、Conclusion-and-Future-work"><a href="#6、Conclusion-and-Future-work" class="headerlink" title="6、Conclusion and Future work"></a>6、Conclusion and Future work</h4><p>　　个人观点：<strong>不太受感受野的限制，只关注单个文字，对于长文本和不规则文本不必特意去设置相应大小的卷积提升感受野</strong>。</p><div class="row">    <embed src="/pdf/CRAFT.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CRAFT </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> NAVER </tag>
            
            <tag> 曲线文本 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 百度提出LOMO文本检测算法</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E7%99%BE%E5%BA%A6%E6%8F%90%E5%87%BALOMO%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E7%99%BE%E5%BA%A6%E6%8F%90%E5%87%BALOMO%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/LOMO/1.png" alt=""><br><strong>Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1904.06535" target="_blank" rel="noopener">https://arxiv.org/abs/1904.06535</a><br><strong>reference</strong>: Zhang C, Liang B, Huang Z, et al. Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes[J]. arXiv preprint arXiv:1904.06535, 2019.<br><strong>Github</strong>: 未开源</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>　　这是百度和厦门大学合作的一篇文章。由于受CNN感受野的限制以及用于描述文本的类似矩形框或者四边形这样的简单的表示方法，当处理更加有挑战的文本实例时，比如极其长的文本和任意形状的文本，之前的一些方法就不适用了。而本文提出的这种方法，正是为了解决这两个问题。<br>　　本文提出了一种文本检测器，即LOMO（Look More Than Once），它可以逐步地调整文本（或者换句话说，不止看一次）。LOMO由直接回归器（DR）、迭代细化模块（IRM）和形状表示模块（SEM）组成。首先，DR分支生成四边形的文本proposals。接下来，IRM基于提取的初步proposals的特征块，通过迭代细化逐步感知整个长文本。最后，通过考虑文本实例的几何属性，包括文本区域、文本中心线和边界偏移，引入SEM来得到更加精确的不规则的多边形的文本表示。</p><h4 id="论文主要贡献"><a href="#论文主要贡献" class="headerlink" title="论文主要贡献"></a>论文主要贡献</h4><p>（1）提出了一个迭代细化模块(<strong>IRM</strong>)，它改善了<strong>长文本</strong>检测的性能。<br>（2）引入实例级形状表示模块(<strong>SEM</strong>)，用于解决<strong>任意形状的场景文本</strong>的检测问题。<br>（3）加入<strong>迭代细化模块</strong>和<strong>形状表示模块</strong>的LOMO可以以端到端的方式训练，并在几个包括不同形式的文本实例（<strong>有向的、长的、多语言的和弯曲的</strong>）的基准数据集上实现了最佳的性能。</p><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>（1）将图像输入到backbone中，抽取 <strong>DR, IRM 和 SEM</strong> 三个分支的共享特征图。backbone用的是<strong>ResNet50 + FPN</strong>，对ResNet50中的阶段2，阶段3，阶段4和阶段5的特征图进行特征融合，得到大小是输入图像的1/4，通道是128的特征图。并由之后的DR，IRM和SEM三个分支共享该特征图。<br>（2）采用类似 EAST 和 Deep Regression 的一个<strong>direct regression network</strong>作为 <strong>DR</strong> 分支，以一种逐像素的方式去预测单词或文本行的四边形。通常，由于感受野的限制，DR分支很难检测到长文本。如图2（2）所示的蓝色四边形。<br>（3）IRM可以从DR或其自身的输出迭代地细化输入proposals，以使初步文本proposals被完善，以更完整地覆盖文本实例，更接近真实边界框。如图2（3）所示的绿色四边形。<br>（4）为了获得文本的紧凑表示，尤其是不规则的文本，因为四边形的建议形式会覆盖太多的背景区域，通过学习文本的几何性质包括<strong>文本区域，文本中心线和边界偏移（中心线和上/下边界线之间的距离）</strong>，SEM会重建文本实例的形状表示。如图2（4）所示的红色四边形。<br><img src="/images/LOMO/2.png" alt=""></p><h4 id="Direct-Regressor-DR-：直接回归DR–-gt-文本-非文本分类和位置回归"><a href="#Direct-Regressor-DR-：直接回归DR–-gt-文本-非文本分类和位置回归" class="headerlink" title="Direct Regressor(DR)：直接回归DR–&gt;文本/非文本分类和位置回归"></a>Direct Regressor(DR)：直接回归DR–&gt;文本/非文本分类和位置回归</h4><p>　　DR模块采用的是一个<strong>fully convolutional sub-network</strong>。基于共享特征图，计算文本/非文本置信度、和包含该正样本像素的矩形的4个角点的偏移量。DR分支的损失函数由两部分组成：<strong>文本/非文本分类和位置回归</strong>。<br>　　将文本/非文本分类视为在1/4下采样分数图上的二值分割。<br>　　第一部分文本分类的损失函数使用的是<strong>scale-invariant dice-coefficient</strong>函数，用于提升 DR 的尺度泛化能力。其中y是0/1标签图，y^是预测分数图，sum是2D空间上的累积函数。此外，w是二维权重图。正位置的值通过将它们所属的四边形的短边分开的归一化常数l来计算，而负位置的值被设定为1.0。在实验中将常数l设置为64。<br><img src="/images/LOMO/3.png" alt=""><br>　　第二部分位置回归的损失函数采用的是<strong>smooth L1 loss</strong>。将这两项结合到一起，DR的整个损失函数可以表示为：<br><img src="/images/LOMO/4.png" alt=""><br>　　其中超参数λ平衡两个损失项，在我们的实验中设置为0.01。</p><h4 id="Iterative-Refinement-Module-IRM-：迭代细化模块IRM"><a href="#Iterative-Refinement-Module-IRM-：迭代细化模块IRM" class="headerlink" title="Iterative Refinement Module(IRM)：迭代细化模块IRM"></a>Iterative Refinement Module(IRM)：迭代细化模块IRM</h4><p>　　IRM的设计参考基于区域的物体检测，但只有边界框回归任务。使用RoI变换层来提取输入文本四边形的特征块，而不是RoI pooling层或RoI align层。与后两者相比，前者可以在保持纵横比不变的情况下提取四边形建议的特征块。<br>　　此外，靠近角点的位置可以在同一感受野内感知到更准确的边界信息。因此，引入角点注意力机制来回归每个角点的坐标偏移。<br><img src="/images/LOMO/5.png" alt=""><br>　　对于一个DR生成的文本四边形，将其与共享特征图一起输入到RoI变换层，获得1×8×64×128特征块。然后，三个3×3卷积层以进一步提取丰富的上下文信息fr。接下来，使用1×1卷积层和sigmoid层来学习4个角点的注意力图ma。每个角点注意力图上的值表示支持相应角点的偏移回归的贡献权重。<br>　　使用fr和ma，可以通过逐点生成和reduce_sum操作来提取4个角点回归特征（图3中绿色的4X{1X1X1X128}特征图）：<br><img src="/images/LOMO/5_1.png" alt=""><br>　　其中fci表示形状为1×1×1×128的第i个角点回归特征，mia是第i个角点注意力特征图。<br>　　最后，预测输入四边形和真值文本框之间的4个角点的偏移。<br>　　在训练阶段，保留来自于DR的K个初步的检测四边形。<strong>corner regression loss</strong>可以表示为：<br><img src="/images/LOMO/6.png" alt=""></p><h4 id="Shape-Expression-Module（SEM）：形状表示模块SEM"><a href="#Shape-Expression-Module（SEM）：形状表示模块SEM" class="headerlink" title="Shape Expression Module（SEM）：形状表示模块SEM"></a>Shape Expression Module（SEM）：形状表示模块SEM</h4><p>SEM是完全卷积网络，随后是RoI变换层。学习文本的几何属性，包括文本区域、文本中心线和边界偏移（文本中心线和上/下文本边界线之间的偏移），以重建文本实例的精确形状表示。<br><strong>文本区域</strong>是一个二值 mask, 里面的 foreground pixels （比如在多边形标注区域内部的）标记为 1，background pixels 标记为 0。<br><strong>文本中心线</strong> 也是一个二值 mask ，不同的是，它是基于文本多边形标注的 side-shrunk version .<br><strong>边界偏移</strong> 为四通道图, 在文本行图对应位置上的正响应区域内，具有有效的值。当中心线样本（红点）如图4（a）所示，绘制一条垂直于其切线的法线，该法线与上下边界线相交，得到两个边界点（即粉色和橙色）。对于每个红点，通过计算从其自身到其两个相关边界点的距离来获得4个边界偏移。<br><img src="/images/LOMO/7.png" alt=""><br>　　SEM 的结构如图4所示，RoI变换层提取的共享特征图上的特征块，之后是两个卷积阶段（每个阶段由一个上采样层和两个3×3卷积层组成），然后使用一个带有6个输出通道的1×1卷积层，用于回归所有文本属性映射。SEM 的目标函数定义如下，其中 Ltr 和 Ltcl 使用<strong>dice-coefficient loss</strong>，Lborder 使用<strong>smooth L1 loss</strong>：<br><img src="/images/LOMO/8.png" alt=""><br>　　其中K表示保留IRM的文本四边形的数量，Ltr和Ltcl分别是文本区域和文本中心线的dice系数损失，Lborder是通过Smooth_L1损失计算。在实验中，权重λ1、λ2和λ3设定为0.01,0.01和1.0。</p><h4 id="文本多边形生成"><a href="#文本多边形生成" class="headerlink" title="文本多边形生成"></a>文本多边形生成</h4><p>　　通过文本多边形生成策略来重建任意形状的文本实例表示。文本多边形生成策略包括三步：<br>（1）<strong>center line sampling</strong>： 在预测的文本中心线图上从左到右以等距离间隔采样n个点。<br>（2）<strong>border points generation</strong>： 基于采样中心线点，考虑同一位置由4个边界偏移图提供的信息，确定相应的边界点。通过顺时针连接所有的边界点，获得完整的文本多边形表示。<br>（3）<strong>polygon scoring</strong>: 计算多边形内的文本区域响应的平均值，作为新的 confidence score。</p><h4 id="训练和推理"><a href="#训练和推理" class="headerlink" title="训练和推理"></a>训练和推理</h4><p>　　整个的损失函数表示为:<br><img src="/images/LOMO/9.png" alt=""><br>　　其中Ldr，Lirm和Lsem分别代表DR，IRM和SEM的损失。权重γ1，γ2和γ3在三个模块之间折衷，并且在实验中都设置为1.0。<br><strong>Training</strong>：训练过程分为两个阶段：<strong>warming-up（预热）</strong> 和 <strong>fine-tuning（微调）</strong>.<br>1）在 warming-up 阶段，使用合成数据集训练 DR 部分，迭代 10 epochs。通过这种方式，DR可以生成高召回的proposals，以涵盖实际数据中的大部分文本实例。<br>2）在 fine-tuning 阶段, 在真实数据集上 fine-tune 所有的三个分支，包括 ICDAR2015, ICDAR2017-RCTW, SCUT-CTW1500, Total-Text 和 ICDAR2017-MLT，迭代大约 10 epochs。IRM和SEM分支都使用由DR分支生成的相同提议。非极大值抑制（NMS）用于保留前K个提议。由于DR表现不佳，这将影响IRM和SEM分支的融合，在实践中用随机扰乱的GT文本四边形替换50％的前K个proposals。注意，IRM仅在训练期间进行一次细化。<br><strong>Inference</strong>：<br>1）DR 生成四边形的得分图和几何图, 然后用 NMS 生成初步的文本建议。<br>2）文本建议和共享特征图全部输入到 IRM 中改善多次。<br>3）精确的四边形和共享特征图输入到 SEM 中，生成精确的文本多边形和置信度得分。<br>4）阈值 s 用于移除低置信度的多边形。在实验中将s设置为0.1。</p><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>ICDAR 2015</strong><br>　　包含<strong>1000张自然场景图像用于训练和500张用于测试</strong>。真值是以<strong>单词级别的四边形（word-level quadrangle）</strong>标注的。<br><strong>ICDAR2017-MLT</strong><br>　　一个<strong>大规模的多语言（large scale multi-lingual）</strong>文本数据集，包括<strong>7200张训练图像、1800张验证图像和9000张测试图像</strong>。这个数据集包含来自于9种语言的场景文本图像。文本区域是以<strong>有四个顶点的四边形（4 vertices of the quadrangle）</strong>标注的。<br><strong>ICDAR2017-RCTW</strong><br>　　它包含<strong>8034张训练图像和4229张测试图像</strong>，这些图像上的场景文本是以中文或者英文打印的。<strong>多方向的单词和文本行（Multi-oriented words and text lines）</strong>是以<strong>四边形（quadrangles）</strong>标注的。<br><strong>SCUT-CTW1500</strong><br>　　包含<strong>1000张训练图像和500张测试图像</strong>。文本实例以<strong>有14个顶点的多边形</strong>标注。<br><strong>Total-Text</strong><br>　　一个<strong>curved text（曲线文本）</strong>基准数据集，包括<strong>1255张训练图像和300张测试图像</strong>。标注是<strong>单词级别（word-level）</strong>的。</p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>　　对于所有的数据集，随机裁剪文本区域并将它们统一缩放到512x512。被裁剪的图像区域将会按照四个方向（0◦、90◦、180◦、270◦）随机旋转。<br><img src="/images/LOMO/10.png" alt=""><br><img src="/images/LOMO/11.png" alt=""><br><img src="/images/LOMO/12.png" alt=""><br><img src="/images/LOMO/13.png" alt=""><br><img src="/images/LOMO/14.png" alt=""></p><h4 id="结论和未来的工作"><a href="#结论和未来的工作" class="headerlink" title="结论和未来的工作"></a>结论和未来的工作</h4><p>　　这篇论文主要解决长文本和弯曲文本的检测问题，LOMO由 DR、IRM and SEM 三个模块组成。DR初步产生文本建议。IRM迭代式的调整DR生成的文本建议。SEM重建不规则文本的精确表示。</p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> 曲线文本 </tag>
            
            <tag> LOMO </tag>
            
            <tag> 百度 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习与深度学习常见问题总结（下）</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="1、为什么随机森林能降低方差？"><a href="#1、为什么随机森林能降低方差？" class="headerlink" title="1、为什么随机森林能降低方差？"></a>1、为什么随机森林能降低方差？</h4><p>随机森林的预测输出值是多棵决策树的均值，如果有n个独立同分布的随机变量xi，它们的方差都为σ^2，则它们的均值的方差为：<br><img src="/images/深度学习2.png" alt=""></p><h4 id="2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？"><a href="#2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？" class="headerlink" title="2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？"></a>2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？</h4><p>对于一个一般的问题，KKT条件是取得极值的必要条件而不是充分条件。对于凸优化问题，则是充分条件，SVM是凸优化问题。</p><h4 id="3、解释维数灾难的概念。"><a href="#3、解释维数灾难的概念。" class="headerlink" title="3、解释维数灾难的概念。"></a>3、解释维数灾难的概念。</h4><p>当特征向量数值很少时，增加特征，可以提高算法的精度，但当特征向量的维数增加到一定数量之后，再增加特征，算法的精度反而会下降。</p><h4 id="4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？"><a href="#4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？" class="headerlink" title="4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？"></a>4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？</h4><p>如果用欧氏距离，不是凸函数，而用交叉熵则是凸函数。</p><h4 id="5、解释hinge-loss损失函数。"><a href="#5、解释hinge-loss损失函数。" class="headerlink" title="5、解释hinge loss损失函数。"></a>5、解释hinge loss损失函数。</h4><p>如果样本没有违反不等式约束，则损失为0；如果违反约束，则有一个正的损失值。</p><h4 id="6、解释GBDT的核心思想。"><a href="#6、解释GBDT的核心思想。" class="headerlink" title="6、解释GBDT的核心思想。"></a>6、解释GBDT的核心思想。</h4><p>用加法模拟，更准确的说，是多棵决策树来拟合一个目标函数。每一棵决策树拟合的是之前迭代得到的模型的残差。求解的时候，对目标函数使用了一阶泰勒展开，用梯度下降法来训练决策树。</p><h4 id="7、解释XGBoost的核心思想。"><a href="#7、解释XGBoost的核心思想。" class="headerlink" title="7、解释XGBoost的核心思想。"></a>7、解释XGBoost的核心思想。</h4><p>在GBDT的基础上，目标函数增加了正则化项，并且在求解时做了二阶泰勒展开。</p><h4 id="8、解释DQN中的经验回放机制，为什么需要这种机制？"><a href="#8、解释DQN中的经验回放机制，为什么需要这种机制？" class="headerlink" title="8、解释DQN中的经验回放机制，为什么需要这种机制？"></a>8、解释DQN中的经验回放机制，为什么需要这种机制？</h4><p>将执行动作后得到的状态转移构造的样本存储在一个列表中，然后从中随机抽样，来训练Q网络。为了解决训练样本之间的相关性，以及训练样本分布变化的问题。</p><h4 id="9、什么是反卷积？"><a href="#9、什么是反卷积？" class="headerlink" title="9、什么是反卷积？"></a>9、什么是反卷积？</h4><p>反卷积也称为转置卷积，如果用矩阵乘法实现卷积操作，将卷积核平铺为矩阵，则转置卷积在正向计算时左乘这个矩阵的转置W^T，在反向传播时左乘W，与卷积操作刚好相反，需要注意的是，反卷积不是卷积的逆运算。</p><h4 id="10、反卷积有哪些用途？"><a href="#10、反卷积有哪些用途？" class="headerlink" title="10、反卷积有哪些用途？"></a>10、反卷积有哪些用途？</h4><p>实现上采样；近似重构输入图像，卷积层可视化。</p><h4 id="11、PCA（主成分分析）优化的目标是什么？"><a href="#11、PCA（主成分分析）优化的目标是什么？" class="headerlink" title="11、PCA（主成分分析）优化的目标是什么？"></a>11、PCA（主成分分析）优化的目标是什么？</h4><p>最小化重构误差/最大化投影后的方差。</p><h4 id="12、LDA（线性判别分析）优化的目标是什么？"><a href="#12、LDA（线性判别分析）优化的目标是什么？" class="headerlink" title="12、LDA（线性判别分析）优化的目标是什么？"></a>12、LDA（线性判别分析）优化的目标是什么？</h4><p>最大化类间差异与类内差异的比值。</p><h4 id="13、解释神经网络的万能逼近定理。"><a href="#13、解释神经网络的万能逼近定理。" class="headerlink" title="13、解释神经网络的万能逼近定理。"></a>13、解释神经网络的万能逼近定理。</h4><p>只要激活函数选择得当，神经元的数值足够，至少有一个隐含层的神经网络可以逼近闭区间上任意一个连续函数到任意指定的精度。</p><h4 id="14、softmax回归训练时的目标函数是凸函数吗？"><a href="#14、softmax回归训练时的目标函数是凸函数吗？" class="headerlink" title="14、softmax回归训练时的目标函数是凸函数吗？"></a>14、softmax回归训练时的目标函数是凸函数吗？</h4><p>是，但有不止一个全局最优解。</p><h4 id="15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？"><a href="#15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？" class="headerlink" title="15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？"></a>15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？</h4><p>原问题不容易求解，含有大量的不易处理的不等式约束。原问题满足Slater条件，强对偶成立，因此原问题与对偶问题等价。</p><h4 id="16、神经网络是生成模型还是判别模型？"><a href="#16、神经网络是生成模型还是判别模型？" class="headerlink" title="16、神经网络是生成模型还是判别模型？"></a>16、神经网络是生成模型还是判别模型？</h4><p>判别模型，直接输出类别标签，或者输出类后验概率p(y|x)。</p><h4 id="17、logistic回归是生成模型还是判别模型？"><a href="#17、logistic回归是生成模型还是判别模型？" class="headerlink" title="17、logistic回归是生成模型还是判别模型？"></a>17、logistic回归是生成模型还是判别模型？</h4><p>判别模型，直接输出类后验概率p(y|x)，没有对类条件概率p(x|y)或者联合概率p(x, y)建模。</p><h4 id="18、Batch-Normalization-和-Group-Normalization有何区别？"><a href="#18、Batch-Normalization-和-Group-Normalization有何区别？" class="headerlink" title="18、Batch Normalization 和 Group Normalization有何区别？"></a>18、Batch Normalization 和 Group Normalization有何区别？</h4><p>BN是在batch这个维度上进行归一化，GN是计算channel方向每个group的均值和方差。</p><h4 id="19、GAN中模型坍塌（model-collapse）是指什么？"><a href="#19、GAN中模型坍塌（model-collapse）是指什么？" class="headerlink" title="19、GAN中模型坍塌（model collapse）是指什么？"></a>19、GAN中模型坍塌（model collapse）是指什么？</h4><p>模型坍塌，即产生的样本单一，没有了多样性。</p><h4 id="20、目前GAN训练中存在的主要问题是什么？"><a href="#20、目前GAN训练中存在的主要问题是什么？" class="headerlink" title="20、目前GAN训练中存在的主要问题是什么？"></a>20、目前GAN训练中存在的主要问题是什么？</h4><p>（1）训练不易收敛；<br>（2）模型坍塌。</p><h4 id="21、Shufflenet为什么效果会好？"><a href="#21、Shufflenet为什么效果会好？" class="headerlink" title="21、Shufflenet为什么效果会好？"></a>21、Shufflenet为什么效果会好？</h4><p>通过引入“通道重排”增加了组与组之间信息交换。</p><h4 id="22、模型压缩的主要方法有哪些？"><a href="#22、模型压缩的主要方法有哪些？" class="headerlink" title="22、模型压缩的主要方法有哪些？"></a>22、模型压缩的主要方法有哪些？</h4><p>（1）从模型结构上优化：模型剪枝、模型蒸馏、automl直接学习出简单的结构。<br>（2）从模型参数上量化：将FP32的数值精度量化到FP16、INT8、二值网络、三值网络等。</p><h4 id="23、目标检测中IOU是如何计算的？"><a href="#23、目标检测中IOU是如何计算的？" class="headerlink" title="23、目标检测中IOU是如何计算的？"></a>23、目标检测中IOU是如何计算的？</h4><p>检测结果与 Ground Truth 的交集比上它们的并集，即为检测的准确率 IoU。<br><img src="/images/深度学习3.png" alt=""></p><h4 id="24、给定0-1矩阵，如何求连通域？"><a href="#24、给定0-1矩阵，如何求连通域？" class="headerlink" title="24、给定0-1矩阵，如何求连通域？"></a>24、给定0-1矩阵，如何求连通域？</h4><p>可采用广度优先搜索。</p><h4 id="25、OCR任务中文本序列识别的主流方法是什么？"><a href="#25、OCR任务中文本序列识别的主流方法是什么？" class="headerlink" title="25、OCR任务中文本序列识别的主流方法是什么？"></a>25、OCR任务中文本序列识别的主流方法是什么？</h4><p>RNN+CTC。</p><h4 id="26、在神经网络体系结构中，哪些会有权重共享？"><a href="#26、在神经网络体系结构中，哪些会有权重共享？" class="headerlink" title="26、在神经网络体系结构中，哪些会有权重共享？"></a>26、在神经网络体系结构中，哪些会有权重共享？</h4><p>（1）卷积神经网络CNN<br>（2）递归神经网络RNN</p><h4 id="27、一个典型人脸识别系统的识别流程？"><a href="#27、一个典型人脸识别系统的识别流程？" class="headerlink" title="27、一个典型人脸识别系统的识别流程？"></a>27、一个典型人脸识别系统的识别流程？</h4><p>人脸检测–&gt;人脸对齐–&gt;人脸特征提取–&gt;人脸特征比对。</p><h4 id="28、平面内有两个矩形，如何快速计算它们的IOU？"><a href="#28、平面内有两个矩形，如何快速计算它们的IOU？" class="headerlink" title="28、平面内有两个矩形，如何快速计算它们的IOU？"></a>28、平面内有两个矩形，如何快速计算它们的IOU？</h4><p><img src="/images/深度学习4.png" alt=""></p><h4 id="29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？"><a href="#29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？" class="headerlink" title="29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？"></a>29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？</h4><p>提示：内存/显存占用；模型收敛速度等。</p><h4 id="30、HMM和CRF的区别？"><a href="#30、HMM和CRF的区别？" class="headerlink" title="30、HMM和CRF的区别？"></a>30、HMM和CRF的区别？</h4><p>前者描述的是 P(X,Y)=P(X|Y)*P(Y)，是 generative model；后者描述的是 P(Y|X)，是 discriminative model。前者要加入对状态概率分布的先验知识，而后者完全是 data driven。</p><h4 id="31、深度学习中为什么不用二阶导去优化？"><a href="#31、深度学习中为什么不用二阶导去优化？" class="headerlink" title="31、深度学习中为什么不用二阶导去优化？"></a>31、深度学习中为什么不用二阶导去优化？</h4><p>Hessian矩阵是n*n，在高维情况下这个矩阵非常大，计算和存储都是问题。</p><h4 id="32、深度机器学习中的mini-batch的大小对学习效果有何影响？"><a href="#32、深度机器学习中的mini-batch的大小对学习效果有何影响？" class="headerlink" title="32、深度机器学习中的mini-batch的大小对学习效果有何影响？"></a>32、深度机器学习中的mini-batch的大小对学习效果有何影响？</h4><p>mini-batch太小会导致收敛变慢，太大容易陷入sharp minima，泛化性不好。</p><h4 id="33、线性回归对于数据的假设是怎样的？"><a href="#33、线性回归对于数据的假设是怎样的？" class="headerlink" title="33、线性回归对于数据的假设是怎样的？"></a>33、线性回归对于数据的假设是怎样的？</h4><p><a href="http://en.wikipedia.org/wiki/Linear_regression" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Linear_regression</a><br>（1）线性，y是多个自变量x之间的线性组合；<br>（2）同方差性，不同的因变量x的方差都是相同的；<br>（3）弱外生性，假设用来预测的自变量x是没有测量误差的；<br>（4）预测变量之中没有多重共线性。</p><h4 id="34、什么是共线性，跟过拟合有啥关联"><a href="#34、什么是共线性，跟过拟合有啥关联" class="headerlink" title="34、什么是共线性，跟过拟合有啥关联?"></a>34、什么是共线性，跟过拟合有啥关联?</h4><p>共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。<br>结果：共线性会造成冗余，导致过拟合。<br>解决方法：排除变量的相关性／加入权重正则。</p><h4 id="35、Bias和Variance的区别？"><a href="#35、Bias和Variance的区别？" class="headerlink" title="35、Bias和Variance的区别？"></a>35、Bias和Variance的区别？</h4><p><strong>Bias</strong>度量了学习算法的期望预测与真实结果的偏离程度，即刻画了算法本身的拟合能力。<br><strong>Variance</strong>度量了同样大小的训练集的变动所导致的学习性能变化，即刻画了数据扰动所造成的影响。</p><h4 id="36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？"><a href="#36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？" class="headerlink" title="36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？"></a>36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？</h4><p>如果训练样本的量很大，训练得到的模型中支持向量的数量太多，在每次做预测时，高斯核需要计算待预测样本与每个支持向量的内积，然后做核函数变换，这会非常耗时；而线性核只需计算 W^T * X + b。</p><h4 id="37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？"><a href="#37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？" class="headerlink" title="37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？"></a>37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？</h4><p>为了保证这个函数是一个概率密度函数，即积分值为1。</p><h4 id="38、介绍beam-search算法的原理。"><a href="#38、介绍beam-search算法的原理。" class="headerlink" title="38、介绍beam search算法的原理。"></a>38、介绍beam search算法的原理。</h4><p>这是一种解码算法，每次选择概率最大的几个解作为候选解，逐步扩展。</p><h4 id="39、介绍seq2seq的原理。"><a href="#39、介绍seq2seq的原理。" class="headerlink" title="39、介绍seq2seq的原理。"></a>39、介绍seq2seq的原理。</h4><p>整个系统由两个RNN组成，一个充当编码器，一个充当解码器；编码器依次接收输入的序列数据，当最后一个数据点输入之后，将循环层的状态向量作为语义向量，与解码器网络的输入向量一起，送入解码器中进行预测。</p><h4 id="40、介绍CTC的原理。"><a href="#40、介绍CTC的原理。" class="headerlink" title="40、介绍CTC的原理。"></a>40、介绍CTC的原理。</h4><p>CTC通过引入空白符号，以及消除连续的相同符号，将RNN原始的输出序列映射为最终的目标序列。可以解决对未对齐的序列数据进行预测的问题，如语音识别。</p><h4 id="41、介绍广义加法模型的原理。"><a href="#41、介绍广义加法模型的原理。" class="headerlink" title="41、介绍广义加法模型的原理。"></a>41、介绍广义加法模型的原理。</h4><p>广义加法模型用多个基函数的和来拟合目标函数，训练的时候，依次确定每个基函数。</p><h4 id="42、为什么很多时候用正态分布来对随机变量建模？"><a href="#42、为什么很多时候用正态分布来对随机变量建模？" class="headerlink" title="42、为什么很多时候用正态分布来对随机变量建模？"></a>42、为什么很多时候用正态分布来对随机变量建模？</h4><p>现实世界中很多变量都服从或近似服从正态分布。中心极限定理指出，抽样得到的多个独立同分布的随机变量样本，当样本数趋向于正无穷时，它们的和服从正态分布。</p>]]></content>
      
      <categories>
          
          <category> 机器学习与深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 旷视科技提出PSENet文本检测算法</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BAPSENet%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BAPSENet%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/PSENet/1.png" alt=""><br><strong>Shape Robust Text Detection with Progressive Scale Expansion Network</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text Face++<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1903.12473" target="_blank" rel="noopener">https://arxiv.org/abs/1903.12473</a><br><strong>reference</strong>: Wang W, Xie E, Li X, et al. Shape Robust Text Detection with Progressive Scale Expansion Network[J]. arXiv preprint arXiv:1903.12473, 2019.<br><strong>Github(tensorflow)</strong>: <a href="https://github.com/whai362/PSENet" target="_blank" rel="noopener">https://github.com/whai362/PSENet</a><br><strong>Github(pytorch)</strong>: <a href="https://github.com/WenmuZhou/PSENet.pytorch" target="_blank" rel="noopener">https://github.com/WenmuZhou/PSENet.pytorch</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>　　PSENet 分好几个版本，最新的一个是19年的CVPR，这是一篇南京大学和face++合作的文章，19年出现了很多不规则文本检测算法，TextMountain、Textfield等等。</p><h4 id="1、论文创新点"><a href="#1、论文创新点" class="headerlink" title="1、论文创新点"></a>1、论文创新点</h4><ol><li>Propose a novel kernel-based framework, namely, <strong>Progressive Scale Expansion Network (PSENet)</strong></li><li>Adopt a progressive scale expansion algorithm based on <strong>Breadth-First-Search (BFS)</strong>:<br>1) Starting from the kernels with <strong>minimal scales</strong> (instances can be distinguished in this step).<br>2) <strong>Expanding their areas</strong> by involving more pixels in larger kernels gradually.<br>3) Finishing until the complete text instances (<strong>the largest kernels</strong>) are explored.</li></ol><p>　　这个文章主要做的创新点大概就是<strong>预测多个分割结果，分别是S1,S2,S3…Sn</strong>代表不同的等级面积的结果，S1最小，基本就是文本骨架，Sn最大，就是完整的文本实例。然后在后处理的过程中，先用<strong>最小的预测结果去区分文本，再逐步扩张成正常文本大小</strong>。<br><img src="/images/PSENet/2.png" alt=""></p><h4 id="2、算法主体"><a href="#2、算法主体" class="headerlink" title="2、算法主体"></a>2、算法主体</h4><p><img src="/images/PSENet/3.png" alt=""><br>　　We firstly get four 256 channels feature maps(<strong>i.e. P2, P3, P4, P5</strong>)from the backbone. To further combine the semantic features from low to high levels, we fuse the four feature maps to get <strong>feature map F with 1024 channels</strong> via the function C(·) as:<br><img src="/images/PSENet/4.png" alt=""><br>　　先backbone下采样得到<strong>四层的feature maps</strong>，再通过<strong>FPN</strong>对四层feature分别进行<strong>上采样2,4,8倍</strong>进行融合得到输出结果。<br>　　如上图所示，网络有三个分割结果，分别是S1,S2,S3.首先利用最小的kernel生成的<strong>S1来区分四个文本实例，然后再逐步扩张成S2和S3</strong>。</p><h4 id="3、label-generation"><a href="#3、label-generation" class="headerlink" title="3、label generation"></a>3、label generation</h4><p>　　产生不同尺寸的S1….Sn需要<strong>不同尺寸的labels</strong>。<br><img src="/images/PSENet/5.png" alt=""><br>　　不同尺寸的labels生成如上图所示，缩放比例可以用下面公式计算得出：<br><img src="/images/PSENet/6.png" alt=""><br>　　这个di表示的是缩小后mask边缘与正常mask边缘的距离，缩放比例rate ri可以由下面计算得出：<br><img src="/images/PSENet/7.png" alt=""><br>　　m是最小mask的比例，n在m到1之间的值，成线性增加。</p><h4 id="4、Loss-Function"><a href="#4、Loss-Function" class="headerlink" title="4、Loss Function"></a>4、Loss Function</h4><p>　　Loss 主要分为分类的<strong>text instance loss和shrunk losses</strong>，L是平衡这两个loss的参数。分类loss主要用了交叉熵和dice loss。<br><img src="/images/PSENet/8.png" alt=""><br>　　The dice coefficient <strong>D(Si, Gi)</strong> 被计算如下：<br><img src="/images/PSENet/9.png" alt=""><br>　　Ls被计算如下：<br><img src="/images/PSENet/10.png" alt=""></p><h4 id="5、Datasets"><a href="#5、Datasets" class="headerlink" title="5、Datasets"></a>5、Datasets</h4><p><strong>TotalText</strong><br>　　A newly-released dataset for curve text detection. <strong>Horizontal, multi-Oriented and curve text instances</strong> are contained in Total-Text. The benchmark consists of <strong>1255 training images and 300 testing images</strong>.</p><p><strong>CTW1500</strong><br>　　CTW1500 dataset mainly consisting of <strong>long curved text</strong>. It consists of <strong>1000 training images and 500 test images</strong>. Text instances are labelled by a polygon with 14 points which can describe the shape of an arbitrarily curve text.</p><p><strong>ICDAR 2015</strong><br>　　Icdar2015 is a commonly used dataset for text detection. It contains a total of <strong>1500 pictures</strong>, 1000 of which are used for training and the remaining are for testing. The text regions are annotated by 4 vertices of the quadrangle.</p><p><strong>ICDAR 2017 MLT</strong><br>　　ICDAR 2017 MIL is a large scale multi-lingual text dataset, which includes <strong>7200 training images, 1800 validation images and 9000 testing images</strong>. The dataset is composed of complete scene images which come from 9 languages.</p><h4 id="6、Experiment-Results"><a href="#6、Experiment-Results" class="headerlink" title="6、Experiment Results"></a>6、Experiment Results</h4><p><strong>Implementation Details</strong><br>　　All the networks are optimized by using stochastic gradient descent (SGD).The data augmentation for training data is listed as follows:<br>1) The images are rescaled with ratio {0.5, 1.0, 2.0, 3.0} randomly;<br>2) The images are horizontally flipped and rotated in the range [−10◦, 10◦] randomly;<br>3) 640 × 640 random samples are cropped from the transformed images.<br><img src="/images/PSENet/11.png" alt=""><br><img src="/images/PSENet/12.png" alt=""><br><img src="/images/PSENet/13.png" alt=""><br><img src="/images/PSENet/14.png" alt=""><br><img src="/images/PSENet/15.png" alt=""><br><img src="/images/PSENet/16.png" alt=""></p><h4 id="7、Conclusion-and-Future-work"><a href="#7、Conclusion-and-Future-work" class="headerlink" title="7、Conclusion and Future work"></a>7、Conclusion and Future work</h4><p>　　这个文章其实做的只是一件事情，就是<strong>用预测得到的小的mask区分文本，然后逐渐扩张形成正常大小的文本mask</strong>。</p><div class="row">    <embed src="/pdf/PSENet.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> 曲线文本 </tag>
            
            <tag> PSENet </tag>
            
            <tag> 旷视 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习与深度学习常见问题总结（上）</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="1、比较Boosting和Bagging的异同。"><a href="#1、比较Boosting和Bagging的异同。" class="headerlink" title="1、比较Boosting和Bagging的异同。"></a>1、比较Boosting和Bagging的异同。</h4><p>二者都是集成学习算法，都是将多个弱学习器组合成强学习器的方法。<br><strong>Bagging</strong>：从原始数据集中每一轮有放回地抽取训练集，训练得到k个弱学习器，将这k个弱学习器以投票的方式得到最终的分类结果。<br><strong>Boosting</strong>：每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重，训练得到k个弱分类器，他们都有各自的权重，通过加权组合的方式得到最终的分类结果。</p><h4 id="2、无监督学习中存在过拟合吗？"><a href="#2、无监督学习中存在过拟合吗？" class="headerlink" title="2、无监督学习中存在过拟合吗？"></a>2、无监督学习中存在过拟合吗？</h4><p>存在。我们可以使用无监督学习的某些指标或人为地去评估模型性能，以此来判断是否过拟合。</p><h4 id="3、什么是k折交叉验证？"><a href="#3、什么是k折交叉验证？" class="headerlink" title="3、什么是k折交叉验证？"></a>3、什么是k折交叉验证？</h4><p>将原始数据集划分为k个子集，将其中一个子集作为验证集，其余k-1个子集作为训练集，如此训练和验证一轮称为一次交叉验证。交叉验证重复k次，每个子集都做一次验证集，得到k个模型，加权平均k个模型的结果作为评估整体模型的依据。</p><h4 id="4、关于k折交叉验证，需要注意什么？"><a href="#4、关于k折交叉验证，需要注意什么？" class="headerlink" title="4、关于k折交叉验证，需要注意什么？"></a>4、关于k折交叉验证，需要注意什么？</h4><p>k越大，不一定效果越好，而且越大的k会加大训练时间；在选择k时，需要考虑最小化数据集之间的方差，比如对于2分类任务，采用2折交叉验证，即将原始数据集对半分，若此时训练集中都是A类别，验证集中都是B类别，则交叉验证效果会非常差。</p><h4 id="5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？"><a href="#5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？" class="headerlink" title="5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？"></a>5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？</h4><p>准确率 = <code>TP / (TP + FP)</code>，召回率 = <code>TP / (TP + FN)</code>，其中TP表示将正例正确分类为正例的数量，FP表示将负例错误分类为正例的数量，FN表示将正例错误分类为负例的数量。<br>准确率可以理解为在所有分类为正例的样品中，分类正确的样本所占比例；召回率可以理解为在所有原始数据集中的正例样品中，正确挑出的正例样本的比例。<br>因此若增大阈值t，更多不确定（分类概率较小）的样本将会被分为负例，剩余确定（分类概率较大）的样本所占比例将会增大（或不变），即正确率会增大（或不变）；若增大阈值t，则可能将部分不确定（分类概率较小）的正例样品误分类为负例，即召回率会减小（或不变）。</p><h4 id="6、以下关于神经网络的说法中，正确的是（-）？"><a href="#6、以下关于神经网络的说法中，正确的是（-）？" class="headerlink" title="6、以下关于神经网络的说法中，正确的是（ ）？"></a>6、以下关于神经网络的说法中，正确的是（ ）？</h4><p>A.增加网络层数，总能减小训练集错误率<br>B.减小网络层数，总能减小测试集错误率<br>C.增加网络层数，可能增加测试集错误率<br>答案：C。增加神经网络层数，确实可能提高模型的泛化性能，但不能绝对地说更深的网络能带来更小的错误率，还是要根据实际应用来判断，比如会导致过拟合等问题，因此只能选C。</p><h4 id="7、说明Lp范数间的区别。"><a href="#7、说明Lp范数间的区别。" class="headerlink" title="7、说明Lp范数间的区别。"></a>7、说明Lp范数间的区别。</h4><p><strong>L1范数</strong>：向量中各个元素绝对值之和<br><strong>L2范数</strong>：向量中各个元素平方和的开二次方根<br><strong>Lp范数</strong>：向量中各个元素绝对值的p次方和的开p次方根</p><h4 id="8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？"><a href="#8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？" class="headerlink" title="8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？"></a>8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？</h4><p>输入数据本身存在nan值，或者梯度爆炸了（可以降低学习率、或者设置梯度的阈值）。</p><h4 id="9、卷积神经网络CNN中池化层有什么作用？"><a href="#9、卷积神经网络CNN中池化层有什么作用？" class="headerlink" title="9、卷积神经网络CNN中池化层有什么作用？"></a>9、卷积神经网络CNN中池化层有什么作用？</h4><p>减小图像尺寸即数据降维，缓解过拟合，保持一定程度的旋转和平移不变性。</p><h4 id="10、请列举几种常见的激活函数。激活函数有什么作用？"><a href="#10、请列举几种常见的激活函数。激活函数有什么作用？" class="headerlink" title="10、请列举几种常见的激活函数。激活函数有什么作用？"></a>10、请列举几种常见的激活函数。激活函数有什么作用？</h4><p>sigmoid， relu，tanh。非线性化</p><h4 id="11、神经网络中Dropout的作用？具体是怎么实现的？"><a href="#11、神经网络中Dropout的作用？具体是怎么实现的？" class="headerlink" title="11、神经网络中Dropout的作用？具体是怎么实现的？"></a>11、神经网络中Dropout的作用？具体是怎么实现的？</h4><p>防止过拟合。每次训练，都对每个神经网络单元，按一定概率临时丢弃。</p><h4 id="12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？"><a href="#12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？" class="headerlink" title="12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？"></a>12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？</h4><p>很有可能是梯度消失了，它表示神经网络迭代更新时，有些权值不更新的现象。改变激活函数，改变权值的初始化等。</p><h4 id="13、如何解决不平衡数据集的分类问题？"><a href="#13、如何解决不平衡数据集的分类问题？" class="headerlink" title="13、如何解决不平衡数据集的分类问题？"></a>13、如何解决不平衡数据集的分类问题？</h4><p>可以扩充数据集，对数据重新采样，改变评价指标等。</p><h4 id="14、残差网络为什么能做到很深层？"><a href="#14、残差网络为什么能做到很深层？" class="headerlink" title="14、残差网络为什么能做到很深层？"></a>14、残差网络为什么能做到很深层？</h4><p>神经网络在反向传播过程中要不断地传播梯度，而当网络层数加深时，梯度在逐层传播过程中会逐渐衰减，导致无法对前面网络层的权重进行有效的调整。残差网络中， 加入了 short connections 为梯度带来了一个直接向前面层的传播通道，缓解了梯度的减小问题。</p><h4 id="15、相比sigmoid激活函数ReLU激活函数有什么优势？"><a href="#15、相比sigmoid激活函数ReLU激活函数有什么优势？" class="headerlink" title="15、相比sigmoid激活函数ReLU激活函数有什么优势？"></a>15、相比sigmoid激活函数ReLU激活函数有什么优势？</h4><p>（1） 防止梯度消失 （sigmoid的导数只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近于0）<br>（2） ReLU的输出具有稀疏性<br>（3） ReLU函数简单计算速度快 </p><h4 id="16、卷积神经网络中空洞卷积的作用是什么？"><a href="#16、卷积神经网络中空洞卷积的作用是什么？" class="headerlink" title="16、卷积神经网络中空洞卷积的作用是什么？"></a>16、卷积神经网络中空洞卷积的作用是什么？</h4><p>空洞卷积也叫扩张卷积，在保持参数个数不变的情况下增大了卷积核的感受野，同时它可以保证输出的特征映射（feature map）的大小保持不变。一个扩张率为2的3×3卷积核，感受野与5×5的卷积核相同，但参数数量仅为9个。</p><h4 id="17、解释下卷积神经网络中感受野的概念？"><a href="#17、解释下卷积神经网络中感受野的概念？" class="headerlink" title="17、解释下卷积神经网络中感受野的概念？"></a>17、解释下卷积神经网络中感受野的概念？</h4><p>在卷积神经网络中，感受野 (receptive field)的定义是：卷积神经网络每一层输出的特征图（feature map）上的像素点在原始图像上映射的区域大小。</p><h4 id="18、模型欠拟合什么情况下会出现？有什么解决方案？"><a href="#18、模型欠拟合什么情况下会出现？有什么解决方案？" class="headerlink" title="18、模型欠拟合什么情况下会出现？有什么解决方案？"></a>18、模型欠拟合什么情况下会出现？有什么解决方案？</h4><p>模型复杂度过低，不能很好的拟合所有的数据。<br>增加模型复杂度，如采用高阶模型（预测）或者引入更多特征（分类）等。</p><h4 id="19、适用于移动端部署的网络结构都有哪些？"><a href="#19、适用于移动端部署的网络结构都有哪些？" class="headerlink" title="19、适用于移动端部署的网络结构都有哪些？"></a>19、适用于移动端部署的网络结构都有哪些？</h4><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">Mobilenet</a><br><a href="https://arxiv.org/abs/1707.01083" target="_blank" rel="noopener">Shufflenet</a><br><a href="https://arxiv.org/abs/1610.02357" target="_blank" rel="noopener">Xception</a></p><h4 id="20、卷积神经网络中im2col是如何实现的？"><a href="#20、卷积神经网络中im2col是如何实现的？" class="headerlink" title="20、卷积神经网络中im2col是如何实现的？"></a>20、卷积神经网络中im2col是如何实现的？</h4><p>使用<code>im2col</code>的方法将划窗卷积转为两个大的矩阵相乘，见下图：<br><img src="/images/深度学习1.png" alt=""></p><h4 id="21、多任务学习中标签缺失如何处理？"><a href="#21、多任务学习中标签缺失如何处理？" class="headerlink" title="21、多任务学习中标签缺失如何处理？"></a>21、多任务学习中标签缺失如何处理？</h4><p>一般做法是将缺失的标签设置特殊标志，在计算梯度的时候忽略。</p><h4 id="22、梯度爆炸的解决方法？"><a href="#22、梯度爆炸的解决方法？" class="headerlink" title="22、梯度爆炸的解决方法？"></a>22、梯度爆炸的解决方法？</h4><p>针对梯度爆炸问题，解决方案是引入Gradient Clipping(梯度裁剪)。通过Gradient Clipping，将梯度约束在一个范围内，这样不会使得梯度过大。</p><h4 id="23、深度学习模型参数初始化都有哪些方法？"><a href="#23、深度学习模型参数初始化都有哪些方法？" class="headerlink" title="23、深度学习模型参数初始化都有哪些方法？"></a>23、深度学习模型参数初始化都有哪些方法？</h4><p>（1）Gaussian 满足mean=0，std=1的高斯分布x∼N(mean，std^2)<br>（2）Xavier 满足x∼U(−a,+a)的均匀分布，其中 a = sqrt(3/n)<br>（3）MSRA 满足x∼N(0,σ^2)的高斯分布，其中 σ = sqrt(2/n)<br>（4）Uniform 满足min=0,max=1的均匀分布。x∼U(min, max) 等等</p><h4 id="24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？"><a href="#24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？" class="headerlink" title="24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？"></a>24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？</h4><p>深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标是从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息。<br>目前在神经机器翻译(Neural Machine Translation)、图像理解(Image caption)等场景都有广泛应用。</p><h4 id="25、卷积神经网络为什么会具有平移等不变性？"><a href="#25、卷积神经网络为什么会具有平移等不变性？" class="headerlink" title="25、卷积神经网络为什么会具有平移等不变性？"></a>25、卷积神经网络为什么会具有平移等不变性？</h4><p>MaxPooling能保证卷积神经网络在一定范围内平移特征能得到同样的激励，具有平移不变性。</p><h4 id="26、神经网络参数共享-parameter-sharing-是指什么？"><a href="#26、神经网络参数共享-parameter-sharing-是指什么？" class="headerlink" title="26、神经网络参数共享(parameter sharing)是指什么？"></a>26、神经网络参数共享(parameter sharing)是指什么？</h4><p>所谓的权值共享就是说，用一个卷积核去卷积一张图，这张图每个位置是被同样数值的卷积核操作的，权重是一样的，也就是参数共享。</p><h4 id="27、如何提高小型网络的精度？"><a href="#27、如何提高小型网络的精度？" class="headerlink" title="27、如何提高小型网络的精度？"></a>27、如何提高小型网络的精度？</h4><p>（1）<a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">模型蒸馏技术</a><br>（2）<a href="https://arxiv.org/abs/1807.11626" target="_blank" rel="noopener">利用AutoML进行网络结构的优化，可将网络计算复杂度作为约束条件之一，得到更优的结构。</a></p><h4 id="28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？"><a href="#28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？" class="headerlink" title="28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？"></a>28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？</h4><p>在反向传播算法计算每一层的误差项的时候，需要乘以本层激活函数的导数值，如果导数值接近于0，则多次乘积之后误差项会趋向于0，而参数的梯度值通过误差项计算，这会导致参数的梯度值接近于0，无法用梯度下降法来有效的更新参数的值。<br>改进激活函数，选用更不容易饱和的函数，如ReLU函数。</p><h4 id="29、列举你所知道的神经网络中使用的损失函数。"><a href="#29、列举你所知道的神经网络中使用的损失函数。" class="headerlink" title="29、列举你所知道的神经网络中使用的损失函数。"></a>29、列举你所知道的神经网络中使用的损失函数。</h4><p>欧氏距离，交叉熵，对比损失，合页损失。</p><h4 id="30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？"><a href="#30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？" class="headerlink" title="30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？"></a>30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？</h4><p>交叉熵在一般情况下更容易收敛到一个更好的解。</p><h4 id="31、1x1卷积有什么用途？"><a href="#31、1x1卷积有什么用途？" class="headerlink" title="31、1x1卷积有什么用途？"></a>31、1x1卷积有什么用途？</h4><p>通道降维，保证卷积神经网络可以接受任何尺寸的输入数据。</p><h4 id="32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？"><a href="#32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？" class="headerlink" title="32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？"></a>32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？</h4><p>不能，每次迭代时目标函数不一样。</p><h4 id="33、梯度下降法，为什么需要设置一个学习率？"><a href="#33、梯度下降法，为什么需要设置一个学习率？" class="headerlink" title="33、梯度下降法，为什么需要设置一个学习率？"></a>33、梯度下降法，为什么需要设置一个学习率？</h4><p>使得迭代之后的值在上次值的邻域内，保证可以忽略泰勒展开中的二次及二次以上的项。</p><h4 id="34、解释梯度下降法中动量项的作用。"><a href="#34、解释梯度下降法中动量项的作用。" class="headerlink" title="34、解释梯度下降法中动量项的作用。"></a>34、解释梯度下降法中动量项的作用。</h4><p>利用之前迭代时的梯度值，减小震荡。</p><h4 id="35、为什么现在倾向于用小尺寸的卷积核？"><a href="#35、为什么现在倾向于用小尺寸的卷积核？" class="headerlink" title="35、为什么现在倾向于用小尺寸的卷积核？"></a>35、为什么现在倾向于用小尺寸的卷积核？</h4><p>用多个小卷积核串联可以有大卷积核同样的能力，而且参数更少，另外有更多次的激活函数作用，增强非线性。</p><h4 id="36、解释GoogleNet的Inception模块的原理。"><a href="#36、解释GoogleNet的Inception模块的原理。" class="headerlink" title="36、解释GoogleNet的Inception模块的原理。"></a>36、解释GoogleNet的Inception模块的原理。</h4><p>对输入图像用多个不同尺寸的卷积核、池化操作进行同时处理，然后将输出结果按照通道拼接起来。</p><h4 id="37、解释反卷积的原理和用途。"><a href="#37、解释反卷积的原理和用途。" class="headerlink" title="37、解释反卷积的原理和用途。"></a>37、解释反卷积的原理和用途。</h4><p>反卷积即转置卷积，正向传播时乘以卷积核的转置矩阵，反向传播时乘以卷积核矩阵。<br>由卷积输出结果近似重构输入数据，上采样。</p><h4 id="38、解释批量归一化的原理。"><a href="#38、解释批量归一化的原理。" class="headerlink" title="38、解释批量归一化的原理。"></a>38、解释批量归一化的原理。</h4><p>在数据送入神经网络的某一层进行处理之前，对数据做归一化。按照训练样本的批量进行处理，先减掉这批样本的均值，然后除以标准差，然后进行缩放和平移。缩放和平移参数同训练得到。预测时使用训练时确定的这些值来计算。</p><h4 id="39、解释SVM核函数的原理。"><a href="#39、解释SVM核函数的原理。" class="headerlink" title="39、解释SVM核函数的原理。"></a>39、解释SVM核函数的原理。</h4><p>核函数将数据映射到更高维的空间后处理，但不用做这种显式映射，而是先对两个样本向量做内积，然后用核函数映射。这等价于先进行映射，然后再做内积。</p><h4 id="40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？"><a href="#40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？" class="headerlink" title="40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？"></a>40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？</h4><p>过拟合指在训练集上表现的很好，但在测试集上表现很差，推广泛化能力差。<br>原因：训练样本的抽样误差，训练时拟合了这种误差。<br>方法：增加训练样本，尤其是样本的代表性；正则化。</p><h4 id="41、什么样的函数可以用作激活函数？"><a href="#41、什么样的函数可以用作激活函数？" class="headerlink" title="41、什么样的函数可以用作激活函数？"></a>41、什么样的函数可以用作激活函数？</h4><p>非线性，几乎处处可到，单调。</p><h4 id="42、什么是鞍点问题？"><a href="#42、什么是鞍点问题？" class="headerlink" title="42、什么是鞍点问题？"></a>42、什么是鞍点问题？</h4><p>梯度为0，Hessian矩阵不定的点，不是极值点。</p><h4 id="43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？"><a href="#43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？" class="headerlink" title="43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？"></a>43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？</h4><p>不收敛，收敛太慢，泛化能力差。调整网络结构，调整样本，调整学习率，调整参数初始化策略。</p><h4 id="44、SVM如何解决多分类问题？"><a href="#44、SVM如何解决多分类问题？" class="headerlink" title="44、SVM如何解决多分类问题？"></a>44、SVM如何解决多分类问题？</h4><p>多个二分类器组合。1对1方案，1对剩余方案，多类损失函数。</p><h4 id="45、列举你知道的聚类算法。"><a href="#45、列举你知道的聚类算法。" class="headerlink" title="45、列举你知道的聚类算法。"></a>45、列举你知道的聚类算法。</h4><p>层次聚类，k均值算法，DBSCAN算法，OPTICS算法，谱聚类。</p><h4 id="46、K均值算法中，初始类中心怎么确定？"><a href="#46、K均值算法中，初始类中心怎么确定？" class="headerlink" title="46、K均值算法中，初始类中心怎么确定？"></a>46、K均值算法中，初始类中心怎么确定？</h4><p>随机选择K个样本作为类中心；将样本随机划分成K个子集然后计算类中心。</p><h4 id="47、简述EM算法的原理。"><a href="#47、简述EM算法的原理。" class="headerlink" title="47、简述EM算法的原理。"></a>47、简述EM算法的原理。</h4><p>EM算法用于求解带有隐变量的最大似然估计问题。由于有隐变量的存在，无法直接用最大似然估计求得对数似然函数极大值的公式解。此时通过jensen不等式构造对数似然函数的下界函数，然后优化下界函数，再用估计出的参数值构造新的下界函数，反复迭代直至收敛到局部极小值点。</p>]]></content>
      
      <categories>
          
          <category> 机器学习与深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令大全</title>
      <link href="/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"/>
      <url>/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li><p>查看当前目录下的文件数量（不包含子目录中的文件）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查看当前目录下的文件数量（包含子目录中的文件） 注意：R，代表子目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查看当前目录下的文件夹目录个数（不包含子目录中的目录），如果需要查看子目录，加上R</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l|grep <span class="string">"^d"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查询当前路径下的指定前缀名的目录下的文件数量，如统计所有以”2018”开头的目录下的全部文件数量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR 2018\*/|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法-任务调度问题</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-E-任务调度问题"><a href="#Problem-E-任务调度问题" class="headerlink" title="Problem E.任务调度问题"></a>Problem E.任务调度问题</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>一个单位时间任务是恰好需要一个单位时间完成的任务。给定一个单位时间任务的有限集 S 。关于S 的一个时间表用于描述S 中单位时间任务的执行次序。时间表中第 1 个任务从时间 0 开始执行直至时间 1 结束，第 2 个任务从时间 1 开始执行至时间 2 结束，…，第n个任务从时间 n-1 开始执行直至时间 n 结束。具有截止时间和误时惩罚的单位时间任务时间表问题可描述如下：<br>(1) n 个单位时间任务的集合 S = {1,2,…,n}（n ≤ 500）；<br>(2) 任务i的截止时间 d[i], 1 ≤ i ≤ n, 1 ≤ d[i] ≤ n，即要求任务 i 在时间 d[i] 之前结束；<br>(3) 任务 i 的误时惩罚 1 ≤ w[i] ≤ 1000, 1 ≤ i ≤ n, 即任务 i 未在时间 d[i] 之前结束将招致 w[i] 的惩罚；若按时完成则无惩罚。<br>任务时间表问题要求确定 S 的一个时间表（最优时间表）使得总误时惩罚达到最小。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行是正整数 n ，表示任务数。接下来的 2 行中，每行有 n 个正整数，分别表示各任务的截止时间和误时惩罚。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>将计算出的最小总误时惩罚输出。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">7</span><br><span class="line">4 2 4 3 1 4 6</span><br><span class="line">70 60 50 40 30 20 10</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">50</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题目类似于活动安排问题。首先将所有任务按照误时惩罚从大到小排序，然后依次从左到右遍历每个任务，将其安排在离截止时间点最近的（包括截止时间点处）未安排任务的时间点处完成，若无法找到这个时间点，则这个任务无法按时完成，将其误时惩罚加到总误时惩罚中。这样得到的总误时惩罚是最小的。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int n, d[510], w[510], visit[510];</span><br><span class="line">int i, j;</span><br><span class="line">long long result;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    memset(visit, 0, sizeof(visit));</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; d[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; w[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt; n; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (w[j] &lt; w[j + 1]) &#123;</span><br><span class="line">                swap(d[j], d[j + 1]);</span><br><span class="line">                swap(w[j], w[j + 1]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        bool flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (j = d[i]; j &gt; 0; j--) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!visit[j]) &#123;</span><br><span class="line">                visit[j] = 1;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="built_in">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!flag) &#123;</span><br><span class="line">            result += w[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; result &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法-合并果子</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-B-合并果子"><a href="#Problem-B-合并果子" class="headerlink" title="Problem B.合并果子"></a>Problem B.合并果子</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个果园里，多多已经将所有的果子打了下来，而且按果子的不同种类分成了不同的堆。多多决定把所有的果子合成一堆。<br>每一次合并，多多可以把两堆果子合并到一起，消耗的体力等于两堆果子的重量之和。可以看出，所有的果子经过n-1次合并之后，就只剩下一堆了。多多在合并果子时总共消耗的体力等于每次合并所耗体力之和。<br>因为还要花大力气把这些果子搬回家，所以多多在合并果子时要尽可能地节省体力。假定每个果子重量都为1，并且已知果子的种类数和每种果子的数目，你的任务是设计出合并的次序方案，使多多耗费的体力最少，并输出这个最小的体力耗费值。<br>例如有3种果子，数目依次为1，2，9。可以先将1、2堆合并，新堆数目为3，耗费体力为3。接着，将新堆与原先的第三堆合并，又得到新的堆，数目为12，耗费体力为12。所以多多总共耗费体力=3+12=15。可以证明15为最小的体力耗费值。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>输入包括两行，第一行是一个整数n(1 &lt;＝ n &lt; 10^4)，表示果子的种类数。第二行包含 n 个整数，用空格分隔，第 i 个整数ai(1 &lt;＝ ai &lt; 2 * 10^4)是第 i 种果子的数目。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>输出包括一行，这一行只包含一个整数，也就是最小的体力耗费值。输入数据保证这个值小于 2^31 。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3</span><br><span class="line">1 2 9</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题类似于哈夫曼编码树。首先用一个优先队列存储每种果子的数目，定义比较函数为从大到小排序。然后从队列中取出数目最少的两种果子，合并到一起，并将合并后的结果重新放入优先队列中，同时体力耗费增加相应的值。依此类推，直到将所有种类的果子合并成一堆。这样所得到的体力耗费值是最小的。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;queue&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">long long int n, a, temp, result;</span><br><span class="line">priority_queue&lt;long long int, vector&lt;long long int&gt;, greater&lt;long long int&gt;&gt; fruits;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; a;</span><br><span class="line">        fruits.push(a);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (fruits.size() &gt; 1) &#123;</span><br><span class="line">        temp = 0;</span><br><span class="line">        <span class="keyword">for</span> (i = 0; i &lt; 2; i++) &#123;</span><br><span class="line">            temp += fruits.top();</span><br><span class="line">            fruits.pop();</span><br><span class="line">        &#125;</span><br><span class="line">        fruits.push(temp);</span><br><span class="line">        result += temp;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; result &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>最大稳定极值区域MSER-Maximally Stable Extrernal Regions</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E6%9C%80%E5%A4%A7%E7%A8%B3%E5%AE%9A%E6%9E%81%E5%80%BC%E5%8C%BA%E5%9F%9FMSER-Maximally-Stable-Extrernal-Regions/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E6%9C%80%E5%A4%A7%E7%A8%B3%E5%AE%9A%E6%9E%81%E5%80%BC%E5%8C%BA%E5%9F%9FMSER-Maximally-Stable-Extrernal-Regions/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>MSER基于分水岭的概念：对图像进行二值化，二值化阈值取[0, 255]，这样二值化图像就经历一个从全黑到全白的过程（就像水位不断上升的俯瞰图）。在这个过程中，有些连通区域面积随阈值上升的变化很小，这种区域就叫MSER。<br><img src="/images/mser.png" alt=""><br>其中Qi表示第i个连通区域的面积，Δ表示微小的阈值变化（注水），当vi小于给定阈值时认为该区域为MSER。<br>显然，这样检测得到的MSER内部灰度值是小于边界的，想象一副黑色背景白色区域的图片，显然这个区域是检测不到的。因此对原图进行一次MSER检测后需要将其反转，再做一次MSER检测，两次操作又称MSER+和MSER-。</p><h2 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">im = cv2.imread(<span class="string">'./source.jpg'</span>)</span><br><span class="line">gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">mser = cv2.MSER_create(_min_area=300)</span><br><span class="line">regions, boxes = mser.detectRegions(gray)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">    x, y, w, h = box</span><br><span class="line">    cv2.rectangle(im, (x, y),(x + w, y + h), (255, 0, 0), 2)</span><br><span class="line"></span><br><span class="line">cv2.imwrite(<span class="string">"./mser.jpg"</span>, im)</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MSER </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法_最小差距</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%9C%80%E5%B0%8F%E5%B7%AE%E8%B7%9D/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%9C%80%E5%B0%8F%E5%B7%AE%E8%B7%9D/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-A-最小差距"><a href="#Problem-A-最小差距" class="headerlink" title="Problem A. 最小差距"></a>Problem A. 最小差距</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一些不同的一位数字，你可以从这些数字中选择若干个，并将它们按一定顺序排列，组成一个整数，把剩下的数字按一定顺序排列，组成另一个整数。组成的整数不能以0开头（除非这个整数只有1位）。<br>例如，给定6个数字，0,1,2,4,6,7，你可以用它们组成一对数10和2467，当然，还可以组成其他的很多对数，比如210和764，204和176。这些对数中两个数差的绝对值最小的是204和176，为28。<br>给定N个不同的0-9之间的数字，请你求出用这些数字组成的每对数中，差的绝对值最小的一对（或多对）数的绝对值是多少？</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行包括一个数 T （T ≤ 1000），为测试数据的组数。<br>每组数据包括两行，第一行为一个数 N （2 ≤ N ≤ 10），表示数字的个数。下面一行为 N 个不同的一位数字。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>T 行，每行一个数，表示第 i 个数据的答案。即最小的差的绝对值。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2</span><br><span class="line">6</span><br><span class="line">0 1 2 4 6 7</span><br><span class="line">4</span><br><span class="line">1 6 3 4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">28</span><br><span class="line">5</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>首先将所有数字从小到大排序，接着这道题可以分三种情况考虑：<br>（1）只有两个数的情况：直接两数相减取绝对值即可。<br>（2）奇数个数的情况：首先保证第一个数字非0，如果为0，就将第一个数与第二个数交换位置，然后从左往右连续取<code>n/2+1</code>个数组成第一个整数，最后从右往左连续取<code>n/2</code>个数，即剩下的所有数组成另一个整数。这样所求得的一对整数的差的绝对值最小。<br>（3）偶数个数的情况：从左往右依次枚举，首先保证第一个数非0，如果为0，就从下一个数开始枚举；取第<code>k</code>个数作为第一个整数的第一个数字，取第<code>k+1</code>个数作为第二个整数的第一个数字；然后，对于剩下的数字，从右往左连续取<code>n/2-1</code>个数加入第一个整数中，从左往右连续取<code>n/2-1</code>个数加入第二个整数中；最后，取差的绝对值最小的一对整数。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int t, n, d[20], num1, num2;</span><br><span class="line">int i, j, k, l, r;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    scanf(<span class="string">"%d"</span>, &amp;t);</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; t; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;n);</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt;= n; j++) &#123;</span><br><span class="line">            scanf(<span class="string">"%d"</span>, &amp;d[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        sort(d + 1, d + n + 1);</span><br><span class="line">        <span class="keyword">if</span> (n == 2) &#123; // 两个数的情况</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, abs(d[2] - d[1]));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (n % 2 == 1) &#123; // 奇数个数的情况</span><br><span class="line">            <span class="keyword">if</span> (d[1] == 0) &#123;</span><br><span class="line">                swap(d[1], d[2]);</span><br><span class="line">            &#125;</span><br><span class="line">            num1 = 0, num2 = 0;</span><br><span class="line">            // 前n/2+1个数从左往右组成第一个整数</span><br><span class="line">            <span class="keyword">for</span> (j = 1; j &lt;= n / 2 + 1; j++) &#123;</span><br><span class="line">                num1 = num1 * 10 + d[j];</span><br><span class="line">            &#125;</span><br><span class="line">            // 后n/2个数从右往左组成第二个整数</span><br><span class="line">            <span class="keyword">for</span> (j = n; j &gt;= n / 2 + 2; j--) &#123;</span><br><span class="line">                num2 = num2 * 10 + d[j];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, abs(num1 - num2));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; // 偶数个数的情况</span><br><span class="line">            int result = 0x7fffffff;</span><br><span class="line">            // 枚举，取第k个数加入第一个整数中，取第k+1个数加入第二个整数中</span><br><span class="line">            <span class="keyword">for</span> (j = 1; j &lt; n; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (d[j] == 0) &#123;</span><br><span class="line">                    <span class="built_in">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                num1 = d[j], num2 = d[j + 1];</span><br><span class="line">                // 从右往左遍历n/2-1个数加入第一个整数中</span><br><span class="line">                // 从左往右遍历n/2-1个数加入第二个整数中</span><br><span class="line">                l = 1, r = n;</span><br><span class="line">                <span class="keyword">for</span> (k = 0; k &lt; n / 2 - 1; k++) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (l == j) l++;</span><br><span class="line">                    <span class="keyword">if</span> (l == j + 1) l++;</span><br><span class="line">                    <span class="keyword">if</span> (r == j + 1) r--;</span><br><span class="line">                    <span class="keyword">if</span> (r == j) r--;</span><br><span class="line">                    num1 = num1 * 10 + d[r];</span><br><span class="line">                    num2 = num2 * 10 + d[l];</span><br><span class="line">                    l++, r--;</span><br><span class="line">                &#125;</span><br><span class="line">                // 取差最小的值</span><br><span class="line">                result = min(result, abs(num1 - num2));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法_旅行</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%97%85%E8%A1%8C/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%97%85%E8%A1%8C/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-D-旅行"><a href="#Problem-D-旅行" class="headerlink" title="Problem D. 旅行"></a>Problem D. 旅行</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>某趟列车的最大载客容量为V人，沿途共有n个停靠站，其中始发站为第1站，终点站为第n站。<br>在第1站至第n-1站之间，共有m个团队申请购票搭乘，若规定：<br>（1）对于某个团队的购票申请，要么全部满足，要么全部拒绝，即不允许只满足部分。（2）每个乘客的搭乘费用为其所乘站数。<br>问：应如何选择这些购票申请，能使该趟列车获得最大的搭乘费用？<br>其中，每个团队的购票申请格式是以空格分隔的三个整数：a b t，即表示有t个人需要从第a站点乘至第b站点（注：每个团队的所有人员都必须同时在a站上车，且必须同时在后面的b站下车）。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>输入数据有若干行。<br>第 1 行只有三个整数 n，m，v，分别表示站点数、申请数、列车的最大载客容量。这三个整数之间都以一个空格分隔。<br>第 2 行至第 m+1 行，每行有三个整数，中间都以一个空格分隔。其中第 k+1 行的三个整数 a，b，t 表示第 k 个申请，含义为：有 t 个人需要从第 a 站乘至第 b 站。<br>其中：1 ≤ n ≤ 10；1 ≤ m ≤ 18</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>输出数据只有一行，该行只有一个整数，为该列车能获得的最大搭乘费用。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3  3  5</span><br><span class="line">1  2  2</span><br><span class="line">2  3  5</span><br><span class="line">1  3  4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题与0-1背包问题类似。直接枚举所有可能的方案数，对于每一个团队，只有两个选择，搭乘与不搭乘，可以采用二进制0与1枚举的方式。由于团队申请数目<code>m</code>最多只有<code>18</code>个，所以最多有<code>2^18</code>种方案。对于每一种方案，统计每一站车上的总人数，如果某一站车上总人数超过了列车的最大载客容量<code>v</code>，那么此方案不可行；否则，比较搭乘费用，取最大的搭乘费用即可。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int n, m, v, a[20], b[20], t[20], num[25];</span><br><span class="line">long long cost = 0, temp;</span><br><span class="line">bool flag;</span><br><span class="line">int i, j;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m &gt;&gt; v;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; m; i++) &#123;</span><br><span class="line">        cin &gt;&gt; a[i] &gt;&gt; b[i] &gt;&gt; t[i];</span><br><span class="line">    &#125;</span><br><span class="line">    // 枚举二进制方案数</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; (1 &lt;&lt; m); i++) &#123;</span><br><span class="line">        // 变量的初始化</span><br><span class="line">        temp = 0;</span><br><span class="line">        flag = <span class="literal">true</span>;</span><br><span class="line">        memset(num, 0, sizeof(num));</span><br><span class="line">        // 判断决定每一个团队是否可以搭乘</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; m; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &amp; (1 &lt;&lt; j)) &#123;</span><br><span class="line">                num[a[j]] += t[j];</span><br><span class="line">                num[b[j]] -= t[j];</span><br><span class="line">                temp += (b[j] - a[j]) * t[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 统计每一站车上的总人数，如果大于容量，就不满足条件</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt;= n; j++) &#123;</span><br><span class="line">            num[j] += num[j - 1];</span><br><span class="line">            <span class="keyword">if</span> (num[j] &gt; v) &#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 满足条件则取最大搭乘费用</span><br><span class="line">        <span class="keyword">if</span> (flag) &#123;</span><br><span class="line">            cost = max(cost, temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cost &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>非极大值抑制NMS(Non-Maximum Suppression)</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6NMS-Non-Maximum-Suppression/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6NMS-Non-Maximum-Suppression/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>NMS顾名思义就是抑制不是极大值的元素，可以理解为局部最大搜索。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。在目标检测中NMS主要用于提取分数最高的候选框。例如在用训练好的模型进行测试时，网络会预测出一系列的候选框，这时候可以用NMS来移除一些多余的候选框，即移除一些IOU值大于某个阈值的框。再比如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用NMS来选取那些邻域里分数最高（是行人的概率最大）的窗口，并且抑制那些分数低的窗口。<br>NMS在计算机视觉领域有着非常重要的应用，如视频目标跟踪、数据挖掘、3D重建、目标识别以及纹理分析等等。</p><h2 id="NMS在目标检测中的应用"><a href="#NMS在目标检测中的应用" class="headerlink" title="NMS在目标检测中的应用"></a>NMS在目标检测中的应用</h2><h4 id="去除重叠人脸检测框的例子"><a href="#去除重叠人脸检测框的例子" class="headerlink" title="去除重叠人脸检测框的例子"></a>去除重叠人脸检测框的例子</h4><p><img src="/images/NMS/1.png" alt=""><br>如上图所示，目的就是要去除冗余的检测框，找到最佳的候选框。</p><h4 id="目标检测pipline中的例子"><a href="#目标检测pipline中的例子" class="headerlink" title="目标检测pipline中的例子"></a>目标检测pipline中的例子</h4><p><img src="/images/NMS/2.png" alt=""><br>如上图所示，产生<strong>proposal</strong>后使用分类网络给出每个框的每类置信度，使用回归网络修正位置，最后使用NMS去除冗余的检测框。</p><h4 id="NMS算法原理"><a href="#NMS算法原理" class="headerlink" title="NMS算法原理"></a>NMS算法原理</h4><p>对于<strong>bounding boxes</strong>列表<strong>B</strong>及其相应的置信度<strong>S</strong>，使用下述计算方式：选择具有最大<strong>score</strong>的检测框<strong>M</strong>，将其从<strong>B</strong>集合中移除并加入到最后的检测结果<strong>R</strong>中。通常将<strong>B</strong>中剩余检测框与<strong>M</strong>的IOU大于阈值<strong>threshold</strong>的框从<strong>B</strong>中移除。重复这个过程，直到<strong>B</strong>为空。<br>其中用到的排序，可以按照检测框右下角的坐标或者面积排序，也可以通过SVM等分类器得到的得分或概率进行排序，R-CNN中就是按照得分进行的排序。<br><img src="/images/NMS/3.png" alt=""><br>比如上图，定位一个车辆的位置，算法找出了许多检测框，这时需要判断哪些矩形框是没用的。<br>非极大值抑制的方法是：先假设有6个矩形框，按照候选框的类别分类概率排序，假设属于车辆的概率排序结果为<strong>A &lt; B &lt; C &lt; D &lt; E &lt; F</strong>。</p><ol><li>先从最大概率矩形框<strong>F</strong>开始，分别判断<strong>A</strong>~<strong>E</strong>与<strong>F</strong>的IOU值是否大于某个设定的阈值；</li><li>假设<strong>B</strong>、<strong>D</strong>与<strong>F</strong>的重叠度超过设定的阈值，那么就移除<strong>B</strong>和<strong>D</strong>；并标记第一个矩形框<strong>F</strong>，是保留下来的。</li><li>从剩下的矩形框<strong>A</strong>、<strong>C</strong>、<strong>E</strong>中，选择概率最大的<strong>E</strong>，然后判断<strong>E</strong>与<strong>A</strong>、<strong>C</strong>的重叠度，如果重叠度大于设定的阈值，那么就扔掉；并标记<strong>E</strong>是保留下来的第二个矩形框。</li></ol><p>就这样一直重复，直到找到所有被保留下来的矩形框。</p><h4 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h4><p>在R-CNN中使用了NMS来确定最终的bbox，其对每个候选框送入分类器，根据分类器的类别分类概率做排序(论文中称为greedy-NMS)。但其实也可以在分类之前运用简单版本的NMS来去除一些框。<br>python实现的单类别nms：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def py_cpu_nms(dets, thresh):</span><br><span class="line"><span class="string">""</span><span class="string">" Pure Python NMS baseline. "</span><span class="string">""</span></span><br><span class="line"><span class="comment"># x1、y1、x2、y2、以及score赋值</span></span><br><span class="line">x1 = dets[:, 0]</span><br><span class="line">y1 = dets[:, 1]</span><br><span class="line">x2 = dets[:, 2]</span><br><span class="line">y2 = dets[:, 3]</span><br><span class="line">scores = dets[:, 4]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一个候选框的面积</span></span><br><span class="line">areas = (x2 - x1 + 1) * (y2 - y1 + 1)</span><br><span class="line"><span class="comment"># 按照score置信度降序排序</span></span><br><span class="line">order = scores.argsort()[::-1]</span><br><span class="line"></span><br><span class="line">keep = [] <span class="comment"># 保留的结果框集合</span></span><br><span class="line"><span class="keyword">while</span> order.size &gt; 0:</span><br><span class="line">i = order[0]</span><br><span class="line">keep.append(i) <span class="comment"># 保留该类剩余box中得分最高的一个</span></span><br><span class="line"><span class="comment"># 计算当前概率最大矩形框与其他矩形框的相交框的坐标</span></span><br><span class="line">xx1 = np.maximum(x1[i], x1[order[1:]])</span><br><span class="line">yy1 = np.maximum(y1[i], y1[order[1:]])</span><br><span class="line">xx2 = np.minimum(x2[i], x2[order[1:]])</span><br><span class="line">yy2 = np.minimum(y2[i], y2[order[1:]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算相交的面积，不重叠时面积为0</span></span><br><span class="line">w = np.maximum(0.0, xx2 - xx1 + 1)</span><br><span class="line">h = np.maximum(0.0, yy2 - yy1 + 1)</span><br><span class="line">inter = w * h</span><br><span class="line"><span class="comment">#计算IoU：重叠面积 /（面积1+面积2-重叠面积）</span></span><br><span class="line">over = inter / (areas[i] + areas[order[1:]] - inter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留IoU小于阈值的矩形框索引</span></span><br><span class="line">inds = np.where(over &lt;= thresh)[0]</span><br><span class="line"><span class="comment"># 将order序列更新，由于前面得到的矩形框索引要比矩形框在原order序列中的索引小1，所以要把这个1加回来</span></span><br><span class="line">order = order[inds + 1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">return</span> keep <span class="comment"># 获取保留下来的索引</span></span><br></pre></td></tr></table></figure></p><p>Faster R-CNN的MATLAB实现与python版实现一致，代码在这里:<a href="https://github.com/ShaoqingRen/faster_rcnn/blob/master/functions/nms/nms.m" target="_blank" rel="noopener">nms.m</a>。另外，<a href="https://github.com/ShaoqingRen/faster_rcnn/blob/master/functions/nms/nms_multiclass.m" target="_blank" rel="noopener">nms_multiclass.m</a>是多类别nms，加了一层for循环对每类进行nms。</p><h4 id="NMS-loss"><a href="#NMS-loss" class="headerlink" title="NMS loss"></a>NMS loss</h4><p>对多类别检测任务，如果对每类分别进行NMS，那么当检测结果中包含两个被分到不同类别的目标且其IoU较大时，会得到不可接受的结果。如下图所示：<br><img src="/images/NMS/4.png" alt=""><br>一种改进方式是在损失函数中加入一部分NMS损失。NMS损失可以定义为与分类损失相同：<br><img src="/images/NMS/5.png" alt=""><br>即真实类别u对应的log损失，p是C个类别的预测概率，相当于增加分类误差。<br>参考论文《Rotated Region Based CNN for Ship Detection》（IEEE2017会议论文）的Multi-task for NMS部分。</p><h4 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h4><p>上述NMS算法的一个主要问题是当两个ground truth的目标的确重叠度很高时，NMS会将具有较低置信度的框去掉(置信度改成0)，如下图所示：<br><img src="/images/NMS/6.png" alt=""><br>论文:<a href="https://arxiv.org/pdf/1704.04503.pdf" target="_blank" rel="noopener">《Improving Object Detection With One Line of Code》</a>，改进之处：<br><img src="/images/NMS/7.png" alt=""><br>改进方法在于将置信度改为IoU的函数：f(IoU)，具有较低的值而不至于从排序列表中删去。<br>（1）线性函数<br><img src="/images/NMS/8.png" alt=""><br>函数值不连续，在某一点的值发生跳跃。<br>（2）高斯函数<br><img src="/images/NMS/9.png" alt=""><br>时间复杂度同传统的greedy-NMS，为O(N^2)。</p><h4 id="Soft-NMS-pythonPython源码实现"><a href="#Soft-NMS-pythonPython源码实现" class="headerlink" title="Soft-NMS pythonPython源码实现"></a>Soft-NMS pythonPython源码实现</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ua = <span class="built_in">float</span>((x2 - x1 + 1) * (y2 - y1 + 1) + area - w * h)</span><br><span class="line">ov = w * h / ua <span class="comment"># iou between max box and detection box</span></span><br><span class="line"><span class="keyword">if</span> method == 1: <span class="comment"># linear</span></span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">        weight = 1 - ov</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        weight = 1</span><br><span class="line"><span class="keyword">elif</span> method == 2: <span class="comment"># gaussian</span></span><br><span class="line">    weight = np.exp(-(ov * ov) / sigma)</span><br><span class="line"><span class="keyword">else</span>: <span class="comment"># original NMS</span></span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">        weight = 0</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        weight = 1</span><br><span class="line"><span class="comment"># re-scoring 修改置信度</span></span><br><span class="line">boxes[pos, 4] = weight * boxes[pos, 4]</span><br></pre></td></tr></table></figure><p>在基于proposal方法的模型结果上应用比较好，检测效果提升：<br><img src="/images/NMS/10.png" alt=""><br>在R-FCN以及Faster-RCNN模型中的测试阶段运用Soft-NMS，在MS-COCO数据集上<em>mAP@[0.5:0.95]</em>能够获得大约1%的提升<a href="https://github.com/bharatsingh430/soft-nms" target="_blank" rel="noopener">详见这里</a>。 如果应用到训练阶段的proposal选取过程理论上也能获得提升。对易重叠的目标类型确实有提高(目标不一定真的有像素上的重叠，切斜的目标的矩形边框会有较大的重叠)。而在SSD，YOLO等非proposal方法中没有提升。</p><h2 id="其它应用"><a href="#其它应用" class="headerlink" title="其它应用"></a>其它应用</h2><ul><li>边缘检测：<br>** Canny算子中的非极大值抑制是沿着梯度方向进行的，即是否为梯度方向上的极值点；<a href="http://blog.csdn.net/kezunhai/article/details/11620357" target="_blank" rel="noopener">参考这里</a></li><li>特征点检测：<br>** 在角点检测等场景下说的非极大值抑制，则是检测中心点处的值是否是某一个邻域内的最大值。</li></ul>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NMS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>交并比IOU(Intersection over Union)</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E4%BA%A4%E5%B9%B6%E6%AF%94IOU-Intersection-over-Union/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E4%BA%A4%E5%B9%B6%E6%AF%94IOU-Intersection-over-Union/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>IOU是在目标检测中使用的一个概念，是产生的预测框(<strong>Predicted bounding box</strong>)与标注框(<strong>Ground-truth bounding box</strong>)的重叠率；简单来说，即两个矩形框面积的交集和并集的比值；它是一个在特定数据集中检测相应物体准确度的测量标准。通常会在<strong>HOG + Linear SVM object detectors</strong>和<strong>Convolutional Neural Network detectors (R-CNN, Faster R-CNN, YOLO 等)</strong>中使用该方法检测其性能。<br>IOU是一个简单的测量标准，在输出中得出一个预测范围(<strong>bounding box</strong>)的任务都可以用IOU来测量。其用于测量真实和预测之间的相关度，相关度越高，该值越高。<br><img src="/images/IOU1.jpg" alt=""><br>上图展示了<strong>ground-truth</strong>和<strong>predicted</strong>的结果，绿色标线是人为标记的正确结果，红色标线是算法预测出来的结果，IOU要做的就是在这两个结果中测量算法的准确度。<br><img src="/images/IOU2.png" alt=""><br><img src="/images/IOU3.png" alt=""><br>一般来说，这个比值 ＞ 0.5 就可以认为是一个不错的结果了。<br><img src="/images/IOU4.png" alt=""></p><h2 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def compute_iou(box1, box2, wh=False):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    compute the iou of two boxes.</span></span><br><span class="line"><span class="string">    args:</span></span><br><span class="line"><span class="string">        box1, box2: [xmin, ymin, xmax, ymax] (wh=False) or [xcenter, ycenter, w, h] (wh=True)</span></span><br><span class="line"><span class="string">        wh: the format of coordinate.</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        iou: iou of box1 and box2.</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> wh == False:</span><br><span class="line">        xmin1, ymin1, xmax1, ymax1 = box1</span><br><span class="line">        xmin2, ymin2, xmax2, ymax2 = box2</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        xmin1, ymin1 = int(box1[0] - box1[2] / 2.0), int(box1[1] - box1[3] / 2.0)</span><br><span class="line">        xmax1, ymax1 = int(box1[0] + box1[2] / 2.0), int(box1[1] + box1[3] / 2.0)</span><br><span class="line">        xmin2, ymin2 = int(box2[0] - box2[2] / 2.0), int(box2[1] - box2[3] / 2.0)</span><br><span class="line">        xmax2, ymax2 = int(box2[0] + box2[2] / 2.0), int(box2[1] + box2[3] / 2.0)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算两个矩形框面积</span></span><br><span class="line">    area1 = (xmax1 - xmin1) * (ymax1 - ymin1)</span><br><span class="line">    area2 = (xmax2 - xmin2) * (ymax2 - ymin2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 获取矩形框交集对应的左上角和右下角的坐标（intersection）</span></span><br><span class="line">    inter_x1 = np.max([xmin1, xmin2])</span><br><span class="line">    inter_y1 = np.max([ymin1, ymin2])</span><br><span class="line">    inter_x2 = np.min([xmax1, xmax2])</span><br><span class="line">    inter_y2 = np.min([ymax1, ymax2])</span><br><span class="line"></span><br><span class="line">    inter_area = (np.max([0, inter_x2 - inter_x1])) * (np.max([0, inter_y2 - inter_y1]))　<span class="comment"># 计算交集面积</span></span><br><span class="line">    iou = inter_area / (area1 + area2 - inter_area + 1e-6)　＃ 计算交并比</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> iou</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IOU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Git基本常用命令</title>
      <link href="/%E5%B7%A5%E5%85%B7/Git%E5%9F%BA%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/%E5%B7%A5%E5%85%B7/Git%E5%9F%BA%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li><strong>git init</strong> 把当前的目录变成可以管理的git仓库，生成隐藏.git文件。</li><li><strong>git add XX</strong> 把xx文件添加到暂存区去。</li><li><strong>git commit -m ‘XX’</strong> 提交文件， –m 后面的是注释。</li><li><strong>git status</strong> 查看本地仓库状态。</li><li><strong>git diff XX</strong> 查看XX文件修改了那些内容。</li><li><strong>git log</strong> 查看历史记录。</li><li><strong>git reset -hard HEAD^</strong> 或者 <strong>git reset –hard HEAD~</strong> 回退到上一个版本(如果想回退到100个版本，使用<strong>git reset –hard HEAD~100</strong> )。</li><li><strong>cat XX</strong> 查看XX文件内容。</li><li><strong>git reflog</strong> 查看历史记录的版本号id。</li><li><strong>git checkout – XX</strong> 把XX文件在工作区的修改全部撤销。</li><li><strong>git rm XX</strong> 删除XX文件。</li><li><strong>git remote add origin <a href="https://github.com/zhaopeng0103/test.git" target="_blank" rel="noopener">https://github.com/zhaopeng0103/test.git</a></strong> 关联一个远程库。</li><li><strong>git push –u(第一次要用-u 以后不需要) origin master</strong> 把当前master分支推送到远程库。</li><li><strong>git clone <a href="https://github.com/zhaopeng0103/test.git" target="_blank" rel="noopener">https://github.com/zhaopeng0103/test.git</a></strong> 从远程库中克隆。</li><li><strong>git checkout –b dev</strong> 创建dev分支，并切换到dev分支上。</li><li><strong>git branch</strong> 查看当前所有的分支。</li><li><strong>git checkout master</strong> 切换回master分支。</li><li><strong>git merge dev</strong> 在当前的分支上合并dev分支。</li><li><strong>git branch –d dev</strong> 删除dev分支。</li><li><strong>git branch name</strong> 创建分支。</li><li><strong>git stash</strong> 把当前的工作隐藏起来 等以后恢复现场后继续工作。</li><li><strong>git stash list</strong> 查看所有被隐藏的文件列表。</li><li><strong>git stash apply</strong> 恢复被隐藏的文件，但是内容不删除。</li><li><strong>git stash drop</strong> 删除文件。</li><li><strong>git stash pop</strong> 恢复文件的同时 也删除文件。</li><li><strong>git remote</strong> 查看远程库的信息。</li><li><strong>git remote –v</strong> 查看远程库的详细信息。</li><li><strong>git push origin master</strong> Git会把master分支推送到远程库对应的远程分支上。</li></ul>]]></content>
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git使用 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>好听的歌曲</title>
      <link href="/music/%E5%A5%BD%E5%90%AC%E7%9A%84%E6%AD%8C%E6%9B%B2/"/>
      <url>/music/%E5%A5%BD%E5%90%AC%E7%9A%84%E6%AD%8C%E6%9B%B2/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>        <div id="aplayer-epZcRTAA" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;"></div>  <script>  var options = {"narrow":false,"autoplay":false,"showlrc":3,"mode":"random","music":[{"title":"小白兔遇上卡布奇诺","author":"兔子牙","url":"/music/小白兔遇上卡布奇诺.mp3","pic":"/images/小白兔1.jpg","lrc":"/documents/小白兔.txt"}]};  options.element = document.getElementById("aplayer-epZcRTAA");  var ap = new APlayer(options);    window.aplayers || (window.aplayers = []);  window.aplayers.push(ap);  </script><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","video":{"url":"/videos/小白兔.mp4","pic":"/images/小白兔.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>]]></content>
      
      <categories>
          
          <category> music </category>
          
      </categories>
      
      
        <tags>
            
            <tag> music </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:五子棋</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E4%BA%94%E5%AD%90%E6%A3%8B/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E4%BA%94%E5%AD%90%E6%A3%8B/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-E-五子棋"><a href="#Problem-E-五子棋" class="headerlink" title="Problem E. 五子棋"></a>Problem E. 五子棋</h2><p>时间限制 1000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个nxn的棋盘上，有一些黑色的棋子和白色的棋子，如果能找出任意五个同色的棋子连成直线（横着、竖着、斜着都可以），那么该颜色方加1分。求黑色方得分和白色方得分。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行为一个正整数n，代表棋盘的大小。 接下来为一个nxn的矩阵，’#’代表没有棋子，’B’代表黑色棋子，’W’代表白色棋子 n&lt;=20</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>两个正整数，分别代表黑色方得分和白色方得分</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">WBBBBB</span><br><span class="line">WBB<span class="comment">###</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 2</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>直接遍历每一个棋子，如果在下图中的任一个方向连成5个，则对应方加1分。<br><img src="/images/wuziqi.png" alt=""></p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = 40;</span><br><span class="line">int n;</span><br><span class="line">int a[maxN][maxN], b_score, w_score;</span><br><span class="line">string s;</span><br><span class="line">int i, j;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    memset(a, 0, sizeof(a));</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 3; i &lt; n + 3; i++) &#123;</span><br><span class="line">        cin &gt;&gt; s;</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; s.length(); j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s[j] == <span class="string">'B'</span>) &#123;</span><br><span class="line">                a[i][j + 3] = 1;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (s[j] == <span class="string">'W'</span>) &#123;</span><br><span class="line">                a[i][j + 3] = 2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 3; i &lt; n + 3; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 3; j &lt; n + 3; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (a[i][j] == 1) &#123;</span><br><span class="line">                <span class="keyword">if</span> (a[i][j - 1] == a[i][j] &amp;&amp; a[i][j - 2] == a[i][j] &amp;&amp; a[i][j + 1] == a[i][j] &amp;&amp; a[i][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i - 1][j] == a[i][j] &amp;&amp; a[i - 2][j] == a[i][j] &amp;&amp; a[i + 1][j] == a[i][j] &amp;&amp; a[i + 2][j] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j + 1] == a[i][j] &amp;&amp; a[i + 2][j + 2] == a[i][j] &amp;&amp; a[i - 1][j - 1] == a[i][j] &amp;&amp; a[i - 2][j - 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j - 1] == a[i][j] &amp;&amp; a[i + 2][j - 2] == a[i][j] &amp;&amp; a[i - 1][j + 1] == a[i][j] &amp;&amp; a[i - 2][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (a[i][j] == 2) &#123;</span><br><span class="line">                <span class="keyword">if</span> (a[i][j - 1] == a[i][j] &amp;&amp; a[i][j - 2] == a[i][j] &amp;&amp; a[i][j + 1] == a[i][j] &amp;&amp; a[i][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i - 1][j] == a[i][j] &amp;&amp; a[i - 2][j] == a[i][j] &amp;&amp; a[i + 1][j] == a[i][j] &amp;&amp; a[i + 2][j] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j + 1] == a[i][j] &amp;&amp; a[i + 2][j + 2] == a[i][j] &amp;&amp; a[i - 1][j - 1] == a[i][j] &amp;&amp; a[i - 2][j - 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j - 1] == a[i][j] &amp;&amp; a[i + 2][j - 2] == a[i][j] &amp;&amp; a[i - 1][j + 1] == a[i][j] &amp;&amp; a[i - 2][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; b_score &lt;&lt; <span class="string">" "</span> &lt;&lt; w_score &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:讨厌的数字</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E8%AE%A8%E5%8E%8C%E7%9A%84%E6%95%B0%E5%AD%97/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E8%AE%A8%E5%8E%8C%E7%9A%84%E6%95%B0%E5%AD%97/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-D-讨厌的数字"><a href="#Problem-D-讨厌的数字" class="headerlink" title="Problem D. 讨厌的数字"></a>Problem D. 讨厌的数字</h2><p>时间限制 1000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>奶牛的生日快到了，你准备送给他一个数x作为生日礼物，x是十进制下的一个n位数，但是奶牛向你提出了一些要求。 1 奶牛准备了一个数字d，他希望x是d的倍数 2 奶牛不喜欢0和3，他不希望x中有0或3 请问有多少个不同的n位数可以作为奶牛的生日礼物呢？ 答案mod1000000007输出。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>两个数字n和d，代表数字位数和奶牛给出的数字d<br>0 &lt;= n &lt;= 1000<br>0 &lt;= d &lt;= 1000</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>一个1000000007之内的整数代表答案</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 3</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">22</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p><code>dp[i][j]</code>表示<code>i</code>位数中模<code>d</code>等于<code>j</code>的方案数。首先计算只有一位数时，满足条件的方案数作为初始值。然后依次遍历<code>i</code>位数下对<code>d</code>求余为<code>j</code>的方案个数；每增加一位数，就在其最后加<code>k</code>，因为要求数字中不能出现<code>0</code>和<code>3</code>，那么遍历时直接去除这两个数字就可以了。最后<code>n</code>位数下是<code>d</code>的倍数的方案个数就是<code>dp[n][0]</code>。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = 1010;</span><br><span class="line">int n, d, dp[maxN][maxN];</span><br><span class="line">int i, j, k;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; d;</span><br><span class="line">    // 计算一位数的方案数</span><br><span class="line">    <span class="keyword">for</span> (k = 1; k &lt;= 9; k++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (k == 3) &#123;</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dp[1][k % d]++;</span><br><span class="line">    &#125;</span><br><span class="line">    // dp[i][j]表示i位数中模d等于j的方案数</span><br><span class="line">    <span class="keyword">for</span> (i = 2; i &lt;= n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; d; j++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (k = 1; k &lt;= 9; k++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (k == 3) &#123;</span><br><span class="line">                    <span class="built_in">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                dp[i][(j * 10 + k) % d] += dp[i - 1][j];</span><br><span class="line">                dp[i][(j * 10 + k) % d] %= 1000000007;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; dp[n][0] &lt;&lt; endl;// 输出n位数中能被d整除的满足条件的方案数</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 程序设计竞赛 </tag>
            
            <tag> 动态规划dp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:约瑟夫环plus</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AFplus/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AFplus/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-C-约瑟夫环plus"><a href="#Problem-C-约瑟夫环plus" class="headerlink" title="Problem C. 约瑟夫环plus"></a>Problem C. 约瑟夫环plus</h2><p>时间限制 2000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>考虑经典的约瑟夫环模型：n个人按顺序围成一圈，从第一个人开始报数，从1开始报，报到k这个数的人会被移出去，然后下一个人从1开始重新报数，第n个人报完数之后第1个人接着报数，问整个过程中第1个人报了几次数。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>两个正整数n，k<br>1 &lt;= n &lt;= 1000000000000000000<br>1 &lt;= k &lt;= 200</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>第1个人被移除之前一共报了几次数</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4 4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="样例说明"><a href="#样例说明" class="headerlink" title="样例说明"></a>样例说明</h3><p>注意n需要用long long存</p><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p><code>cur_number</code>存储第一个人每次轮到他时所报的号，最开始时，第一个人报号的次数<code>res</code>为<code>1</code>，<code>cur_number</code>也为<code>1</code>；从上一次这个人报号到下一次轮到他报号为止为一个周期，在这个周期内有<code>(n + cur_number) / k</code>个人被移出去，这个人报的号更新为<code>(n + cur_number) % k</code>；所以当<code>(n + cur_number) % k = 0</code>时，第一个人会被移出去，也就是下一次轮到他时<code>cur_number = 0</code>。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">long long n, k, cur_number, res, temp;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; k;</span><br><span class="line">    res = 1;</span><br><span class="line">    cur_number = 1;</span><br><span class="line">    <span class="keyword">while</span> (cur_number != 0) &#123;</span><br><span class="line">        temp = n + cur_number;</span><br><span class="line">        n -= temp / k;</span><br><span class="line">        cur_number = temp % k;</span><br><span class="line">        res++;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:魔法师排队</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E9%AD%94%E6%B3%95%E5%B8%88%E6%8E%92%E9%98%9F/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E9%AD%94%E6%B3%95%E5%B8%88%E6%8E%92%E9%98%9F/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-B-魔法师排队"><a href="#Problem-B-魔法师排队" class="headerlink" title="Problem B. 魔法师排队"></a>Problem B. 魔法师排队</h2><p>时间限制 2000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>有n个魔法师在排队买魔法面包，每个魔法师都有自己的魔力值，用一个正整数表示。 魔法师都不喜欢排队，如果任意时刻某个魔法师发现前面的魔法师的魔力值比自己小，那么这个魔法师就会用法术把前面的人传送到异空间。 请输出有多少个魔法师会被传送到异空间。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行为一个正整数n，代表魔法师的人数。 接下来一行位n个正整数，第i个正整数ai代表队伍中第i个魔法师的魔力值。（第1个魔法师在队头，第n个魔法师在队尾）<br>1 &lt;= n &lt;= 1000000<br>1 &lt;= ai &lt;= 100000000</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>被传送到异空间的魔法师个数</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5</span><br><span class="line">4 5 1 3 2</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>一开始的想法是：找从第一个魔法师到最后一个魔法师中的拥有最大魔力值的魔法师<code>max_index</code>，那么位于它之前的魔法师都将会被传送走，此具有最大魔力值的魔法师会留下来；接着寻找从<code>max_index + 1</code>到最后一个魔法师之间的拥有最大魔力值的魔法师，进行同样的操作，依次循环下去，直到剩下最后一个魔法师为止（最后一个魔法师肯定会留下来）；然而结果却超时了。于是换了种思维方式，既然是位于魔法师前面且比其魔力值小的魔法师会被传送走，那么最后一个魔法师肯定会留下来；直接定义一个存储最大魔力值的变量<code>max_num</code>，初始化为最后一个魔法师的魔力值，从后向前倒序遍历，如果当前魔法师的魔力值比<code>max_num</code>小，那么就把他传送走；否则，更新最大魔力值。</p><h3 id="TLE代码"><a href="#TLE代码" class="headerlink" title="TLE代码"></a>TLE代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = int(1e6 + 10);</span><br><span class="line">int n, a[maxN], l, r, max_index, cont;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    l = 0; r = n;</span><br><span class="line">    <span class="keyword">while</span>(l &lt; r) &#123;</span><br><span class="line">        vector&lt;int&gt; v(a + l, a + r);</span><br><span class="line">        auto max_value = max_element(v.begin(), v.end());</span><br><span class="line">        max_index = distance(begin(v), max_value);</span><br><span class="line">        cont += max_index;</span><br><span class="line">        l = l + max_index + 1;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cont &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = int(1e6 + 10);</span><br><span class="line">int n, a[maxN], max_num, cont;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    max_num = a[n];</span><br><span class="line">    <span class="keyword">for</span> (i = n - 1; i &gt; 0; i--) &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &lt; max_num) &#123;</span><br><span class="line">            cont++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            max_num = a[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cont &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/default/hello-world/"/>
      <url>/default/hello-world/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><h3 id="创建一篇新文章"><a href="#创建一篇新文章" class="headerlink" title="创建一篇新文章"></a>创建一篇新文章</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>更多信息请查看： </p><ul><li><a href="https://hexo.io/zh-cn/docs/writing.html" target="_blank" rel="noopener">Writing</a> </li><li><a href="https://hexo.io/zh-cn/docs/tag-plugins" target="_blank" rel="noopener">标签插件（Tag Plugins）</a></li><li><a href="https://blog.csdn.net/zhuzhuyule/article/details/58347687" target="_blank" rel="noopener">Markdown语法(GFM)写博客</a></li><li><a href="http://www.cnblogs.com/youngwilliam/articles/youngwilliam.html" target="_blank" rel="noopener">HexoEditor, 一个写 Hexo 非常好用的 Markdown 编辑器</a></li><li><a href="https://github.com/zhuzhuyule/HexoEditor" target="_blank" rel="noopener">HexoEditor</a></li></ul><h3 id="运行服务"><a href="#运行服务" class="headerlink" title="运行服务"></a>运行服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="生成静态文件"><a href="#生成静态文件" class="headerlink" title="生成静态文件"></a>生成静态文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="发布到远程站点"><a href="#发布到远程站点" class="headerlink" title="发布到远程站点"></a>发布到远程站点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g</span><br><span class="line">$ gulp</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h3 id="关于图片素材"><a href="#关于图片素材" class="headerlink" title="关于图片素材"></a>关于图片素材</h3><p>图片素材按官方教程说法，可统一放置在source/images目录中，并以<code>![](/images/image.jpg)</code> 方式引用。或者在<code>_config.yml</code>打开 post_asset_folder 功能，将当前文章所用的图片放置到source目录下的文章同名资源目录下，以<code>![](image.jpg)</code>方式引用</p><h3 id="使用-Hexo-Admin-插件"><a href="#使用-Hexo-Admin-插件" class="headerlink" title="使用 Hexo Admin 插件"></a>使用 Hexo Admin 插件</h3><p>Hexo Admin是一个本地在线式文章管理器，可以用直观可视化的方式新建、编辑博客文章、page页面，添加标签、分类等，并且支持剪贴板粘贴图片（自动在source_images_目录中创建文件）。<br><img src="/images/hexoadmin.png" alt=""></p><ul><li><p>在Hexo网站目录下，安装 Hexo Admin 插件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --save hexo-admin</span><br></pre></td></tr></table></figure></li><li><p>启动本地服务器并打开管理界面，即可使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server -d</span><br><span class="line">$ open http://localhost:4000/admin/</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用HexoEditor-Markdown-编辑器"><a href="#使用HexoEditor-Markdown-编辑器" class="headerlink" title="使用HexoEditor Markdown 编辑器"></a>使用HexoEditor Markdown 编辑器</h3><blockquote><p>设置 npm 缓存路径</p><blockquote><p>Windows 下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">"C:/Program Files/nodejs/npm_global"</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">"C:/Program Files/nodejs/npm_cache"</span></span><br></pre></td></tr></table></figure></p></blockquote></blockquote><blockquote><blockquote><p>Linux\Mac 下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">"~/nodejs/npm_global"</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">"~/nodejs/npm_cache"</span></span><br></pre></td></tr></table></figure></p></blockquote></blockquote><blockquote><blockquote><p>注意：这里的路径是你安装 nodejs 的子目录下对应的路径</p></blockquote></blockquote><blockquote><p>设置下载来源（镜像），加速下载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry <span class="string">"https://registry.npm.taobao.org/"</span></span><br><span class="line">npm config <span class="built_in">set</span> electron_mirror <span class="string">"https://npm.taobao.org/mirrors/electron/"</span></span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>下载 GitHub 上最新的版本并安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/zhuzhuyule/HexoEditor.git</span><br><span class="line"><span class="built_in">cd</span> HexoEditor</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm start</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="使用github-pages服务搭建博客的好处"><a href="#使用github-pages服务搭建博客的好处" class="headerlink" title="使用github pages服务搭建博客的好处"></a>使用github pages服务搭建博客的好处</h3><ol><li>全是静态文件，访问速度快；</li><li>免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；</li><li>可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；</li><li>数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；</li><li>博客内容可以轻松打包、转移、发布到其它平台。</li></ol>]]></content>
      
      <categories>
          
          <category> default </category>
          
      </categories>
      
      
        <tags>
            
            <tag> default </tag>
            
        </tags>
      
    </entry>
    
  
  
    
    <entry>
      <title>关于我</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h2><ul><li>我叫赵鹏</li><li>男</li><li>石家庄人</li><li>现居北京</li><li>学生</li></ul><h2 id="联系我"><a href="#联系我" class="headerlink" title="联系我"></a>联系我</h2><ul><li>Email：<a href="mailto:424107420@qq.com" target="_blank" rel="noopener">424107420@qq.com</a></li><li>GitHub：zhaopeng0103</li><li>WeChat：zp18713598785</li><li>QQ：424107420</li></ul>]]></content>
    </entry>
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
    </entry>
    
    <entry>
      <title>标签云</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
    </entry>
    
  
</search>
