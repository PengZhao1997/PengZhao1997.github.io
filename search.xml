<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>CVPR2018 | 旷视科技提出通过角点定位与区域分割来检测多方向的文本</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E9%80%9A%E8%BF%87%E8%A7%92%E7%82%B9%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%96%B9%E5%90%91%E7%9A%84%E6%96%87%E6%9C%AC/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E9%80%9A%E8%BF%87%E8%A7%92%E7%82%B9%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2%E6%9D%A5%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%96%B9%E5%90%91%E7%9A%84%E6%96%87%E6%9C%AC/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/CLRS/1.png" alt=""><br><strong>Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation</strong><br><strong>KeyWords Plus</strong>: CVPR2018 Multi-Oriented Text<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1802.08948.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1802.08948.pdf</a><br><strong>reference</strong>: Lyu P, Yao C, Wu W, et al. Multi-oriented scene text detection via corner localization and region segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7553-7563.<br><strong>Github</strong>: <a href="https://github.com/lvpengyuan/corner" target="_blank" rel="noopener">https://github.com/lvpengyuan/corner</a></p><h3 id="方法概括"><a href="#方法概括" class="headerlink" title="方法概括"></a>方法概括</h3><h4 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h4><p>该方法用一个端到端的网络实现文本检测整个过程。除了基础卷积网络（backbone）外，包括两个并行分支和一个后处理过程。第一个分支是通过一个DSSD网络进行角点检测来提取候选文本区域，第二个分支是利用类似于RFCN进行网格划分的方式来做position-sensitive的segmentation。后处理过程是利用segmentation的score map来综合得分，过滤角点检测得到的候选区域中的噪声。</p><h4 id="背景（文本检测三大难点）"><a href="#背景（文本检测三大难点）" class="headerlink" title="背景（文本检测三大难点）"></a>背景（文本检测三大难点）</h4><ul><li>多方向</li><li>长宽比多变</li><li>文本的粒度多样（包括字符、单词、文本行等多种形式）</li></ul><h4 id="文章亮点"><a href="#文章亮点" class="headerlink" title="文章亮点"></a>文章亮点</h4><ul><li>检测不是用一般的object detection的框架来做，而是用corner point detection来做，可以更好地解决文本方向任意、文本长宽比多变的问题。</li><li>分割用的是<strong>position sensitive segmentation</strong>，仿照RFCN划分网格的思路，把位置信息融合进去，对于检测单词这种细粒度的更有帮助。</li><li>把检测和分割两大类的方法整合起来，进行综合打分的pipeline，这可以使检测精度更高。</li></ul><h3 id="方法细节"><a href="#方法细节" class="headerlink" title="方法细节"></a>方法细节</h3><h4 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h4><p>用一个检测网络完成整个检测过程，该网络分为以下几个部分：<br><img src="/images/CLRS/2.png" alt=""></p><ul><li><strong>backbone</strong>：基础网络，用于特征提取（不同分支特征共享）。</li><li><strong>corner detection</strong>：用来生成候选检测框，是一个独立的检测模块，类似于RPN的功能。</li><li><strong>Position Sensitive Segmentation</strong>：整张图逐像素的打分，和一般分割不同的是输出4个score map，分别对应左上、右上、右下、左下四个不同位置的得分。</li><li><strong>Scoring + NMS</strong>：综合打分，利用（2）的框和（3）的score map综合打分，去掉非文本框，最后再接一个NMS。</li></ul><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/images/CLRS/3.png" alt=""></p><ul><li>Backbone取自DSSD = VGG16(pool5) + conv6(fc6) + conv7(fc7) + 4conv + 6 deconv (with 6 residual block)。</li><li>Corner Point Detection是类似于SSD，从多个deconv的feature map上单独做detection得到候选框，然后多层的检测结果串起来，nms后为最后的结果。</li><li>损失：<br><img src="/images/CLRS/4.png" alt=""></li></ul><h4 id="Corner-Detection"><a href="#Corner-Detection" class="headerlink" title="Corner Detection"></a>Corner Detection</h4><h6 id="思路说明"><a href="#思路说明" class="headerlink" title="思路说明"></a>思路说明</h6><ul><li>Step1: 用DSSD框架（任何一个目标检测的框架都可以）找到一个框的四个角点，然后整张图的所有角点都放到一个集合中。</li><li>Step2: 把集合中的所有角点进行组合得到所有候选框。</li></ul><h6 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h6><p><img src="/images/CLRS/5.png" alt=""></p><ul><li>Fi表示backbone结构中的后面几个deconv得到的feature map（每层都单独做了detection）。</li><li>w, h是feature map大小，k是defalt box的个数，q表示角点类型，这里q = 4，即每个位置（左上、右上、右下、左下）都能单独得到2个score map和4个offset map。</li></ul><h6 id="角点信息"><a href="#角点信息" class="headerlink" title="角点信息"></a>角点信息</h6><p><img src="/images/CLRS/6.png" alt=""></p><ul><li>实际上是一个正方形，正方形中心为gt框（指的是文本框）的顶点，正方形的边长 = gt框的最短边。</li><li>corner detection对每一种角点（四种）单独输出corner box，可以看做是一个四类的目标检测问题。</li></ul><h6 id="角点如何组合成文本框？"><a href="#角点如何组合成文本框？" class="headerlink" title="角点如何组合成文本框？"></a>角点如何组合成文本框？</h6><ul><li>由于角点不但有顶点位置信息，也有边长信息，所以满足条件的两个corner point组合起来可以确定一个文字框。</li><li>具体组合思路如下： 一个rotated rectangle可以由两个顶点+垂直于两个顶点组成的边且已知长度的边来确定。<ul><li>由于角点的顶点类型确定，所以短边方向也是确定的，例如左上-左下连边确定短边在右边。</li><li>垂直的边的长度可以取两个角点的正方形边长的平均值。</li></ul></li><li>可以组合的两个corner point满足条件如下：<ul><li>角点分数阈值&gt;0.5；</li><li>角点的正方形边长大小相似（边长比&lt;1.5）；</li><li>框的顶点类型和位置先验信息（例如，“左上”、“左下”的角点的x应该比“右上”、“右下”小）。</li></ul></li></ul><h6 id="损失"><a href="#损失" class="headerlink" title="损失"></a>损失</h6><ul><li>得分分支（score branch）的损失：Cross Entropy损失。<br><img src="/images/CLRS/7.png" alt=""></li><li>偏移分支（offset branch）的损失：Smooth L1损失。<br><img src="/images/CLRS/8.png" alt=""></li></ul><h4 id="Poosition-Sensitive-Segmentation"><a href="#Poosition-Sensitive-Segmentation" class="headerlink" title="Poosition Sensitive Segmentation"></a>Poosition Sensitive Segmentation</h4><ul><li>思路说明<ul><li>把一个文字框划分成g * g个网格的小框（一个bin），每个bin做为一类，把一个text/non-text的二类问题变成g * g个二类问题。</li></ul></li><li>网络结构<br><img src="/images/CLRS/9.png" alt=""></li><li>损失：dice损失<br><img src="/images/CLRS/10.png" alt=""></li></ul><h4 id="Scoring"><a href="#Scoring" class="headerlink" title="Scoring"></a>Scoring</h4><p><img src="/images/CLRS/11.png" alt=""></p><ul><li>目的<ul><li>利用segmentation得到的g * g张score map来进一步判断corner detection得到的那些候选框是否是文字，过滤噪声框</li></ul></li><li>思路说明<ul><li>把detection得到的框先划分成g * g个网格（bin），每个bin对应各自的segmentation score map，然后把对应的score map里对应bin位置的那些前景点的像素值取平均（底下P的分母是C，不是直接R的面积，或者bin的面积可以看出只取前景点，即score&gt;0的点）作为每个bin的分数，最后把g * g个bin的分数取平均为初始文字框的分数</li></ul></li><li><p>算法伪代码<br><img src="/images/CLRS/12.png" alt=""></p></li><li><p>为什么scoring这么复杂，不直接用区域的像素平均值？</p><ul><li>采用position sensitive segmentation的思路决定了最后scoring的时候也必须划网格单独取值再平均。至于之所以只取前像素点是为了平均时不受背景点影响，更加精确。</li></ul></li><li>注意一点<ul><li>该文章的分割分支与角点分支（也可以叫做回归分支，候选目标检测分支，作用类似于RPN，用来回归候选框）的组合方式与其他的目标检测方法（例如RPN，SSD）中分割与回归分支的组合方式完全不同。对于RPN或SSD，其回归分支与分割分支共同作用才能得到候选框，分割分支的score map上的每个像素点值决定了回归分支中某几个框是否是有效的（目标框还是背景框）。而这篇文章的分割分支和回归分支除了共用特征外，以及最后把损失都加到损失层外，两个分支是完全独立的！也就是说，回归分支可以换成任何一个可以生成候选框的目标检测分支（RPN，SSD，甚至Faster R-CNN），分割分支可以换成任何一个可以生成目标置信概率图的分支，而把这两个分支加上最后的综合打分就可以让分割分支去帮助目标检测分支进一步过滤噪声（但对框的生成没有影响）。这种框架是把目前的两大类文字检测方法（基于目标检测的框架，和基于分割的框架）综合起来，可以提高检测精度。</li></ul></li></ul><h4 id="问题搜集"><a href="#问题搜集" class="headerlink" title="问题搜集"></a>问题搜集</h4><ul><li>为什么要用position-sensitive segmentation？从结果来讲，和普通的segmentation而言，到底好在哪里？是否是更适合各种粒度的文字（字符，单词，文本行）?</li><li>文章中用角点检测来检测文字和一般用目标检测的方法来检测文字，其优势和劣势在哪里?<ul><li>优势</li><li>角点检测里每个角点都是独立的，所以在多个特征层上的detection的角点可以全部放到一个集合里再去两两组合获得文字框，而不采用每个特征层单独做直接得到文字框后再多层融合。这样好处在于，同一个框的不同角点可以是从不同的特征层上检测到的，即使在某一层上某个角点漏了，但有其他层可以帮忙将其找回来。</li><li>角点检测不用考虑方向性，所以可以用任何一般的目标检测框架而无需修改（加方向参数等）直接用于检测角点。</li><li>角点检测不用考虑文字框的长宽比大小，对于类似RPN等基于anchor的其defaut box的长宽比和scale不好设置，尤其针对长文本，角点检测则不用考虑这个问题。</li><li>可能潜在的问题</li><li>如果角点很多，那么这种两两组合的可能性很多，使得检测框特别多，对后续nms等压力较大。</li><li>由于任意两个角点都组合，所以可能导致很多无关的框、没有意义的框都被当做候选框（比如从左上顶点和右下顶点组成的框）。</li></ul></li><li>我认为文章中疑问或者有问题的点<ul><li>Corner Point Prediction的offset输出没有必要是4维的，因为已知是正方形的情况下，只需x1，y1，s三维就好了（w = h = s）。</li><li>部分存在歧义，没有说清楚：We determine the relative position of a rotated rectangle by the following rules: 1) the x-coordinates of top left and bottom-left corner points must less than the x coordinates of top-right and bottom-right corner points; 2)the y-coordinates of top-left and top-right corner points must less than the y-coordinates of bottom-left and bottom right corner points.<br><img src="/images/CLRS/13.png" alt=""></li></ul></li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/CLRS/14.png" alt=""></p><ul><li>深度框架：Pytorch</li><li>结果与速度说明<ul><li>Nvidia Titan Pascal GPU</li><li>ICDAR2013：图像大小resize成512 * 512，100ms/每张图，F值=85.5%/88.0%（多尺度）。</li><li>MSRA-TD500：图像大小768 * 768，5.7FPS，F值=81.5%。</li><li>MLT：768 * 768，F值=72.4%。</li><li>ICDAR2015：768 * 1280，1FPS，F值= 84.3%。</li><li>COCO-Text：768 * 768，IOU=0.5，F值=42.5%。</li></ul></li><li>ICDAR2013<br><img src="/images/CLRS/15.png" alt=""></li><li>ICDAR2015<br><img src="/images/CLRS/16.png" alt=""></li><li>MSRA-TD500<br><img src="/images/CLRS/17.png" alt=""></li><li>COCO-Text<br><img src="/images/CLRS/18.png" alt=""></li><li>MLT<br><img src="/images/CLRS/19.png" alt=""></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>用角点检测来做目标检测问题很有新意。</li><li>Position-sensitive segmentation和一般的segmentation不太一样，虽然不是完全理解用这个的原因（融合位置信息？）。</li><li>做一次分割，再做一次目标检测，两个共同来打分，这个思路很有意思，不管是用什么做分割或检测，不管分割和检测是否共用网络基础结构，不管分割和检测之间是否有关系，这个框架都很可取。</li></ul>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> 旷视 </tag>
            
            <tag> 角点定位与区域分割 </tag>
            
            <tag> CVPR2018 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNN网络结构的发展：从LeNet到EfficientNet</title>
      <link href="/CNN/CNN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%EF%BC%9A%E4%BB%8ELeNet%E5%88%B0EfficientNet/"/>
      <url>/CNN/CNN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95%EF%BC%9A%E4%BB%8ELeNet%E5%88%B0EfficientNet/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="CNN基本部件介绍"><a href="#CNN基本部件介绍" class="headerlink" title="CNN基本部件介绍"></a>CNN基本部件介绍</h3><h4 id="局部感受野"><a href="#局部感受野" class="headerlink" title="局部感受野"></a>局部感受野</h4><p>在图像中局部像素之间的联系较为紧密，而距离较远的像素联系相对较弱。因此，其实每个神经元没必要对图像全局进行感知，只需要感知局部信息，然后在更高层局部信息综合起来即可得到全局信息。卷积操作即是局部感受野的实现，并且卷积操作因为能够权值共享，所以也减少了参数量。</p><h4 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h4><p>池化是将输入图像进行缩小，减少像素信息，只保留重要信息，主要是为了减少计算量。主要包括最大池化和均值池化。</p><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>激活函数的作用是用来加入非线性。常见的激活函数有sigmod，tanh，relu，前两者常用在全连接层，relu常见于卷积层。</p><h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>全连接层在整个卷积神经网络中起分类器的作用。在全连接层之前需要将之前的输出展平。</p><h3 id="经典网络结构"><a href="#经典网络结构" class="headerlink" title="经典网络结构"></a>经典网络结构</h3><h4 id="1、LeNet5"><a href="#1、LeNet5" class="headerlink" title="1、LeNet5"></a>1、LeNet5</h4><p>由两个卷积层，两个池化层，两个全连接层组成。卷积核都是5×5，stride=1，池化层使用maxpooling。<br><img src="/images/CNN/1.png" alt=""></p><h4 id="2、AlexNet"><a href="#2、AlexNet" class="headerlink" title="2、AlexNet"></a>2、AlexNet</h4><p>模型共八层（不算input层），包含五个卷积层、三个全连接层。最后一层使用softmax做分类输出。AlexNet使用了ReLU做激活函数；防止过拟合使用dropout和数据增强；双GPU实现；使用LRN。<br><img src="/images/CNN/2.png" alt=""><br><img src="/images/CNN/3.png" alt=""></p><h4 id="3、VGG"><a href="#3、VGG" class="headerlink" title="3、VGG"></a>3、VGG</h4><p>全部使用3×3卷积核的堆叠，来模拟更大的感受野，并且网络层数更深。VGG有五段卷积，每段卷积后接一层最大池化。卷积核数目逐渐增加。<br>总结：LRN作用不大；越深的网络效果越好；1×1的卷积也很有效但是没有3×3好。<br><img src="/images/CNN/4.png" alt=""></p><h4 id="4、GoogLeNet-inception-v1"><a href="#4、GoogLeNet-inception-v1" class="headerlink" title="4、GoogLeNet(inception v1)"></a>4、GoogLeNet(inception v1)</h4><p>从VGG中了解到，网络层数越深效果越好。但是随着模型越深参数越来越多，这就导致网络比较容易过拟合，需要提供更多的训练数据；另外，复杂的网络意味更多的计算量，更大的模型存储，需要更多的资源，且速度不够快。GoogLeNet就是从减少参数的角度来设计网络结构的。<br>GoogLeNet通过增加网络宽度的方式来增加网络复杂度，让网络可以自己去应该如何选择卷积核。这种设计减少了参数 ，同时提高了网络对多种尺度的适应性。使用了1×1卷积可以使网络在不增加参数的情况下增加网络复杂度。<br><img src="/images/CNN/5.png" alt=""></p><p><strong>Inception-v2</strong><br>在v1的基础上加入batch normalization技术，在tensorflow中，使用BN在激活函数之前效果更好；将5×5卷积替换成两个连续的3×3卷积，使网络更深，参数更少。</p><p><strong>Inception-v3</strong><br>核心思想是将卷积核分解成更小的卷积，如将7×7分解成1×7和7×1两个卷积核，使网络参数减少，深度加快。</p><p><strong>Inception-v4</strong><br>引入了ResNet，使训练加速，性能提升。但是当滤波器的数目过大（&gt;1000）时，训练很不稳定，可以加入activate scaling因子来缓解。</p><h4 id="5、Xception"><a href="#5、Xception" class="headerlink" title="5、Xception"></a>5、Xception</h4><p>在Inception-v3的基础上提出，基本思想是通道分离式卷积，但是又有区别。模型参数稍微减少，但是精度更高。Xception先做1×1卷积再做3×3卷积，即先将通道合并，再进行空间卷积。depthwise正好相反，先进行空间3×3卷积，再进行通道1×1卷积。核心思想是遵循一个假设：卷积的时候要将通道的卷积与空间的卷积进行分离。而MobileNet-v1用的就是depthwise的顺序，并且加了BN和ReLU。Xception的参数量与Inception-v3相差不大，其增加了网络宽度，旨在提升网络准确率，而MobileNet-v1旨在减少网络参数，提高效率。<br><img src="/images/CNN/6.png" alt=""><br><img src="/images/CNN/7.png" alt=""></p><h4 id="6、MobileNet系列"><a href="#6、MobileNet系列" class="headerlink" title="6、MobileNet系列"></a>6、MobileNet系列</h4><p><strong>V1</strong><br>使用depthwise separable convolutions；放弃pooling层，而使用stride=2的卷积。标准卷积的卷积核的通道数等于输入特征图的通道数；而depthwise卷积核通道数是1；还有两个参数可以控制，a控制输入输出通道数；p控制图像（特征图）分辨率。<br><img src="/images/CNN/8.png" alt=""><br><img src="/images/CNN/9.png" alt=""></p><p><strong>V2</strong><br>相比v1有三点不同：</p><ol><li>引入了残差结构；</li><li>在dw之前先进行1×1卷积增加feature map通道数，与一般的residual block是不同的；</li><li>pointwise结束之后弃用ReLU，改为linear激活函数，来防止ReLU对特征的破环。这样做是因为dw层提取的特征受限于输入的通道数，若采用传统的residual block，先压缩那dw可提取的特征就更少了，因此一开始不压缩，反而先扩张。但是当采用扩张-卷积-压缩时，在压缩之后会碰到一个问题，ReLU会破环特征，而特征本来就已经被压缩，再经过ReLU还会损失一部分特征，应该采用linear。</li></ol><p><img src="/images/CNN/10.png" alt=""><br><img src="/images/CNN/11.png" alt=""></p><p><strong>V3</strong><br>互补搜索技术组合：由资源受限的NAS执行模块集搜索，NetAdapt执行局部搜索；网络结构改进：将最后一步的平均池化层前移并移除最后一个卷积层，引入h-swish激活函数，修改了开始的滤波器组。<br>V3综合了v1的深度可分离卷积，v2的具有线性瓶颈的反残差结构，SE结构的轻量级注意力模型。<br><img src="/images/CNN/12.png" alt=""><br><img src="/images/CNN/13.png" alt=""><br><img src="/images/CNN/14.png" alt=""></p><h4 id="7、EffNet"><a href="#7、EffNet" class="headerlink" title="7、EffNet"></a>7、EffNet</h4><p>EffNet是对MobileNet-v1的改进，主要思想是：将MobileNet-1的dw层分解成两个3×1和1×3的dw层，这样，第一层之后就采用pooling，从而减少第二层的计算量。EffNet比MobileNet-v1和ShuffleNet-v1模型更小，精度更高。<br><img src="/images/CNN/15.png" alt=""><br><img src="/images/CNN/16.png" alt=""></p><h4 id="8、EfficientNet"><a href="#8、EfficientNet" class="headerlink" title="8、EfficientNet"></a>8、EfficientNet</h4><p>研究网络设计时在<strong><em>depth, width, resolution</em></strong>上进行扩展的方式，以及之间的相互关系。可以取得更高的效率和准确率。<br><img src="/images/CNN/17.png" alt=""></p><h4 id="9、ResNet"><a href="#9、ResNet" class="headerlink" title="9、ResNet"></a>9、ResNet</h4><p>VGG证明更深的网络层数是提高精度的有效手段，但是更深的网络极易导致梯度弥散，从而导致网络无法收敛。经测试，20层以上会随着层数增加收敛效果越来越差。ResNet可以很好的解决梯度消失的问题（其实是缓解，并不能真正解决），ResNet增加了<strong><em>shortcut连边</em></strong>。<br><img src="/images/CNN/18.png" alt=""></p><h4 id="10、ResNeXt"><a href="#10、ResNeXt" class="headerlink" title="10、ResNeXt"></a>10、ResNeXt</h4><p>基于ResNet和Inception的split+transform+concate结合。但效果却比ResNet、Inception、Inception-ResNet效果都要好。可以使用<strong><em>group convolution</em></strong>。一般来说增加网络表达能力的途径有三种：1.增加网络深度，如从AlexNet到ResNet，但是实验结果表明由网络深度带来的提升越来越小；2.增加网络模块的宽度，但是宽度的增加必然带来指数级的参数规模提升，也非主流CNN设计；3.改善CNN网络结构设计，如Inception系列和ResNeXt等。且实验发现增加Cardinatity即一个block中所具有的相同分支的数目可以更好的提升模型表达能力。<br><img src="/images/CNN/19.png" alt=""><br><img src="/images/CNN/20.png" alt=""></p><h4 id="11、DenseNet"><a href="#11、DenseNet" class="headerlink" title="11、DenseNet"></a>11、DenseNet</h4><p>DenseNet通过<strong><em>特征重用</em></strong>来大幅减少网络的参数量，又在一定程度上缓解了梯度消失问题。<br><img src="/images/CNN/21.png" alt=""></p><h4 id="12、SqueezeNet"><a href="#12、SqueezeNet" class="headerlink" title="12、SqueezeNet"></a>12、SqueezeNet</h4><p>提出了fire-module：squeeze层+expand层。Squeeze层就是1×1卷积，expand层用1×1和3×3分别卷积，然后concatenation。squeezeNet参数是alexnet的1/50，经过压缩之后是1/510，但是准确率和alexnet相当。<br><img src="/images/CNN/22.png" alt=""></p><h4 id="13、ShuffleNet系列"><a href="#13、ShuffleNet系列" class="headerlink" title="13、ShuffleNet系列"></a>13、ShuffleNet系列</h4><p><strong>V1</strong><br>通过分组卷积与1×1的逐点群卷积核来降低计算量，通过重组通道来丰富各个通道的信息。Xception和ResNeXt在小型网络模型中效率较低，因为大量的1×1卷积很耗资源，因此提出逐点群卷积来降低计算复杂度，但是使用逐点群卷积会有副作用，故在此基础上提出通道shuffle来帮助信息流通。虽然dw可以减少计算量和参数量，但是在低功耗设备上，与密集的操作相比，计算、存储访问的效率更差，故shufflenet上旨在bottleneck上使用深度卷积，尽可能减少开销。<br><img src="/images/CNN/23.png" alt=""></p><p><strong>V2</strong><br>使神经网络更加高效的CNN网络结构设计准则：</p><ol><li>输入通道数与输出通道数保持相等可以最小化内存访问成本。</li><li>分组卷积中使用过多的分组会增加内存访问成本。</li><li>网络结构太复杂（分支和基本单元过多）会降低网络的并行程度。</li><li>element-wise的操作消耗也不可忽略。</li></ol><p><img src="/images/CNN/24.png" alt=""></p><h4 id="14、SENet"><a href="#14、SENet" class="headerlink" title="14、SENet"></a>14、SENet</h4><p><img src="/images/CNN/25.png" alt=""></p><h4 id="15、SKNet"><a href="#15、SKNet" class="headerlink" title="15、SKNet"></a>15、SKNet</h4><p><img src="/images/CNN/26.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> CNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 商汤提出金字塔掩模文本检测器：PMTD</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E5%95%86%E6%B1%A4%E6%8F%90%E5%87%BA%E9%87%91%E5%AD%97%E5%A1%94%E6%8E%A9%E6%A8%A1%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E5%99%A8%EF%BC%9APMTD/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E5%95%86%E6%B1%A4%E6%8F%90%E5%87%BA%E9%87%91%E5%AD%97%E5%A1%94%E6%8E%A9%E6%A8%A1%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E5%99%A8%EF%BC%9APMTD/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/PMTD/1.png" alt=""><br><strong>Pyramid Mask Text Detector</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Quadrilateral Text<br><strong>paper</strong>：<a href="https://arxiv.org/pdf/1903.11800.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1903.11800.pdf</a><br><strong>reference</strong>: Liu, Jingchao &amp; Liu, Xuebo &amp; Sheng, Jie &amp; Liang, Ding &amp; Li, Xin &amp; Liu, Qingjie. (2019). Pyramid Mask Text Detector.<br><strong>Github</strong>: 未开源</p><p>本文是商汤和香港中文大学联合发表并于 2019.03.28 挂在 arXiv 上，本文的方法在 ICDAR2017 MIT 数据集上，相比于之前最高的精确率提升了 5.83% 百分点，达到 80.13%；在 ICDAR2015 数据集上，提升了 1.34% 个百分点，达到 89.33%。</p><h4 id="论文主要思想"><a href="#论文主要思想" class="headerlink" title="论文主要思想"></a>论文主要思想</h4><p>本文提出了 Pyramid Mask 文本检测器，简称 PMTD。它主要做了如下工作：</p><ol><li>提出了软语义分割的训练数据标签。与现有的基于 Mask RCNN 方法（文本区域内的像素标签为 0 或 1）不同，本文针对文本区域和背景区域提出了软语义分割（soft semantic segmentation），文本行区域内的像素标签值范围在 0-1 之间，不同位置的像素标签值是由其当前位置到文本边界框的距离决定的，这样做的好处是可以考虑训练数据的形状和位置信息，同时可以一定程度上缓解文本边界区域的一些背景干扰；</li><li>提出通过平面聚类的方法构建最终的文本行。通过像素坐标及对应像素点的得分构建 3D 点集合，然后通过金字塔平面聚类的迭代方法得到最终的文本行。</li></ol><p><img src="/images/PMTD/2.png" alt=""></p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>文中做了两个实验：baseline 和 PMTD。baseline 是基于 Mask RCNN 的，主干提取特征网络采用的是 ResNet50，网络结构采用了 FPN。相比原生的 Mask RCNN，做了 3 方面修改：1）数据增广；2）RPN anchor；3）OHEM。</p><h4 id="baseline存在的问题"><a href="#baseline存在的问题" class="headerlink" title="baseline存在的问题"></a>baseline存在的问题</h4><ol><li>没有考虑普通文本一般是四边形，仅按照像素进行分类，丢失了与形状相关的信息；</li><li>将文本行的四边形的标定转换为像素级别的 groundtruth 会造成 groundtruth 不准的问题；</li><li>在 Mask R-CNN 中是先得到检测的框，然后对框内的物体进行分割，如果框的位置不准确，这样会导致分割出来的结果也不会准确。</li></ol><h4 id="PMTD所做的改进"><a href="#PMTD所做的改进" class="headerlink" title="PMTD所做的改进"></a>PMTD所做的改进</h4><p>PMTD 是针对 baseline 中存在的问题提出的改进，主要包括：</p><ol><li>网络结构的改进：PMTD 采用了更大的感受野来获取更高的准确率，为了获取更大的感受野，本文通过改变 mask 分支，将该分支中的前 4 个卷积层改成步长为 2 的空洞卷积，因为反卷积操作会带来棋盘效应，所以这里采用双线性采样＋卷积层来替换反卷积层；</li><li>对于训练标签生成部分，使用了金字塔标签生成，具体做法是：文本行的中心点为金字塔的顶点（score=1），文本行的边为金字塔的底边，对金字塔的每个面中应该包含哪些像素点采用双线性插值的方法。</li></ol><p><img src="/images/PMTD/3.png" alt=""></p><h4 id="最终文本行的生成"><a href="#最终文本行的生成" class="headerlink" title="最终文本行的生成"></a>最终文本行的生成</h4><p>文中使用了平面聚类的方法，用于迭代回归从已学习到的 soft text mask 寻找最佳的文本行的边界框。在具体操作时，可以看成与金字塔标签生成的反过程。<br><img src="/images/PMTD/4.png" alt=""><br><img src="/images/PMTD/5.png" alt=""><br><img src="/images/PMTD/6.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> PMTD </tag>
            
            <tag> 商汤 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ECCV2018 | 旷视科技提出弯曲文本表示TextSnake</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/ECCV2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E5%BC%AF%E6%9B%B2%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BATextSnake/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/ECCV2018-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BA%E5%BC%AF%E6%9B%B2%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BATextSnake/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes</strong><br><strong>KeyWords Plus</strong>: ECCV2018 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1807.01544" target="_blank" rel="noopener">https://arxiv.org/abs/1807.01544</a><br><strong>reference</strong>: Long S, Ruan J, Zhang W, et al. Textsnake: A flexible representation for detecting text of arbitrary shapes[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 20-36.<br><strong>Github</strong>: <a href="https://github.com/princewang1994/TextSnake.pytorch" target="_blank" rel="noopener">https://github.com/princewang1994/TextSnake.pytorch</a></p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> TextSnake </tag>
            
            <tag> ECCV2018 </tag>
            
            <tag> 旷视 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | NAVER提出字符级别的文本检测网络：CRAFT</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-NAVER%E6%8F%90%E5%87%BA%E5%AD%97%E7%AC%A6%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%EF%BC%9ACRAFT/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-NAVER%E6%8F%90%E5%87%BA%E5%AD%97%E7%AC%A6%E7%BA%A7%E5%88%AB%E7%9A%84%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%EF%BC%9ACRAFT/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/CRAFT/1.png" alt=""><br><strong>Character Region Awareness for Text Detection</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1904.01941" target="_blank" rel="noopener">https://arxiv.org/abs/1904.01941</a><br><strong>reference</strong>: Baek Y, Lee B, Han D, et al. Character Region Awareness for Text Detection[J]. arXiv preprint arXiv:1904.01941, 2019.<br><strong>NAVER</strong>：line的母公司，韩国的最大的互联网公司，字符级别的文字检测，采用了CAM热力图的操作去检测每一个字符。<br><strong>Github</strong>: 未开源</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>字符级别的文本检测网络，用分水岭算法生成label，采用heatmaps去得到激活值最大的目标区域，有点类似attention。</p><h4 id="1、论文创新点"><a href="#1、论文创新点" class="headerlink" title="1、论文创新点"></a>1、论文创新点</h4><ol><li>提出了一种字符级别的文本检测算法;</li><li>预测得到:1.<strong>The character region score</strong> 2. <strong>Affinity score</strong>. The region score is used to <strong>localize individual characters</strong> in the image, and the affinity score is used to <strong>group each character into a single instance</strong>.</li><li>Propose a <strong>weakly-supervised learning framework</strong> that estimates character-level groundtruths in existing real word-level datasets.</li></ol><p><img src="/images/CRAFT/2.png" alt=""></p><h4 id="2、算法主体"><a href="#2、算法主体" class="headerlink" title="2、算法主体"></a>2、算法主体</h4><p>该论文主要预测<strong>每个字符区域和字符之间的紧密程度</strong>，因为没有字符级别的标注，所以模型训练是在<strong>弱监督的方式</strong>下。网络的backbone采用VGG16，之后接上采样，最终输出两个通道：<strong>the region score and the affinity score</strong>。<br><img src="/images/CRAFT/3.png" alt=""><br>训练在<strong>弱监督学习的方式</strong>下，首先有人造合成的数据集，具有字符级别的label；然后real image没有字符级别的标注时，网络检测合成产生label再进行训练。如上图所示，对真实场景中的数据集和人造合成的数据集分别有不同的训练方式。</p><h4 id="3、label-generation"><a href="#3、label-generation" class="headerlink" title="3、label generation"></a>3、label generation</h4><p><img src="/images/CRAFT/4.png" alt=""><br>分别产生<strong>Region Score GT和Affinity Score GT</strong>。<br>The following steps to approximate and generate the ground truth for both the region score and the affinity score:<br>1) prepare a <strong>2-dimensional isotropic Gaussian map</strong>;<br>2) compute <strong>perspective transform</strong> between the Gaussian map region and each character box;<br>3) <strong>warp Gaussian map</strong> to the box area.<br>使用小感受野也能预测大文本和长文本，只需要关注字符级别的内容而不需要关注整个文本实例。<br><img src="/images/CRAFT/5.png" alt=""><br>分三步产生字符级别的label： </p><ol><li>抠出文本级别的内容；</li><li>预测region score区域；</li><li>运用分水岭算法；</li><li>得到字符基本的文字框;</li><li>贴上文字框;</li></ol><p>为了防止在弱监督方式下产生的错误label带偏网络，该论文提出了一种评价方式:<br><img src="/images/CRAFT/6.png" alt=""></p><h4 id="4、Post-processing"><a href="#4、Post-processing" class="headerlink" title="4、Post-processing"></a>4、Post-processing</h4><p>规则文本后处理可以分为以下几步：</p><ol><li>首先对0-1之间的概率图进行取阈值计算；</li><li>使用 Connected Component Labeling(CCL) 进行区域连接；</li><li>最后使用 OpenCV 的 MinAreaRect 框出最小的四边形区域。</li></ol><p><img src="/images/CRAFT/7.png" alt=""><br>不规则文本检测后处理可以分为以下几步（如上图所示）：</p><ol><li>先找到扫描方向的局部最大值（blue line）；</li><li>连接所有the local maxima上的中心点叫做中心线；</li><li>然后将the local maxima lines旋转至于中心线垂直 </li><li>the local maxima lines上的端点是文本控制点的候选点，为了能更好的覆盖文本，将文本最外端的两个控制点分别向外移动the local maxima lines的半径长度最为最终的控制点。</li></ol><h4 id="5、Experiment-Results"><a href="#5、Experiment-Results" class="headerlink" title="5、Experiment Results"></a>5、Experiment Results</h4><p><img src="/images/CRAFT/8.png" alt=""><br><img src="/images/CRAFT/9.png" alt=""><br><img src="/images/CRAFT/10.png" alt=""><br><img src="/images/CRAFT/11.png" alt=""></p><h4 id="6、Conclusion-and-Future-work"><a href="#6、Conclusion-and-Future-work" class="headerlink" title="6、Conclusion and Future work"></a>6、Conclusion and Future work</h4><p>个人观点：<strong>不太受感受野的限制，只关注单个文字，对于长文本和不规则文本不必特意去设置相应大小的卷积提升感受野</strong>。</p><div class="row">    <embed src="/pdf/CRAFT.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CRAFT </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> NAVER </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 百度提出LOMO文本检测算法</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E7%99%BE%E5%BA%A6%E6%8F%90%E5%87%BALOMO%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E7%99%BE%E5%BA%A6%E6%8F%90%E5%87%BALOMO%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/LOMO/1.png" alt=""><br><strong>Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text Baidu Inc<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1904.06535" target="_blank" rel="noopener">https://arxiv.org/abs/1904.06535</a><br><strong>reference</strong>: Zhang C, Liang B, Huang Z, et al. Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes[J]. arXiv preprint arXiv:1904.06535, 2019.<br><strong>Github</strong>: 未开源</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这是百度和厦门大学合作的一篇文章。由于受CNN感受野的限制以及用于描述文本的类似矩形框或者四边形这样的简单的表示方法，当处理更加有挑战的文本实例时，比如极其长的文本和任意形状的文本，之前的一些方法就不适用了。而本文提出的这种方法，正是为了解决这两个问题。</p><h4 id="1、论文主要贡献"><a href="#1、论文主要贡献" class="headerlink" title="1、论文主要贡献"></a>1、论文主要贡献</h4><p>（1）Propose an iterative refinement module(<strong>IRM</strong>) which improves the performance of <strong>long scene text detection</strong>.<br>（2）An instance-level shape expression module(<strong>SEM</strong>) is introduced to solve the problem of <strong>detecting scene text of arbitrary shapes</strong>.<br>（3）LOMO with <strong>iterative refinement module</strong> and <strong>shape expression module</strong> can be trained in an end-to-end manner and achieves state-of-the-art performance on several benchmarks including text instances of different forms (<strong>oriented, long, multi-lingual and curved</strong>).</p><h4 id="2、网络结构"><a href="#2、网络结构" class="headerlink" title="2、网络结构"></a>2、网络结构</h4><p>（1）将图像输入到backbone中，抽取 <strong>DR, IRM 和 SEM</strong> 三个分支的共享特征图。backbone用的是<strong>ResNet50 + FPN</strong>，在ResNet50中的stage-2, stage-3, stage-4 和 stage-5 的特征图被有效合并。<br>（2）采用类似 EAST 和 Deep Regression 的一个<strong>direct regression network</strong>作为 <strong>DR</strong> 分支，以一种逐像素的方式去预测单词或文本行的四边形。<br>（3）IRM 可以迭代式的调整从 DR 输出的或者 IRM 自身的建议，使它们更接近于groundtruth bounding box。<br>（4）为了获得文本的紧凑表示，尤其是不规则的文本，因为四边形的建议形式会覆盖太多的背景区域，通过学习文本的几何性质包括<strong>text region, text center line and border offsets (center line 和 upper/lower border lines之间的距离)</strong>，SEM会重建文本实例的形状表示。<br><img src="/images/LOMO/2.png" alt=""></p><h4 id="3、Direct-Regressor（DR）"><a href="#3、Direct-Regressor（DR）" class="headerlink" title="3、Direct Regressor（DR）"></a>3、Direct Regressor（DR）</h4><p>DR模块采用的是一个<strong>fully convolutional sub-network</strong>。DR分支的损失函数由两部分组成：<strong>text/non-text classification term and location regression term</strong>。<br>第一部分文本分类的损失函数使用的是<strong>scale-invariant dice-coefficient</strong>函数，用于提升 DR 的尺度泛化能力。<br><img src="/images/LOMO/3.png" alt=""><br>第二部分位置回归的损失函数采用的是<strong>smooth L1 loss</strong>。将这两项结合到一起，DR的整个损失函数可以表示为：<br><img src="/images/LOMO/4.png" alt=""></p><h4 id="4、Iterative-Refinement-Module（IRM）"><a href="#4、Iterative-Refinement-Module（IRM）" class="headerlink" title="4、Iterative Refinement Module（IRM）"></a>4、Iterative Refinement Module（IRM）</h4><p><img src="/images/LOMO/5.png" alt=""><br>在训练阶段，保留来自于DR的K个初步的检测四边形。<strong>corner regression loss</strong>可以表示为：<br><img src="/images/LOMO/6.png" alt=""></p><h4 id="5、Shape-Expression-Module（SEM）"><a href="#5、Shape-Expression-Module（SEM）" class="headerlink" title="5、Shape Expression Module（SEM）"></a>5、Shape Expression Module（SEM）</h4><p><strong>Text region</strong>是一个二值 mask, 里面的 foreground pixels （比如在多边形标注区域内部的）标记为 1，background pixels 标记为 0.<br><strong>Text center line</strong> 也是一个二值 mask ，不同的是，它是基于文本多边形标注的 side-shrunk version .<br><strong>Border offsets</strong> 为四通道图, 在文本行图对应位置上的正响应区域内，具有有效的值。<br><img src="/images/LOMO/7.png" alt=""><br>SEM 的目标函数定义如下，其中 Ltr 和 Ltcl 使用<strong>dice-coefficient loss</strong>，Lborder 使用<strong>smooth L1 loss</strong>：<br><img src="/images/LOMO/8.png" alt=""></p><h4 id="6、Text-Polygon-Generation"><a href="#6、Text-Polygon-Generation" class="headerlink" title="6、Text Polygon Generation"></a>6、Text Polygon Generation</h4><p>文本多边形生成策略包括三步：<br>（1）<strong>center line sampling</strong>： 在预测的文本中心线图上从左到右以等距离间隔采样n个点。<br>（2）<strong>border points generation</strong>： 基于采样中心线点，考虑同一位置由4个边界偏移图提供的信息，确定相应的边界点。通过顺时针连接所有的边界点，获得完整的文本多边形表示。<br>（3）<strong>polygon scoring</strong>: 计算多边形内的文本区域响应的均值，作为新的 confidence score。</p><h4 id="7、Training-and-Inference"><a href="#7、Training-and-Inference" class="headerlink" title="7、Training and Inference"></a>7、Training and Inference</h4><p>整个的损失函数表示为:<br><img src="/images/LOMO/9.png" alt=""><br><strong>Training</strong>: 训练过程分为两个阶段：<strong>warming-up</strong> 和 <strong>fine-tuning</strong>.<br>1）在 warming-up 阶段, 使用合成数据集训练 DR 部分，迭代 10 epochs.<br>2）在 fine-tuning 阶段, 在真实数据集上 fine-tune 所有的三个分支，包括 ICDAR2015, ICDAR2017-RCTW, SCUT-CTW1500, Total-Text 和 ICDAR2017-MLT，迭代大约 10 epochs.<br><strong>Inference</strong>:<br>1）DR 生成四边形的 score map 和 geometry maps, 然后用 NMS 生成初步的 proposals.<br>2）Proposals 和 shared feature maps 全部输入到 IRM 中 refine 多次.<br>3）Refined quadrangles 和 shared feature maps 输入到 SEM 中，生成精确的 text polygons 和 confidence scores.<br>4）阈值 s 用于移除 low-confidence 的多边形.</p><h4 id="8、Datasets"><a href="#8、Datasets" class="headerlink" title="8、Datasets"></a>8、Datasets</h4><p><strong>ICDAR 2015</strong><br>It consists of <strong>1000 natural images for training and 500 for testing</strong>. The ground truth is annotated with <strong>word-level quadrangle</strong>.<br><strong>ICDAR2017-MLT</strong><br>A <strong>large scale multi-lingual</strong> text dataset, which includes <strong>7200 training images, 1800 validation images and 9000 test images</strong>. The dataset consists of scene text images which come from 9 languages. The text regions in ICDAR2017-MLT are also annotated by <strong>4 vertices of the quadrangle</strong>.<br><strong>ICDAR2017-RCTW</strong><br>It comprises <strong>8034 training images and 4229 test images</strong> with scene texts printed in either Chinese or English. <strong>Multi-oriented words and text lines</strong> are annotated using <strong>quadrangles</strong>.<br><strong>SCUT-CTW1500</strong><br>It consists of <strong>1000 training images and 500 test images</strong>. The text instances are labelled by <strong>polygons with 14 vertices</strong>.<br><strong>Total-Text</strong><br>A <strong>curved text</strong> benchmarks, which consist of <strong>1255 training images and 300 testing images</strong>. The annotations are labelled in <strong>word-level</strong>.</p><h4 id="9、Experiments"><a href="#9、Experiments" class="headerlink" title="9、Experiments"></a>9、Experiments</h4><p>For all datasets, we randomly crop the text regions and resize them to 512×512. The cropped image regions will be rotated randomly in 4 directions including 0◦, 90◦, 180◦ and 270◦.<br><img src="/images/LOMO/10.png" alt=""><br><img src="/images/LOMO/11.png" alt=""><br><img src="/images/LOMO/12.png" alt=""><br><img src="/images/LOMO/13.png" alt=""><br><img src="/images/LOMO/14.png" alt=""></p><h4 id="10、Conclusion-and-Future-Work"><a href="#10、Conclusion-and-Future-Work" class="headerlink" title="10、Conclusion and Future Work"></a>10、Conclusion and Future Work</h4><p>这篇论文主要解决长文本和弯曲文本的检测问题，LOMO由 DR, IRM and SEM 三个模块组成。DR初步产生文本建议。IRM迭代式的调整DR生成的文本建议。SEM重建不规则文本的精确表示。</p>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> LOMO </tag>
            
            <tag> 百度 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习与深度学习常见问题总结（下）</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="1、为什么随机森林能降低方差？"><a href="#1、为什么随机森林能降低方差？" class="headerlink" title="1、为什么随机森林能降低方差？"></a>1、为什么随机森林能降低方差？</h4><p>随机森林的预测输出值是多棵决策树的均值，如果有n个独立同分布的随机变量xi，它们的方差都为σ^2，则它们的均值的方差为：<br><img src="/images/深度学习2.png" alt=""></p><h4 id="2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？"><a href="#2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？" class="headerlink" title="2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？"></a>2、对于带等式和不等式约束的优化问题，KKT条件是取得极值的充分条件还是必要条件？对于SVM呢？</h4><p>对于一个一般的问题，KKT条件是取得极值的必要条件而不是充分条件。对于凸优化问题，则是充分条件，SVM是凸优化问题。</p><h4 id="3、解释维数灾难的概念。"><a href="#3、解释维数灾难的概念。" class="headerlink" title="3、解释维数灾难的概念。"></a>3、解释维数灾难的概念。</h4><p>当特征向量数值很少时，增加特征，可以提高算法的精度，但当特征向量的维数增加到一定数量之后，再增加特征，算法的精度反而会下降。</p><h4 id="4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？"><a href="#4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？" class="headerlink" title="4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？"></a>4、Logistic回归为什么用交叉熵而不用欧氏距离做损失函数？</h4><p>如果用欧氏距离，不是凸函数，而用交叉熵则是凸函数。</p><h4 id="5、解释hinge-loss损失函数。"><a href="#5、解释hinge-loss损失函数。" class="headerlink" title="5、解释hinge loss损失函数。"></a>5、解释hinge loss损失函数。</h4><p>如果样本没有违反不等式约束，则损失为0；如果违反约束，则有一个正的损失值。</p><h4 id="6、解释GBDT的核心思想。"><a href="#6、解释GBDT的核心思想。" class="headerlink" title="6、解释GBDT的核心思想。"></a>6、解释GBDT的核心思想。</h4><p>用加法模拟，更准确的说，是多棵决策树来拟合一个目标函数。每一棵决策树拟合的是之前迭代得到的模型的残差。求解的时候，对目标函数使用了一阶泰勒展开，用梯度下降法来训练决策树。</p><h4 id="7、解释XGBoost的核心思想。"><a href="#7、解释XGBoost的核心思想。" class="headerlink" title="7、解释XGBoost的核心思想。"></a>7、解释XGBoost的核心思想。</h4><p>在GBDT的基础上，目标函数增加了正则化项，并且在求解时做了二阶泰勒展开。</p><h4 id="8、解释DQN中的经验回放机制，为什么需要这种机制？"><a href="#8、解释DQN中的经验回放机制，为什么需要这种机制？" class="headerlink" title="8、解释DQN中的经验回放机制，为什么需要这种机制？"></a>8、解释DQN中的经验回放机制，为什么需要这种机制？</h4><p>将执行动作后得到的状态转移构造的样本存储在一个列表中，然后从中随机抽样，来训练Q网络。为了解决训练样本之间的相关性，以及训练样本分布变化的问题。</p><h4 id="9、什么是反卷积？"><a href="#9、什么是反卷积？" class="headerlink" title="9、什么是反卷积？"></a>9、什么是反卷积？</h4><p>反卷积也称为转置卷积，如果用矩阵乘法实现卷积操作，将卷积核平铺为矩阵，则转置卷积在正向计算时左乘这个矩阵的转置W^T，在反向传播时左乘W，与卷积操作刚好相反，需要注意的是，反卷积不是卷积的逆运算。</p><h4 id="10、反卷积有哪些用途？"><a href="#10、反卷积有哪些用途？" class="headerlink" title="10、反卷积有哪些用途？"></a>10、反卷积有哪些用途？</h4><p>实现上采样；近似重构输入图像，卷积层可视化。</p><h4 id="11、PCA（主成分分析）优化的目标是什么？"><a href="#11、PCA（主成分分析）优化的目标是什么？" class="headerlink" title="11、PCA（主成分分析）优化的目标是什么？"></a>11、PCA（主成分分析）优化的目标是什么？</h4><p>最小化重构误差/最大化投影后的方差。</p><h4 id="12、LDA（线性判别分析）优化的目标是什么？"><a href="#12、LDA（线性判别分析）优化的目标是什么？" class="headerlink" title="12、LDA（线性判别分析）优化的目标是什么？"></a>12、LDA（线性判别分析）优化的目标是什么？</h4><p>最大化类间差异与类内差异的比值。</p><h4 id="13、解释神经网络的万能逼近定理。"><a href="#13、解释神经网络的万能逼近定理。" class="headerlink" title="13、解释神经网络的万能逼近定理。"></a>13、解释神经网络的万能逼近定理。</h4><p>只要激活函数选择得当，神经元的数值足够，至少有一个隐含层的神经网络可以逼近闭区间上任意一个连续函数到任意指定的精度。</p><h4 id="14、softmax回归训练时的目标函数是凸函数吗？"><a href="#14、softmax回归训练时的目标函数是凸函数吗？" class="headerlink" title="14、softmax回归训练时的目标函数是凸函数吗？"></a>14、softmax回归训练时的目标函数是凸函数吗？</h4><p>是，但有不止一个全局最优解。</p><h4 id="15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？"><a href="#15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？" class="headerlink" title="15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？"></a>15、SVM为什么要求解对偶问题？为什么对偶问题与原问题等价？</h4><p>原问题不容易求解，含有大量的不易处理的不等式约束。原问题满足Slater条件，强对偶成立，因此原问题与对偶问题等价。</p><h4 id="16、神经网络是生成模型还是判别模型？"><a href="#16、神经网络是生成模型还是判别模型？" class="headerlink" title="16、神经网络是生成模型还是判别模型？"></a>16、神经网络是生成模型还是判别模型？</h4><p>判别模型，直接输出类别标签，或者输出类后验概率p(y|x)。</p><h4 id="17、logistic回归是生成模型还是判别模型？"><a href="#17、logistic回归是生成模型还是判别模型？" class="headerlink" title="17、logistic回归是生成模型还是判别模型？"></a>17、logistic回归是生成模型还是判别模型？</h4><p>判别模型，直接输出类后验概率p(y|x)，没有对类条件概率p(x|y)或者联合概率p(x, y)建模。</p><h4 id="18、Batch-Normalization-和-Group-Normalization有何区别？"><a href="#18、Batch-Normalization-和-Group-Normalization有何区别？" class="headerlink" title="18、Batch Normalization 和 Group Normalization有何区别？"></a>18、Batch Normalization 和 Group Normalization有何区别？</h4><p>BN是在batch这个维度上进行归一化，GN是计算channel方向每个group的均值和方差。</p><h4 id="19、GAN中模型坍塌（model-collapse）是指什么？"><a href="#19、GAN中模型坍塌（model-collapse）是指什么？" class="headerlink" title="19、GAN中模型坍塌（model collapse）是指什么？"></a>19、GAN中模型坍塌（model collapse）是指什么？</h4><p>模型坍塌，即产生的样本单一，没有了多样性。</p><h4 id="20、目前GAN训练中存在的主要问题是什么？"><a href="#20、目前GAN训练中存在的主要问题是什么？" class="headerlink" title="20、目前GAN训练中存在的主要问题是什么？"></a>20、目前GAN训练中存在的主要问题是什么？</h4><p>（1）训练不易收敛；<br>（2）模型坍塌。</p><h4 id="21、Shufflenet为什么效果会好？"><a href="#21、Shufflenet为什么效果会好？" class="headerlink" title="21、Shufflenet为什么效果会好？"></a>21、Shufflenet为什么效果会好？</h4><p>通过引入“通道重排”增加了组与组之间信息交换。</p><h4 id="22、模型压缩的主要方法有哪些？"><a href="#22、模型压缩的主要方法有哪些？" class="headerlink" title="22、模型压缩的主要方法有哪些？"></a>22、模型压缩的主要方法有哪些？</h4><p>（1）从模型结构上优化：模型剪枝、模型蒸馏、automl直接学习出简单的结构。<br>（2）从模型参数上量化：将FP32的数值精度量化到FP16、INT8、二值网络、三值网络等。</p><h4 id="23、目标检测中IOU是如何计算的？"><a href="#23、目标检测中IOU是如何计算的？" class="headerlink" title="23、目标检测中IOU是如何计算的？"></a>23、目标检测中IOU是如何计算的？</h4><p>检测结果与 Ground Truth 的交集比上它们的并集，即为检测的准确率 IoU。<br><img src="/images/深度学习3.png" alt=""></p><h4 id="24、给定0-1矩阵，如何求连通域？"><a href="#24、给定0-1矩阵，如何求连通域？" class="headerlink" title="24、给定0-1矩阵，如何求连通域？"></a>24、给定0-1矩阵，如何求连通域？</h4><p>可采用广度优先搜索。</p><h4 id="25、OCR任务中文本序列识别的主流方法是什么？"><a href="#25、OCR任务中文本序列识别的主流方法是什么？" class="headerlink" title="25、OCR任务中文本序列识别的主流方法是什么？"></a>25、OCR任务中文本序列识别的主流方法是什么？</h4><p>RNN+CTC。</p><h4 id="26、在神经网络体系结构中，哪些会有权重共享？"><a href="#26、在神经网络体系结构中，哪些会有权重共享？" class="headerlink" title="26、在神经网络体系结构中，哪些会有权重共享？"></a>26、在神经网络体系结构中，哪些会有权重共享？</h4><p>（1）卷积神经网络CNN<br>（2）递归神经网络RNN</p><h4 id="27、一个典型人脸识别系统的识别流程？"><a href="#27、一个典型人脸识别系统的识别流程？" class="headerlink" title="27、一个典型人脸识别系统的识别流程？"></a>27、一个典型人脸识别系统的识别流程？</h4><p>人脸检测–&gt;人脸对齐–&gt;人脸特征提取–&gt;人脸特征比对。</p><h4 id="28、平面内有两个矩形，如何快速计算它们的IOU？"><a href="#28、平面内有两个矩形，如何快速计算它们的IOU？" class="headerlink" title="28、平面内有两个矩形，如何快速计算它们的IOU？"></a>28、平面内有两个矩形，如何快速计算它们的IOU？</h4><p><img src="/images/深度学习4.png" alt=""></p><h4 id="29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？"><a href="#29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？" class="headerlink" title="29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？"></a>29、使用深度卷积网络做图像分类如果训练一个拥有1000万个类的模型会碰到什么问题？</h4><p>提示：内存/显存占用；模型收敛速度等。</p><h4 id="30、HMM和CRF的区别？"><a href="#30、HMM和CRF的区别？" class="headerlink" title="30、HMM和CRF的区别？"></a>30、HMM和CRF的区别？</h4><p>前者描述的是 P(X,Y)=P(X|Y)*P(Y)，是 generative model；后者描述的是 P(Y|X)，是 discriminative model。前者要加入对状态概率分布的先验知识，而后者完全是 data driven。</p><h4 id="31、深度学习中为什么不用二阶导去优化？"><a href="#31、深度学习中为什么不用二阶导去优化？" class="headerlink" title="31、深度学习中为什么不用二阶导去优化？"></a>31、深度学习中为什么不用二阶导去优化？</h4><p>Hessian矩阵是n*n，在高维情况下这个矩阵非常大，计算和存储都是问题。</p><h4 id="32、深度机器学习中的mini-batch的大小对学习效果有何影响？"><a href="#32、深度机器学习中的mini-batch的大小对学习效果有何影响？" class="headerlink" title="32、深度机器学习中的mini-batch的大小对学习效果有何影响？"></a>32、深度机器学习中的mini-batch的大小对学习效果有何影响？</h4><p>mini-batch太小会导致收敛变慢，太大容易陷入sharp minima，泛化性不好。</p><h4 id="33、线性回归对于数据的假设是怎样的？"><a href="#33、线性回归对于数据的假设是怎样的？" class="headerlink" title="33、线性回归对于数据的假设是怎样的？"></a>33、线性回归对于数据的假设是怎样的？</h4><p><a href="http://en.wikipedia.org/wiki/Linear_regression" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Linear_regression</a><br>（1）线性，y是多个自变量x之间的线性组合；<br>（2）同方差性，不同的因变量x的方差都是相同的；<br>（3）弱外生性，假设用来预测的自变量x是没有测量误差的；<br>（4）预测变量之中没有多重共线性。</p><h4 id="34、什么是共线性，跟过拟合有啥关联"><a href="#34、什么是共线性，跟过拟合有啥关联" class="headerlink" title="34、什么是共线性，跟过拟合有啥关联?"></a>34、什么是共线性，跟过拟合有啥关联?</h4><p>共线性：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。<br>结果：共线性会造成冗余，导致过拟合。<br>解决方法：排除变量的相关性／加入权重正则。</p><h4 id="35、Bias和Variance的区别？"><a href="#35、Bias和Variance的区别？" class="headerlink" title="35、Bias和Variance的区别？"></a>35、Bias和Variance的区别？</h4><p><strong>Bias</strong>度量了学习算法的期望预测与真实结果的偏离程度，即刻画了算法本身的拟合能力。<br><strong>Variance</strong>度量了同样大小的训练集的变动所导致的学习性能变化，即刻画了数据扰动所造成的影响。</p><h4 id="36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？"><a href="#36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？" class="headerlink" title="36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？"></a>36、对于支持向量机，高斯核一般比线性核有更好的精度，但实际应用中为什么一般用线性核而不用高斯核？</h4><p>如果训练样本的量很大，训练得到的模型中支持向量的数量太多，在每次做预测时，高斯核需要计算待预测样本与每个支持向量的内积，然后做核函数变换，这会非常耗时；而线性核只需计算 W^T * X + b。</p><h4 id="37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？"><a href="#37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？" class="headerlink" title="37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？"></a>37、高斯混合模型中，为什么各个高斯分量的权重之和要保证为1？</h4><p>为了保证这个函数是一个概率密度函数，即积分值为1。</p><h4 id="38、介绍beam-search算法的原理。"><a href="#38、介绍beam-search算法的原理。" class="headerlink" title="38、介绍beam search算法的原理。"></a>38、介绍beam search算法的原理。</h4><p>这是一种解码算法，每次选择概率最大的几个解作为候选解，逐步扩展。</p><h4 id="39、介绍seq2seq的原理。"><a href="#39、介绍seq2seq的原理。" class="headerlink" title="39、介绍seq2seq的原理。"></a>39、介绍seq2seq的原理。</h4><p>整个系统由两个RNN组成，一个充当编码器，一个充当解码器；编码器依次接收输入的序列数据，当最后一个数据点输入之后，将循环层的状态向量作为语义向量，与解码器网络的输入向量一起，送入解码器中进行预测。</p><h4 id="40、介绍CTC的原理。"><a href="#40、介绍CTC的原理。" class="headerlink" title="40、介绍CTC的原理。"></a>40、介绍CTC的原理。</h4><p>CTC通过引入空白符号，以及消除连续的相同符号，将RNN原始的输出序列映射为最终的目标序列。可以解决对未对齐的序列数据进行预测的问题，如语音识别。</p><h4 id="41、介绍广义加法模型的原理。"><a href="#41、介绍广义加法模型的原理。" class="headerlink" title="41、介绍广义加法模型的原理。"></a>41、介绍广义加法模型的原理。</h4><p>广义加法模型用多个基函数的和来拟合目标函数，训练的时候，依次确定每个基函数。</p><h4 id="42、为什么很多时候用正态分布来对随机变量建模？"><a href="#42、为什么很多时候用正态分布来对随机变量建模？" class="headerlink" title="42、为什么很多时候用正态分布来对随机变量建模？"></a>42、为什么很多时候用正态分布来对随机变量建模？</h4><p>现实世界中很多变量都服从或近似服从正态分布。中心极限定理指出，抽样得到的多个独立同分布的随机变量样本，当样本数趋向于正无穷时，它们的和服从正态分布。</p>]]></content>
      
      <categories>
          
          <category> 机器学习与深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CVPR2019 | 旷视科技提出PSENet文本检测算法</title>
      <link href="/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BAPSENet%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"/>
      <url>/%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B/CVPR2019-%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80%E6%8F%90%E5%87%BAPSENet%E6%96%87%E6%9C%AC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/images/PSENet/1.png" alt=""><br><strong>Shape Robust Text Detection with Progressive Scale Expansion Network</strong><br><strong>KeyWords Plus</strong>: CVPR2019 Curved Text Face++<br><strong>paper</strong>：<a href="https://arxiv.org/abs/1903.12473" target="_blank" rel="noopener">https://arxiv.org/abs/1903.12473</a><br><strong>reference</strong>: Wang W, Xie E, Li X, et al. Shape Robust Text Detection with Progressive Scale Expansion Network[J]. arXiv preprint arXiv:1903.12473, 2019.<br><strong>Github(tensorflow)</strong>: <a href="https://github.com/whai362/PSENet" target="_blank" rel="noopener">https://github.com/whai362/PSENet</a><br><strong>Github(pytorch)</strong>: <a href="https://github.com/WenmuZhou/PSENet.pytorch" target="_blank" rel="noopener">https://github.com/WenmuZhou/PSENet.pytorch</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>PSENet 分好几个版本，最新的一个是19年的CVPR，这是一篇南京大学和face++合作的文章，19年出现了很多不规则文本检测算法，TextMountain、Textfield等等。</p><h4 id="1、论文创新点"><a href="#1、论文创新点" class="headerlink" title="1、论文创新点"></a>1、论文创新点</h4><ol><li>Propose a novel kernel-based framework, namely, <strong>Progressive Scale Expansion Network (PSENet)</strong></li><li>Adopt a progressive scale expansion algorithm based on <strong>Breadth-First-Search (BFS)</strong>:<br>1) Starting from the kernels with <strong>minimal scales</strong> (instances can be distinguished in this step).<br>2) <strong>Expanding their areas</strong> by involving more pixels in larger kernels gradually.<br>3) Finishing until the complete text instances (<strong>the largest kernels</strong>) are explored.</li></ol><p>这个文章主要做的创新点大概就是<strong>预测多个分割结果，分别是S1,S2,S3…Sn</strong>代表不同的等级面积的结果，S1最小，基本就是文本骨架，Sn最大，就是完整的文本实例。然后在后处理的过程中，先用<strong>最小的预测结果去区分文本，再逐步扩张成正常文本大小</strong>。<br><img src="/images/PSENet/2.png" alt=""></p><h4 id="2、算法主体"><a href="#2、算法主体" class="headerlink" title="2、算法主体"></a>2、算法主体</h4><p><img src="/images/PSENet/3.png" alt=""><br>We firstly get four 256 channels feature maps(<strong>i.e. P2, P3, P4, P5</strong>)from the backbone. To further combine the semantic features from low to high levels, we fuse the four feature maps to get <strong>feature map F with 1024 channels</strong> via the function C(·) as:<br><img src="/images/PSENet/4.png" alt=""><br>先backbone下采样得到<strong>四层的feature maps</strong>，再通过<strong>FPN</strong>对四层feature分别进行<strong>上采样2,4,8倍</strong>进行融合得到输出结果。<br>如上图所示，网络有三个分割结果，分别是S1,S2,S3.首先利用最小的kernel生成的<strong>S1来区分四个文本实例，然后再逐步扩张成S2和S3</strong>。</p><h4 id="3、label-generation"><a href="#3、label-generation" class="headerlink" title="3、label generation"></a>3、label generation</h4><p>产生不同尺寸的S1….Sn需要<strong>不同尺寸的labels</strong>。<br><img src="/images/PSENet/5.png" alt=""><br>不同尺寸的labels生成如上图所示，缩放比例可以用下面公式计算得出：<br><img src="/images/PSENet/6.png" alt=""><br>这个di表示的是缩小后mask边缘与正常mask边缘的距离，缩放比例rate ri可以由下面计算得出：<br><img src="/images/PSENet/7.png" alt=""><br>m是最小mask的比例，n在m到1之间的值，成线性增加。</p><h4 id="4、Loss-Function"><a href="#4、Loss-Function" class="headerlink" title="4、Loss Function"></a>4、Loss Function</h4><p>Loss 主要分为分类的<strong>text instance loss和shrunk losses</strong>，L是平衡这两个loss的参数。分类loss主要用了交叉熵和dice loss。<br><img src="/images/PSENet/8.png" alt=""><br>The dice coefficient <strong>D(Si, Gi)</strong> 被计算如下：<br><img src="/images/PSENet/9.png" alt=""><br>Ls被计算如下：<br><img src="/images/PSENet/10.png" alt=""></p><h4 id="5、Datasets"><a href="#5、Datasets" class="headerlink" title="5、Datasets"></a>5、Datasets</h4><p><strong>TotalText</strong><br>A newly-released dataset for curve text detection. <strong>Horizontal, multi-Oriented and curve text instances</strong> are contained in Total-Text. The benchmark consists of <strong>1255 training images and 300 testing images</strong>.</p><p><strong>CTW1500</strong><br>CTW1500 dataset mainly consisting of <strong>long curved text</strong>. It consists of <strong>1000 training images and 500 test images</strong>. Text instances are labelled by a polygon with 14 points which can describe the shape of an arbitrarily curve text.</p><p><strong>ICDAR 2015</strong><br>Icdar2015 is a commonly used dataset for text detection. It contains a total of <strong>1500 pictures</strong>, 1000 of which are used for training and the remaining are for testing. The text regions are annotated by 4 vertices of the quadrangle.</p><p><strong>ICDAR 2017 MLT</strong><br>ICDAR 2017 MIL is a large scale multi-lingual text dataset, which includes <strong>7200 training images, 1800 validation images and 9000 testing images</strong>. The dataset is composed of complete scene images which come from 9 languages.</p><h4 id="6、Experiment-Results"><a href="#6、Experiment-Results" class="headerlink" title="6、Experiment Results"></a>6、Experiment Results</h4><p><strong>Implementation Details</strong><br>All the networks are optimized by using stochastic gradient descent (SGD).The data augmentation for training data is listed as follows:<br>1) The images are rescaled with ratio {0.5, 1.0, 2.0, 3.0} randomly;<br>2) The images are horizontally flipped and rotated in the range [−10◦, 10◦] randomly;<br>3) 640 × 640 random samples are cropped from the transformed images.<br><img src="/images/PSENet/11.png" alt=""><br><img src="/images/PSENet/12.png" alt=""><br><img src="/images/PSENet/13.png" alt=""><br><img src="/images/PSENet/14.png" alt=""><br><img src="/images/PSENet/15.png" alt=""><br><img src="/images/PSENet/16.png" alt=""></p><h4 id="7、Conclusion-and-Future-work"><a href="#7、Conclusion-and-Future-work" class="headerlink" title="7、Conclusion and Future work"></a>7、Conclusion and Future work</h4><p>这个文章其实做的只是一件事情，就是<strong>用预测得到的小的mask区分文本，然后逐渐扩张形成正常大小的文本mask</strong>。</p><div class="row">    <embed src="/pdf/PSENet.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      <categories>
          
          <category> 文本检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文本检测 </tag>
            
            <tag> CVPR2019 </tag>
            
            <tag> PSENet </tag>
            
            <tag> 旷视科技 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习与深度学习常见问题总结（上）</title>
      <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="1、比较Boosting和Bagging的异同。"><a href="#1、比较Boosting和Bagging的异同。" class="headerlink" title="1、比较Boosting和Bagging的异同。"></a>1、比较Boosting和Bagging的异同。</h4><p>二者都是集成学习算法，都是将多个弱学习器组合成强学习器的方法。<br><strong>Bagging</strong>：从原始数据集中每一轮有放回地抽取训练集，训练得到k个弱学习器，将这k个弱学习器以投票的方式得到最终的分类结果。<br><strong>Boosting</strong>：每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重，训练得到k个弱分类器，他们都有各自的权重，通过加权组合的方式得到最终的分类结果。</p><h4 id="2、无监督学习中存在过拟合吗？"><a href="#2、无监督学习中存在过拟合吗？" class="headerlink" title="2、无监督学习中存在过拟合吗？"></a>2、无监督学习中存在过拟合吗？</h4><p>存在。我们可以使用无监督学习的某些指标或人为地去评估模型性能，以此来判断是否过拟合。</p><h4 id="3、什么是k折交叉验证？"><a href="#3、什么是k折交叉验证？" class="headerlink" title="3、什么是k折交叉验证？"></a>3、什么是k折交叉验证？</h4><p>将原始数据集划分为k个子集，将其中一个子集作为验证集，其余k-1个子集作为训练集，如此训练和验证一轮称为一次交叉验证。交叉验证重复k次，每个子集都做一次验证集，得到k个模型，加权平均k个模型的结果作为评估整体模型的依据。</p><h4 id="4、关于k折交叉验证，需要注意什么？"><a href="#4、关于k折交叉验证，需要注意什么？" class="headerlink" title="4、关于k折交叉验证，需要注意什么？"></a>4、关于k折交叉验证，需要注意什么？</h4><p>k越大，不一定效果越好，而且越大的k会加大训练时间；在选择k时，需要考虑最小化数据集之间的方差，比如对于2分类任务，采用2折交叉验证，即将原始数据集对半分，若此时训练集中都是A类别，验证集中都是B类别，则交叉验证效果会非常差。</p><h4 id="5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？"><a href="#5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？" class="headerlink" title="5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？"></a>5、对于一个二分类问题，我们定义超过阈值t的判定为正例，否则判定为负例。现在若将t增大，则准确率和召回率会如何变化？</h4><p>准确率 = <code>TP / (TP + FP)</code>，召回率 = <code>TP / (TP + FN)</code>，其中TP表示将正例正确分类为正例的数量，FP表示将负例错误分类为正例的数量，FN表示将正例错误分类为负例的数量。<br>准确率可以理解为在所有分类为正例的样品中，分类正确的样本所占比例；召回率可以理解为在所有原始数据集中的正例样品中，正确挑出的正例样本的比例。<br>因此若增大阈值t，更多不确定（分类概率较小）的样本将会被分为负例，剩余确定（分类概率较大）的样本所占比例将会增大（或不变），即正确率会增大（或不变）；若增大阈值t，则可能将部分不确定（分类概率较小）的正例样品误分类为负例，即召回率会减小（或不变）。</p><h4 id="6、以下关于神经网络的说法中，正确的是（-）？"><a href="#6、以下关于神经网络的说法中，正确的是（-）？" class="headerlink" title="6、以下关于神经网络的说法中，正确的是（ ）？"></a>6、以下关于神经网络的说法中，正确的是（ ）？</h4><p>A.增加网络层数，总能减小训练集错误率<br>B.减小网络层数，总能减小测试集错误率<br>C.增加网络层数，可能增加测试集错误率<br>答案：C。增加神经网络层数，确实可能提高模型的泛化性能，但不能绝对地说更深的网络能带来更小的错误率，还是要根据实际应用来判断，比如会导致过拟合等问题，因此只能选C。</p><h4 id="7、说明Lp范数间的区别。"><a href="#7、说明Lp范数间的区别。" class="headerlink" title="7、说明Lp范数间的区别。"></a>7、说明Lp范数间的区别。</h4><p><strong>L1范数</strong>：向量中各个元素绝对值之和<br><strong>L2范数</strong>：向量中各个元素平方和的开二次方根<br><strong>Lp范数</strong>：向量中各个元素绝对值的p次方和的开p次方根</p><h4 id="8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？"><a href="#8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？" class="headerlink" title="8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？"></a>8、用梯度下降训练神经网络的参数，为什么参数有时会被训练为nan值？</h4><p>输入数据本身存在nan值，或者梯度爆炸了（可以降低学习率、或者设置梯度的阈值）。</p><h4 id="9、卷积神经网络CNN中池化层有什么作用？"><a href="#9、卷积神经网络CNN中池化层有什么作用？" class="headerlink" title="9、卷积神经网络CNN中池化层有什么作用？"></a>9、卷积神经网络CNN中池化层有什么作用？</h4><p>减小图像尺寸即数据降维，缓解过拟合，保持一定程度的旋转和平移不变性。</p><h4 id="10、请列举几种常见的激活函数。激活函数有什么作用？"><a href="#10、请列举几种常见的激活函数。激活函数有什么作用？" class="headerlink" title="10、请列举几种常见的激活函数。激活函数有什么作用？"></a>10、请列举几种常见的激活函数。激活函数有什么作用？</h4><p>sigmoid， relu，tanh。非线性化</p><h4 id="11、神经网络中Dropout的作用？具体是怎么实现的？"><a href="#11、神经网络中Dropout的作用？具体是怎么实现的？" class="headerlink" title="11、神经网络中Dropout的作用？具体是怎么实现的？"></a>11、神经网络中Dropout的作用？具体是怎么实现的？</h4><p>防止过拟合。每次训练，都对每个神经网络单元，按一定概率临时丢弃。</p><h4 id="12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？"><a href="#12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？" class="headerlink" title="12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？"></a>12、利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？</h4><p>很有可能是梯度消失了，它表示神经网络迭代更新时，有些权值不更新的现象。改变激活函数，改变权值的初始化等。</p><h4 id="13、如何解决不平衡数据集的分类问题？"><a href="#13、如何解决不平衡数据集的分类问题？" class="headerlink" title="13、如何解决不平衡数据集的分类问题？"></a>13、如何解决不平衡数据集的分类问题？</h4><p>可以扩充数据集，对数据重新采样，改变评价指标等。</p><h4 id="14、残差网络为什么能做到很深层？"><a href="#14、残差网络为什么能做到很深层？" class="headerlink" title="14、残差网络为什么能做到很深层？"></a>14、残差网络为什么能做到很深层？</h4><p>神经网络在反向传播过程中要不断地传播梯度，而当网络层数加深时，梯度在逐层传播过程中会逐渐衰减，导致无法对前面网络层的权重进行有效的调整。残差网络中， 加入了 short connections 为梯度带来了一个直接向前面层的传播通道，缓解了梯度的减小问题。</p><h4 id="15、相比sigmoid激活函数ReLU激活函数有什么优势？"><a href="#15、相比sigmoid激活函数ReLU激活函数有什么优势？" class="headerlink" title="15、相比sigmoid激活函数ReLU激活函数有什么优势？"></a>15、相比sigmoid激活函数ReLU激活函数有什么优势？</h4><p>（1） 防止梯度消失 （sigmoid的导数只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近于0）<br>（2） ReLU的输出具有稀疏性<br>（3） ReLU函数简单计算速度快 </p><h4 id="16、卷积神经网络中空洞卷积的作用是什么？"><a href="#16、卷积神经网络中空洞卷积的作用是什么？" class="headerlink" title="16、卷积神经网络中空洞卷积的作用是什么？"></a>16、卷积神经网络中空洞卷积的作用是什么？</h4><p>空洞卷积也叫扩张卷积，在保持参数个数不变的情况下增大了卷积核的感受野，同时它可以保证输出的特征映射（feature map）的大小保持不变。一个扩张率为2的3×3卷积核，感受野与5×5的卷积核相同，但参数数量仅为9个。</p><h4 id="17、解释下卷积神经网络中感受野的概念？"><a href="#17、解释下卷积神经网络中感受野的概念？" class="headerlink" title="17、解释下卷积神经网络中感受野的概念？"></a>17、解释下卷积神经网络中感受野的概念？</h4><p>在卷积神经网络中，感受野 (receptive field)的定义是：卷积神经网络每一层输出的特征图（feature map）上的像素点在原始图像上映射的区域大小。</p><h4 id="18、模型欠拟合什么情况下会出现？有什么解决方案？"><a href="#18、模型欠拟合什么情况下会出现？有什么解决方案？" class="headerlink" title="18、模型欠拟合什么情况下会出现？有什么解决方案？"></a>18、模型欠拟合什么情况下会出现？有什么解决方案？</h4><p>模型复杂度过低，不能很好的拟合所有的数据。<br>增加模型复杂度，如采用高阶模型（预测）或者引入更多特征（分类）等。</p><h4 id="19、适用于移动端部署的网络结构都有哪些？"><a href="#19、适用于移动端部署的网络结构都有哪些？" class="headerlink" title="19、适用于移动端部署的网络结构都有哪些？"></a>19、适用于移动端部署的网络结构都有哪些？</h4><p><a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">Mobilenet</a><br><a href="https://arxiv.org/abs/1707.01083" target="_blank" rel="noopener">Shufflenet</a><br><a href="https://arxiv.org/abs/1610.02357" target="_blank" rel="noopener">Xception</a></p><h4 id="20、卷积神经网络中im2col是如何实现的？"><a href="#20、卷积神经网络中im2col是如何实现的？" class="headerlink" title="20、卷积神经网络中im2col是如何实现的？"></a>20、卷积神经网络中im2col是如何实现的？</h4><p>使用<code>im2col</code>的方法将划窗卷积转为两个大的矩阵相乘，见下图：<br><img src="/images/深度学习1.png" alt=""></p><h4 id="21、多任务学习中标签缺失如何处理？"><a href="#21、多任务学习中标签缺失如何处理？" class="headerlink" title="21、多任务学习中标签缺失如何处理？"></a>21、多任务学习中标签缺失如何处理？</h4><p>一般做法是将缺失的标签设置特殊标志，在计算梯度的时候忽略。</p><h4 id="22、梯度爆炸的解决方法？"><a href="#22、梯度爆炸的解决方法？" class="headerlink" title="22、梯度爆炸的解决方法？"></a>22、梯度爆炸的解决方法？</h4><p>针对梯度爆炸问题，解决方案是引入Gradient Clipping(梯度裁剪)。通过Gradient Clipping，将梯度约束在一个范围内，这样不会使得梯度过大。</p><h4 id="23、深度学习模型参数初始化都有哪些方法？"><a href="#23、深度学习模型参数初始化都有哪些方法？" class="headerlink" title="23、深度学习模型参数初始化都有哪些方法？"></a>23、深度学习模型参数初始化都有哪些方法？</h4><p>（1）Gaussian 满足mean=0，std=1的高斯分布x∼N(mean，std^2)<br>（2）Xavier 满足x∼U(−a,+a)的均匀分布，其中 a = sqrt(3/n)<br>（3）MSRA 满足x∼N(0,σ^2)的高斯分布，其中 σ = sqrt(2/n)<br>（4）Uniform 满足min=0,max=1的均匀分布。x∼U(min, max) 等等</p><h4 id="24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？"><a href="#24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？" class="headerlink" title="24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？"></a>24、注意力机制在深度学习中的作用是什么？有哪些场景会使用？</h4><p>深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标是从大量信息中有选择地筛选出少量重要信息并聚焦到这些重要信息上，忽略大多不重要的信息。<br>目前在神经机器翻译(Neural Machine Translation)、图像理解(Image caption)等场景都有广泛应用。</p><h4 id="25、卷积神经网络为什么会具有平移等不变性？"><a href="#25、卷积神经网络为什么会具有平移等不变性？" class="headerlink" title="25、卷积神经网络为什么会具有平移等不变性？"></a>25、卷积神经网络为什么会具有平移等不变性？</h4><p>MaxPooling能保证卷积神经网络在一定范围内平移特征能得到同样的激励，具有平移不变性。</p><h4 id="26、神经网络参数共享-parameter-sharing-是指什么？"><a href="#26、神经网络参数共享-parameter-sharing-是指什么？" class="headerlink" title="26、神经网络参数共享(parameter sharing)是指什么？"></a>26、神经网络参数共享(parameter sharing)是指什么？</h4><p>所谓的权值共享就是说，用一个卷积核去卷积一张图，这张图每个位置是被同样数值的卷积核操作的，权重是一样的，也就是参数共享。</p><h4 id="27、如何提高小型网络的精度？"><a href="#27、如何提高小型网络的精度？" class="headerlink" title="27、如何提高小型网络的精度？"></a>27、如何提高小型网络的精度？</h4><p>（1）<a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">模型蒸馏技术</a><br>（2）<a href="https://arxiv.org/abs/1807.11626" target="_blank" rel="noopener">利用AutoML进行网络结构的优化，可将网络计算复杂度作为约束条件之一，得到更优的结构。</a></p><h4 id="28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？"><a href="#28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？" class="headerlink" title="28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？"></a>28、什么是神经网络的梯度消失问题，为什么会有梯度消失问题？有什么办法能缓解梯度消失问题？</h4><p>在反向传播算法计算每一层的误差项的时候，需要乘以本层激活函数的导数值，如果导数值接近于0，则多次乘积之后误差项会趋向于0，而参数的梯度值通过误差项计算，这会导致参数的梯度值接近于0，无法用梯度下降法来有效的更新参数的值。<br>改进激活函数，选用更不容易饱和的函数，如ReLU函数。</p><h4 id="29、列举你所知道的神经网络中使用的损失函数。"><a href="#29、列举你所知道的神经网络中使用的损失函数。" class="headerlink" title="29、列举你所知道的神经网络中使用的损失函数。"></a>29、列举你所知道的神经网络中使用的损失函数。</h4><p>欧氏距离，交叉熵，对比损失，合页损失。</p><h4 id="30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？"><a href="#30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？" class="headerlink" title="30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？"></a>30、对于多分类问题，为什么神经网络一般使用交叉熵而不用欧氏距离损失？</h4><p>交叉熵在一般情况下更容易收敛到一个更好的解。</p><h4 id="31、1x1卷积有什么用途？"><a href="#31、1x1卷积有什么用途？" class="headerlink" title="31、1x1卷积有什么用途？"></a>31、1x1卷积有什么用途？</h4><p>通道降维，保证卷积神经网络可以接受任何尺寸的输入数据。</p><h4 id="32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？"><a href="#32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？" class="headerlink" title="32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？"></a>32、随机梯度下降法，在每次迭代时能保证目标函数值一定下降吗？为什么？</h4><p>不能，每次迭代时目标函数不一样。</p><h4 id="33、梯度下降法，为什么需要设置一个学习率？"><a href="#33、梯度下降法，为什么需要设置一个学习率？" class="headerlink" title="33、梯度下降法，为什么需要设置一个学习率？"></a>33、梯度下降法，为什么需要设置一个学习率？</h4><p>使得迭代之后的值在上次值的邻域内，保证可以忽略泰勒展开中的二次及二次以上的项。</p><h4 id="34、解释梯度下降法中动量项的作用。"><a href="#34、解释梯度下降法中动量项的作用。" class="headerlink" title="34、解释梯度下降法中动量项的作用。"></a>34、解释梯度下降法中动量项的作用。</h4><p>利用之前迭代时的梯度值，减小震荡。</p><h4 id="35、为什么现在倾向于用小尺寸的卷积核？"><a href="#35、为什么现在倾向于用小尺寸的卷积核？" class="headerlink" title="35、为什么现在倾向于用小尺寸的卷积核？"></a>35、为什么现在倾向于用小尺寸的卷积核？</h4><p>用多个小卷积核串联可以有大卷积核同样的能力，而且参数更少，另外有更多次的激活函数作用，增强非线性。</p><h4 id="36、解释GoogleNet的Inception模块的原理。"><a href="#36、解释GoogleNet的Inception模块的原理。" class="headerlink" title="36、解释GoogleNet的Inception模块的原理。"></a>36、解释GoogleNet的Inception模块的原理。</h4><p>对输入图像用多个不同尺寸的卷积核、池化操作进行同时处理，然后将输出结果按照通道拼接起来。</p><h4 id="37、解释反卷积的原理和用途。"><a href="#37、解释反卷积的原理和用途。" class="headerlink" title="37、解释反卷积的原理和用途。"></a>37、解释反卷积的原理和用途。</h4><p>反卷积即转置卷积，正向传播时乘以卷积核的转置矩阵，反向传播时乘以卷积核矩阵。<br>由卷积输出结果近似重构输入数据，上采样。</p><h4 id="38、解释批量归一化的原理。"><a href="#38、解释批量归一化的原理。" class="headerlink" title="38、解释批量归一化的原理。"></a>38、解释批量归一化的原理。</h4><p>在数据送入神经网络的某一层进行处理之前，对数据做归一化。按照训练样本的批量进行处理，先减掉这批样本的均值，然后除以标准差，然后进行缩放和平移。缩放和平移参数同训练得到。预测时使用训练时确定的这些值来计算。</p><h4 id="39、解释SVM核函数的原理。"><a href="#39、解释SVM核函数的原理。" class="headerlink" title="39、解释SVM核函数的原理。"></a>39、解释SVM核函数的原理。</h4><p>核函数将数据映射到更高维的空间后处理，但不用做这种显式映射，而是先对两个样本向量做内积，然后用核函数映射。这等价于先进行映射，然后再做内积。</p><h4 id="40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？"><a href="#40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？" class="headerlink" title="40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？"></a>40、什么是过拟合，过拟合产生的原因是什么？有什么方法能减轻过拟合？</h4><p>过拟合指在训练集上表现的很好，但在测试集上表现很差，推广泛化能力差。<br>原因：训练样本的抽样误差，训练时拟合了这种误差。<br>方法：增加训练样本，尤其是样本的代表性；正则化。</p><h4 id="41、什么样的函数可以用作激活函数？"><a href="#41、什么样的函数可以用作激活函数？" class="headerlink" title="41、什么样的函数可以用作激活函数？"></a>41、什么样的函数可以用作激活函数？</h4><p>非线性，几乎处处可到，单调。</p><h4 id="42、什么是鞍点问题？"><a href="#42、什么是鞍点问题？" class="headerlink" title="42、什么是鞍点问题？"></a>42、什么是鞍点问题？</h4><p>梯度为0，Hessian矩阵不定的点，不是极值点。</p><h4 id="43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？"><a href="#43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？" class="headerlink" title="43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？"></a>43、在训练深度神经网络的过程中，遇到过哪些问题，怎么解决的？</h4><p>不收敛，收敛太慢，泛化能力差。调整网络结构，调整样本，调整学习率，调整参数初始化策略。</p><h4 id="44、SVM如何解决多分类问题？"><a href="#44、SVM如何解决多分类问题？" class="headerlink" title="44、SVM如何解决多分类问题？"></a>44、SVM如何解决多分类问题？</h4><p>多个二分类器组合。1对1方案，1对剩余方案，多类损失函数。</p><h4 id="45、列举你知道的聚类算法。"><a href="#45、列举你知道的聚类算法。" class="headerlink" title="45、列举你知道的聚类算法。"></a>45、列举你知道的聚类算法。</h4><p>层次聚类，k均值算法，DBSCAN算法，OPTICS算法，谱聚类。</p><h4 id="46、K均值算法中，初始类中心怎么确定？"><a href="#46、K均值算法中，初始类中心怎么确定？" class="headerlink" title="46、K均值算法中，初始类中心怎么确定？"></a>46、K均值算法中，初始类中心怎么确定？</h4><p>随机选择K个样本作为类中心；将样本随机划分成K个子集然后计算类中心。</p><h4 id="47、简述EM算法的原理。"><a href="#47、简述EM算法的原理。" class="headerlink" title="47、简述EM算法的原理。"></a>47、简述EM算法的原理。</h4><p>EM算法用于求解带有隐变量的最大似然估计问题。由于有隐变量的存在，无法直接用最大似然估计求得对数似然函数极大值的公式解。此时通过jensen不等式构造对数似然函数的下界函数，然后优化下界函数，再用估计出的参数值构造新的下界函数，反复迭代直至收敛到局部极小值点。</p>]]></content>
      
      <categories>
          
          <category> 机器学习与深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令大全</title>
      <link href="/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"/>
      <url>/Linux/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li><p>查看当前目录下的文件数量（不包含子目录中的文件）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查看当前目录下的文件数量（包含子目录中的文件） 注意：R，代表子目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查看当前目录下的文件夹目录个数（不包含子目录中的目录），如果需要查看子目录，加上R</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l|grep <span class="string">"^d"</span>| wc -l</span><br></pre></td></tr></table></figure></li><li><p>查询当前路径下的指定前缀名的目录下的文件数量，如统计所有以”2018”开头的目录下的全部文件数量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR 2018\*/|grep <span class="string">"^-"</span>| wc -l</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法-任务调度问题</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-E-任务调度问题"><a href="#Problem-E-任务调度问题" class="headerlink" title="Problem E.任务调度问题"></a>Problem E.任务调度问题</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>一个单位时间任务是恰好需要一个单位时间完成的任务。给定一个单位时间任务的有限集 S 。关于S 的一个时间表用于描述S 中单位时间任务的执行次序。时间表中第 1 个任务从时间 0 开始执行直至时间 1 结束，第 2 个任务从时间 1 开始执行至时间 2 结束，…，第n个任务从时间 n-1 开始执行直至时间 n 结束。具有截止时间和误时惩罚的单位时间任务时间表问题可描述如下：<br>(1) n 个单位时间任务的集合 S = {1,2,…,n}（n ≤ 500）；<br>(2) 任务i的截止时间 d[i], 1 ≤ i ≤ n, 1 ≤ d[i] ≤ n，即要求任务 i 在时间 d[i] 之前结束；<br>(3) 任务 i 的误时惩罚 1 ≤ w[i] ≤ 1000, 1 ≤ i ≤ n, 即任务 i 未在时间 d[i] 之前结束将招致 w[i] 的惩罚；若按时完成则无惩罚。<br>任务时间表问题要求确定 S 的一个时间表（最优时间表）使得总误时惩罚达到最小。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行是正整数 n ，表示任务数。接下来的 2 行中，每行有 n 个正整数，分别表示各任务的截止时间和误时惩罚。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>将计算出的最小总误时惩罚输出。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">7</span><br><span class="line">4 2 4 3 1 4 6</span><br><span class="line">70 60 50 40 30 20 10</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">50</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题目类似于活动安排问题。首先将所有任务按照误时惩罚从大到小排序，然后依次从左到右遍历每个任务，将其安排在离截止时间点最近的（包括截止时间点处）未安排任务的时间点处完成，若无法找到这个时间点，则这个任务无法按时完成，将其误时惩罚加到总误时惩罚中。这样得到的总误时惩罚是最小的。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int n, d[510], w[510], visit[510];</span><br><span class="line">int i, j;</span><br><span class="line">long long result;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    memset(visit, 0, sizeof(visit));</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; d[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; w[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt; n; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (w[j] &lt; w[j + 1]) &#123;</span><br><span class="line">                swap(d[j], d[j + 1]);</span><br><span class="line">                swap(w[j], w[j + 1]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        bool flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (j = d[i]; j &gt; 0; j--) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!visit[j]) &#123;</span><br><span class="line">                visit[j] = 1;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="built_in">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!flag) &#123;</span><br><span class="line">            result += w[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; result &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法-合并果子</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-B-合并果子"><a href="#Problem-B-合并果子" class="headerlink" title="Problem B.合并果子"></a>Problem B.合并果子</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个果园里，多多已经将所有的果子打了下来，而且按果子的不同种类分成了不同的堆。多多决定把所有的果子合成一堆。<br>每一次合并，多多可以把两堆果子合并到一起，消耗的体力等于两堆果子的重量之和。可以看出，所有的果子经过n-1次合并之后，就只剩下一堆了。多多在合并果子时总共消耗的体力等于每次合并所耗体力之和。<br>因为还要花大力气把这些果子搬回家，所以多多在合并果子时要尽可能地节省体力。假定每个果子重量都为1，并且已知果子的种类数和每种果子的数目，你的任务是设计出合并的次序方案，使多多耗费的体力最少，并输出这个最小的体力耗费值。<br>例如有3种果子，数目依次为1，2，9。可以先将1、2堆合并，新堆数目为3，耗费体力为3。接着，将新堆与原先的第三堆合并，又得到新的堆，数目为12，耗费体力为12。所以多多总共耗费体力=3+12=15。可以证明15为最小的体力耗费值。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>输入包括两行，第一行是一个整数n(1 &lt;＝ n &lt; 10^4)，表示果子的种类数。第二行包含 n 个整数，用空格分隔，第 i 个整数ai(1 &lt;＝ ai &lt; 2 * 10^4)是第 i 种果子的数目。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>输出包括一行，这一行只包含一个整数，也就是最小的体力耗费值。输入数据保证这个值小于 2^31 。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3</span><br><span class="line">1 2 9</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题类似于哈夫曼编码树。首先用一个优先队列存储每种果子的数目，定义比较函数为从大到小排序。然后从队列中取出数目最少的两种果子，合并到一起，并将合并后的结果重新放入优先队列中，同时体力耗费增加相应的值。依此类推，直到将所有种类的果子合并成一堆。这样所得到的体力耗费值是最小的。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;queue&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">long long int n, a, temp, result;</span><br><span class="line">priority_queue&lt;long long int, vector&lt;long long int&gt;, greater&lt;long long int&gt;&gt; fruits;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        cin &gt;&gt; a;</span><br><span class="line">        fruits.push(a);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (fruits.size() &gt; 1) &#123;</span><br><span class="line">        temp = 0;</span><br><span class="line">        <span class="keyword">for</span> (i = 0; i &lt; 2; i++) &#123;</span><br><span class="line">            temp += fruits.top();</span><br><span class="line">            fruits.pop();</span><br><span class="line">        &#125;</span><br><span class="line">        fruits.push(temp);</span><br><span class="line">        result += temp;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; result &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>最大稳定极值区域MSER-Maximally Stable Extrernal Regions</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E6%9C%80%E5%A4%A7%E7%A8%B3%E5%AE%9A%E6%9E%81%E5%80%BC%E5%8C%BA%E5%9F%9FMSER-Maximally-Stable-Extrernal-Regions/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E6%9C%80%E5%A4%A7%E7%A8%B3%E5%AE%9A%E6%9E%81%E5%80%BC%E5%8C%BA%E5%9F%9FMSER-Maximally-Stable-Extrernal-Regions/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>MSER基于分水岭的概念：对图像进行二值化，二值化阈值取[0, 255]，这样二值化图像就经历一个从全黑到全白的过程（就像水位不断上升的俯瞰图）。在这个过程中，有些连通区域面积随阈值上升的变化很小，这种区域就叫MSER。<br><img src="/images/mser.png" alt=""><br>其中Qi表示第i个连通区域的面积，Δ表示微小的阈值变化（注水），当vi小于给定阈值时认为该区域为MSER。<br>显然，这样检测得到的MSER内部灰度值是小于边界的，想象一副黑色背景白色区域的图片，显然这个区域是检测不到的。因此对原图进行一次MSER检测后需要将其反转，再做一次MSER检测，两次操作又称MSER+和MSER-。</p><h2 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">im = cv2.imread(<span class="string">'./source.jpg'</span>)</span><br><span class="line">gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">mser = cv2.MSER_create(_min_area=300)</span><br><span class="line">regions, boxes = mser.detectRegions(gray)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">    x, y, w, h = box</span><br><span class="line">    cv2.rectangle(im, (x, y),(x + w, y + h), (255, 0, 0), 2)</span><br><span class="line"></span><br><span class="line">cv2.imwrite(<span class="string">"./mser.jpg"</span>, im)</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MSER </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法_最小差距</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%9C%80%E5%B0%8F%E5%B7%AE%E8%B7%9D/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%9C%80%E5%B0%8F%E5%B7%AE%E8%B7%9D/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-A-最小差距"><a href="#Problem-A-最小差距" class="headerlink" title="Problem A. 最小差距"></a>Problem A. 最小差距</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一些不同的一位数字，你可以从这些数字中选择若干个，并将它们按一定顺序排列，组成一个整数，把剩下的数字按一定顺序排列，组成另一个整数。组成的整数不能以0开头（除非这个整数只有1位）。<br>例如，给定6个数字，0,1,2,4,6,7，你可以用它们组成一对数10和2467，当然，还可以组成其他的很多对数，比如210和764，204和176。这些对数中两个数差的绝对值最小的是204和176，为28。<br>给定N个不同的0-9之间的数字，请你求出用这些数字组成的每对数中，差的绝对值最小的一对（或多对）数的绝对值是多少？</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行包括一个数 T （T ≤ 1000），为测试数据的组数。<br>每组数据包括两行，第一行为一个数 N （2 ≤ N ≤ 10），表示数字的个数。下面一行为 N 个不同的一位数字。</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>T 行，每行一个数，表示第 i 个数据的答案。即最小的差的绝对值。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2</span><br><span class="line">6</span><br><span class="line">0 1 2 4 6 7</span><br><span class="line">4</span><br><span class="line">1 6 3 4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">28</span><br><span class="line">5</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>首先将所有数字从小到大排序，接着这道题可以分三种情况考虑：<br>（1）只有两个数的情况：直接两数相减取绝对值即可。<br>（2）奇数个数的情况：首先保证第一个数字非0，如果为0，就将第一个数与第二个数交换位置，然后从左往右连续取<code>n/2+1</code>个数组成第一个整数，最后从右往左连续取<code>n/2</code>个数，即剩下的所有数组成另一个整数。这样所求得的一对整数的差的绝对值最小。<br>（3）偶数个数的情况：从左往右依次枚举，首先保证第一个数非0，如果为0，就从下一个数开始枚举；取第<code>k</code>个数作为第一个整数的第一个数字，取第<code>k+1</code>个数作为第二个整数的第一个数字；然后，对于剩下的数字，从右往左连续取<code>n/2-1</code>个数加入第一个整数中，从左往右连续取<code>n/2-1</code>个数加入第二个整数中；最后，取差的绝对值最小的一对整数。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int t, n, d[20], num1, num2;</span><br><span class="line">int i, j, k, l, r;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    scanf(<span class="string">"%d"</span>, &amp;t);</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; t; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;n);</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt;= n; j++) &#123;</span><br><span class="line">            scanf(<span class="string">"%d"</span>, &amp;d[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        sort(d + 1, d + n + 1);</span><br><span class="line">        <span class="keyword">if</span> (n == 2) &#123; // 两个数的情况</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, abs(d[2] - d[1]));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (n % 2 == 1) &#123; // 奇数个数的情况</span><br><span class="line">            <span class="keyword">if</span> (d[1] == 0) &#123;</span><br><span class="line">                swap(d[1], d[2]);</span><br><span class="line">            &#125;</span><br><span class="line">            num1 = 0, num2 = 0;</span><br><span class="line">            // 前n/2+1个数从左往右组成第一个整数</span><br><span class="line">            <span class="keyword">for</span> (j = 1; j &lt;= n / 2 + 1; j++) &#123;</span><br><span class="line">                num1 = num1 * 10 + d[j];</span><br><span class="line">            &#125;</span><br><span class="line">            // 后n/2个数从右往左组成第二个整数</span><br><span class="line">            <span class="keyword">for</span> (j = n; j &gt;= n / 2 + 2; j--) &#123;</span><br><span class="line">                num2 = num2 * 10 + d[j];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, abs(num1 - num2));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; // 偶数个数的情况</span><br><span class="line">            int result = 0x7fffffff;</span><br><span class="line">            // 枚举，取第k个数加入第一个整数中，取第k+1个数加入第二个整数中</span><br><span class="line">            <span class="keyword">for</span> (j = 1; j &lt; n; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (d[j] == 0) &#123;</span><br><span class="line">                    <span class="built_in">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                num1 = d[j], num2 = d[j + 1];</span><br><span class="line">                // 从右往左遍历n/2-1个数加入第一个整数中</span><br><span class="line">                // 从左往右遍历n/2-1个数加入第二个整数中</span><br><span class="line">                l = 1, r = n;</span><br><span class="line">                <span class="keyword">for</span> (k = 0; k &lt; n / 2 - 1; k++) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (l == j) l++;</span><br><span class="line">                    <span class="keyword">if</span> (l == j + 1) l++;</span><br><span class="line">                    <span class="keyword">if</span> (r == j + 1) r--;</span><br><span class="line">                    <span class="keyword">if</span> (r == j) r--;</span><br><span class="line">                    num1 = num1 * 10 + d[r];</span><br><span class="line">                    num2 = num2 * 10 + d[l];</span><br><span class="line">                    l++, r--;</span><br><span class="line">                &#125;</span><br><span class="line">                // 取差最小的值</span><br><span class="line">                result = min(result, abs(num1 - num2));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>贪心算法_旅行</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%97%85%E8%A1%8C/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95-%E6%97%85%E8%A1%8C/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-D-旅行"><a href="#Problem-D-旅行" class="headerlink" title="Problem D. 旅行"></a>Problem D. 旅行</h2><p>时间限制 1000 ms<br>内存限制 128 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>某趟列车的最大载客容量为V人，沿途共有n个停靠站，其中始发站为第1站，终点站为第n站。<br>在第1站至第n-1站之间，共有m个团队申请购票搭乘，若规定：<br>（1）对于某个团队的购票申请，要么全部满足，要么全部拒绝，即不允许只满足部分。（2）每个乘客的搭乘费用为其所乘站数。<br>问：应如何选择这些购票申请，能使该趟列车获得最大的搭乘费用？<br>其中，每个团队的购票申请格式是以空格分隔的三个整数：a b t，即表示有t个人需要从第a站点乘至第b站点（注：每个团队的所有人员都必须同时在a站上车，且必须同时在后面的b站下车）。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>输入数据有若干行。<br>第 1 行只有三个整数 n，m，v，分别表示站点数、申请数、列车的最大载客容量。这三个整数之间都以一个空格分隔。<br>第 2 行至第 m+1 行，每行有三个整数，中间都以一个空格分隔。其中第 k+1 行的三个整数 a，b，t 表示第 k 个申请，含义为：有 t 个人需要从第 a 站乘至第 b 站。<br>其中：1 ≤ n ≤ 10；1 ≤ m ≤ 18</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>输出数据只有一行，该行只有一个整数，为该列车能获得的最大搭乘费用。</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3  3  5</span><br><span class="line">1  2  2</span><br><span class="line">2  3  5</span><br><span class="line">1  3  4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>这道题与0-1背包问题类似。直接枚举所有可能的方案数，对于每一个团队，只有两个选择，搭乘与不搭乘，可以采用二进制0与1枚举的方式。由于团队申请数目<code>m</code>最多只有<code>18</code>个，所以最多有<code>2^18</code>种方案。对于每一种方案，统计每一站车上的总人数，如果某一站车上总人数超过了列车的最大载客容量<code>v</code>，那么此方案不可行；否则，比较搭乘费用，取最大的搭乘费用即可。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int n, m, v, a[20], b[20], t[20], num[25];</span><br><span class="line">long long cost = 0, temp;</span><br><span class="line">bool flag;</span><br><span class="line">int i, j;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m &gt;&gt; v;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; m; i++) &#123;</span><br><span class="line">        cin &gt;&gt; a[i] &gt;&gt; b[i] &gt;&gt; t[i];</span><br><span class="line">    &#125;</span><br><span class="line">    // 枚举二进制方案数</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; (1 &lt;&lt; m); i++) &#123;</span><br><span class="line">        // 变量的初始化</span><br><span class="line">        temp = 0;</span><br><span class="line">        flag = <span class="literal">true</span>;</span><br><span class="line">        memset(num, 0, sizeof(num));</span><br><span class="line">        // 判断决定每一个团队是否可以搭乘</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; m; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i &amp; (1 &lt;&lt; j)) &#123;</span><br><span class="line">                num[a[j]] += t[j];</span><br><span class="line">                num[b[j]] -= t[j];</span><br><span class="line">                temp += (b[j] - a[j]) * t[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 统计每一站车上的总人数，如果大于容量，就不满足条件</span><br><span class="line">        <span class="keyword">for</span> (j = 1; j &lt;= n; j++) &#123;</span><br><span class="line">            num[j] += num[j - 1];</span><br><span class="line">            <span class="keyword">if</span> (num[j] &gt; v) &#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 满足条件则取最大搭乘费用</span><br><span class="line">        <span class="keyword">if</span> (flag) &#123;</span><br><span class="line">            cost = max(cost, temp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cost &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贪心 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>非极大值抑制NMS(Non-Maximum Suppression)</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6NMS-Non-Maximum-Suppression/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6NMS-Non-Maximum-Suppression/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>NMS顾名思义就是抑制不是极大值的元素，可以理解为局部最大搜索。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。在目标检测中NMS主要用于提取分数最高的候选框。例如在用训练好的模型进行测试时，网络会预测出一系列的候选框，这时候可以用NMS来移除一些多余的候选框，即移除一些IOU值大于某个阈值的框。再比如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用NMS来选取那些邻域里分数最高（是行人的概率最大）的窗口，并且抑制那些分数低的窗口。<br>NMS在计算机视觉领域有着非常重要的应用，如视频目标跟踪、数据挖掘、3D重建、目标识别以及纹理分析等等。</p><h2 id="NMS在目标检测中的应用"><a href="#NMS在目标检测中的应用" class="headerlink" title="NMS在目标检测中的应用"></a>NMS在目标检测中的应用</h2><h4 id="去除重叠人脸检测框的例子"><a href="#去除重叠人脸检测框的例子" class="headerlink" title="去除重叠人脸检测框的例子"></a>去除重叠人脸检测框的例子</h4><p><img src="/images/NMS/1.png" alt=""><br>如上图所示，目的就是要去除冗余的检测框，找到最佳的候选框。</p><h4 id="目标检测pipline中的例子"><a href="#目标检测pipline中的例子" class="headerlink" title="目标检测pipline中的例子"></a>目标检测pipline中的例子</h4><p><img src="/images/NMS/2.png" alt=""><br>如上图所示，产生<strong>proposal</strong>后使用分类网络给出每个框的每类置信度，使用回归网络修正位置，最后使用NMS去除冗余的检测框。</p><h4 id="NMS算法原理"><a href="#NMS算法原理" class="headerlink" title="NMS算法原理"></a>NMS算法原理</h4><p>对于<strong>bounding boxes</strong>列表<strong>B</strong>及其相应的置信度<strong>S</strong>，使用下述计算方式：选择具有最大<strong>score</strong>的检测框<strong>M</strong>，将其从<strong>B</strong>集合中移除并加入到最后的检测结果<strong>R</strong>中。通常将<strong>B</strong>中剩余检测框与<strong>M</strong>的IOU大于阈值<strong>threshold</strong>的框从<strong>B</strong>中移除。重复这个过程，直到<strong>B</strong>为空。<br>其中用到的排序，可以按照检测框右下角的坐标或者面积排序，也可以通过SVM等分类器得到的得分或概率进行排序，R-CNN中就是按照得分进行的排序。<br><img src="/images/NMS/3.png" alt=""><br>比如上图，定位一个车辆的位置，算法找出了许多检测框，这时需要判断哪些矩形框是没用的。<br>非极大值抑制的方法是：先假设有6个矩形框，按照候选框的类别分类概率排序，假设属于车辆的概率排序结果为<strong>A &lt; B &lt; C &lt; D &lt; E &lt; F</strong>。</p><ol><li>先从最大概率矩形框<strong>F</strong>开始，分别判断<strong>A</strong>~<strong>E</strong>与<strong>F</strong>的IOU值是否大于某个设定的阈值；</li><li>假设<strong>B</strong>、<strong>D</strong>与<strong>F</strong>的重叠度超过设定的阈值，那么就移除<strong>B</strong>和<strong>D</strong>；并标记第一个矩形框<strong>F</strong>，是保留下来的。</li><li>从剩下的矩形框<strong>A</strong>、<strong>C</strong>、<strong>E</strong>中，选择概率最大的<strong>E</strong>，然后判断<strong>E</strong>与<strong>A</strong>、<strong>C</strong>的重叠度，如果重叠度大于设定的阈值，那么就扔掉；并标记<strong>E</strong>是保留下来的第二个矩形框。</li></ol><p>就这样一直重复，直到找到所有被保留下来的矩形框。</p><h4 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h4><p>在R-CNN中使用了NMS来确定最终的bbox，其对每个候选框送入分类器，根据分类器的类别分类概率做排序(论文中称为greedy-NMS)。但其实也可以在分类之前运用简单版本的NMS来去除一些框。<br>python实现的单类别nms：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def py_cpu_nms(dets, thresh):</span><br><span class="line"><span class="string">""</span><span class="string">" Pure Python NMS baseline. "</span><span class="string">""</span></span><br><span class="line"><span class="comment"># x1、y1、x2、y2、以及score赋值</span></span><br><span class="line">x1 = dets[:, 0]</span><br><span class="line">y1 = dets[:, 1]</span><br><span class="line">x2 = dets[:, 2]</span><br><span class="line">y2 = dets[:, 3]</span><br><span class="line">scores = dets[:, 4]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一个候选框的面积</span></span><br><span class="line">areas = (x2 - x1 + 1) * (y2 - y1 + 1)</span><br><span class="line"><span class="comment"># 按照score置信度降序排序</span></span><br><span class="line">order = scores.argsort()[::-1]</span><br><span class="line"></span><br><span class="line">keep = [] <span class="comment"># 保留的结果框集合</span></span><br><span class="line"><span class="keyword">while</span> order.size &gt; 0:</span><br><span class="line">i = order[0]</span><br><span class="line">keep.append(i) <span class="comment"># 保留该类剩余box中得分最高的一个</span></span><br><span class="line"><span class="comment"># 计算当前概率最大矩形框与其他矩形框的相交框的坐标</span></span><br><span class="line">xx1 = np.maximum(x1[i], x1[order[1:]])</span><br><span class="line">yy1 = np.maximum(y1[i], y1[order[1:]])</span><br><span class="line">xx2 = np.minimum(x2[i], x2[order[1:]])</span><br><span class="line">yy2 = np.minimum(y2[i], y2[order[1:]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算相交的面积，不重叠时面积为0</span></span><br><span class="line">w = np.maximum(0.0, xx2 - xx1 + 1)</span><br><span class="line">h = np.maximum(0.0, yy2 - yy1 + 1)</span><br><span class="line">inter = w * h</span><br><span class="line"><span class="comment">#计算IoU：重叠面积 /（面积1+面积2-重叠面积）</span></span><br><span class="line">over = inter / (areas[i] + areas[order[1:]] - inter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留IoU小于阈值的矩形框索引</span></span><br><span class="line">inds = np.where(over &lt;= thresh)[0]</span><br><span class="line"><span class="comment"># 将order序列更新，由于前面得到的矩形框索引要比矩形框在原order序列中的索引小1，所以要把这个1加回来</span></span><br><span class="line">order = order[inds + 1]</span><br><span class="line"></span><br><span class="line"><span class="built_in">return</span> keep <span class="comment"># 获取保留下来的索引</span></span><br></pre></td></tr></table></figure></p><p>Faster R-CNN的MATLAB实现与python版实现一致，代码在这里:<a href="https://github.com/ShaoqingRen/faster_rcnn/blob/master/functions/nms/nms.m" target="_blank" rel="noopener">nms.m</a>。另外，<a href="https://github.com/ShaoqingRen/faster_rcnn/blob/master/functions/nms/nms_multiclass.m" target="_blank" rel="noopener">nms_multiclass.m</a>是多类别nms，加了一层for循环对每类进行nms。</p><h4 id="NMS-loss"><a href="#NMS-loss" class="headerlink" title="NMS loss"></a>NMS loss</h4><p>对多类别检测任务，如果对每类分别进行NMS，那么当检测结果中包含两个被分到不同类别的目标且其IoU较大时，会得到不可接受的结果。如下图所示：<br><img src="/images/NMS/4.png" alt=""><br>一种改进方式是在损失函数中加入一部分NMS损失。NMS损失可以定义为与分类损失相同：<br><img src="/images/NMS/5.png" alt=""><br>即真实类别u对应的log损失，p是C个类别的预测概率，相当于增加分类误差。<br>参考论文《Rotated Region Based CNN for Ship Detection》（IEEE2017会议论文）的Multi-task for NMS部分。</p><h4 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h4><p>上述NMS算法的一个主要问题是当两个ground truth的目标的确重叠度很高时，NMS会将具有较低置信度的框去掉(置信度改成0)，如下图所示：<br><img src="/images/NMS/6.png" alt=""><br>论文:<a href="https://arxiv.org/pdf/1704.04503.pdf" target="_blank" rel="noopener">《Improving Object Detection With One Line of Code》</a>，改进之处：<br><img src="/images/NMS/7.png" alt=""><br>改进方法在于将置信度改为IoU的函数：f(IoU)，具有较低的值而不至于从排序列表中删去。<br>（1）线性函数<br><img src="/images/NMS/8.png" alt=""><br>函数值不连续，在某一点的值发生跳跃。<br>（2）高斯函数<br><img src="/images/NMS/9.png" alt=""><br>时间复杂度同传统的greedy-NMS，为O(N^2)。</p><h4 id="Soft-NMS-pythonPython源码实现"><a href="#Soft-NMS-pythonPython源码实现" class="headerlink" title="Soft-NMS pythonPython源码实现"></a>Soft-NMS pythonPython源码实现</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ua = <span class="built_in">float</span>((x2 - x1 + 1) * (y2 - y1 + 1) + area - w * h)</span><br><span class="line">ov = w * h / ua <span class="comment"># iou between max box and detection box</span></span><br><span class="line"><span class="keyword">if</span> method == 1: <span class="comment"># linear</span></span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">        weight = 1 - ov</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        weight = 1</span><br><span class="line"><span class="keyword">elif</span> method == 2: <span class="comment"># gaussian</span></span><br><span class="line">    weight = np.exp(-(ov * ov) / sigma)</span><br><span class="line"><span class="keyword">else</span>: <span class="comment"># original NMS</span></span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">        weight = 0</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        weight = 1</span><br><span class="line"><span class="comment"># re-scoring 修改置信度</span></span><br><span class="line">boxes[pos, 4] = weight * boxes[pos, 4]</span><br></pre></td></tr></table></figure><p>在基于proposal方法的模型结果上应用比较好，检测效果提升：<br><img src="/images/NMS/10.png" alt=""><br>在R-FCN以及Faster-RCNN模型中的测试阶段运用Soft-NMS，在MS-COCO数据集上<em>mAP@[0.5:0.95]</em>能够获得大约1%的提升<a href="https://github.com/bharatsingh430/soft-nms" target="_blank" rel="noopener">详见这里</a>。 如果应用到训练阶段的proposal选取过程理论上也能获得提升。对易重叠的目标类型确实有提高(目标不一定真的有像素上的重叠，切斜的目标的矩形边框会有较大的重叠)。而在SSD，YOLO等非proposal方法中没有提升。</p><h2 id="其它应用"><a href="#其它应用" class="headerlink" title="其它应用"></a>其它应用</h2><ul><li>边缘检测：<br>** Canny算子中的非极大值抑制是沿着梯度方向进行的，即是否为梯度方向上的极值点；<a href="http://blog.csdn.net/kezunhai/article/details/11620357" target="_blank" rel="noopener">参考这里</a></li><li>特征点检测：<br>** 在角点检测等场景下说的非极大值抑制，则是检测中心点处的值是否是某一个邻域内的最大值。</li></ul>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NMS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>交并比IOU(Intersection over Union)</title>
      <link href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E4%BA%A4%E5%B9%B6%E6%AF%94IOU-Intersection-over-Union/"/>
      <url>/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/%E4%BA%A4%E5%B9%B6%E6%AF%94IOU-Intersection-over-Union/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>IOU是在目标检测中使用的一个概念，是产生的预测框(<strong>Predicted bounding box</strong>)与标注框(<strong>Ground-truth bounding box</strong>)的重叠率；简单来说，即两个矩形框面积的交集和并集的比值；它是一个在特定数据集中检测相应物体准确度的测量标准。通常会在<strong>HOG + Linear SVM object detectors</strong>和<strong>Convolutional Neural Network detectors (R-CNN, Faster R-CNN, YOLO 等)</strong>中使用该方法检测其性能。<br>IOU是一个简单的测量标准，在输出中得出一个预测范围(<strong>bounding box</strong>)的任务都可以用IOU来测量。其用于测量真实和预测之间的相关度，相关度越高，该值越高。<br><img src="/images/IOU1.jpg" alt=""><br>上图展示了<strong>ground-truth</strong>和<strong>predicted</strong>的结果，绿色标线是人为标记的正确结果，红色标线是算法预测出来的结果，IOU要做的就是在这两个结果中测量算法的准确度。<br><img src="/images/IOU2.png" alt=""><br><img src="/images/IOU3.png" alt=""><br>一般来说，这个比值 ＞ 0.5 就可以认为是一个不错的结果了。<br><img src="/images/IOU4.png" alt=""></p><h2 id="Python源码实现"><a href="#Python源码实现" class="headerlink" title="Python源码实现"></a>Python源码实现</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def compute_iou(box1, box2, wh=False):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    compute the iou of two boxes.</span></span><br><span class="line"><span class="string">    args:</span></span><br><span class="line"><span class="string">        box1, box2: [xmin, ymin, xmax, ymax] (wh=False) or [xcenter, ycenter, w, h] (wh=True)</span></span><br><span class="line"><span class="string">        wh: the format of coordinate.</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        iou: iou of box1 and box2.</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    <span class="keyword">if</span> wh == False:</span><br><span class="line">        xmin1, ymin1, xmax1, ymax1 = box1</span><br><span class="line">        xmin2, ymin2, xmax2, ymax2 = box2</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        xmin1, ymin1 = int(box1[0] - box1[2] / 2.0), int(box1[1] - box1[3] / 2.0)</span><br><span class="line">        xmax1, ymax1 = int(box1[0] + box1[2] / 2.0), int(box1[1] + box1[3] / 2.0)</span><br><span class="line">        xmin2, ymin2 = int(box2[0] - box2[2] / 2.0), int(box2[1] - box2[3] / 2.0)</span><br><span class="line">        xmax2, ymax2 = int(box2[0] + box2[2] / 2.0), int(box2[1] + box2[3] / 2.0)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算两个矩形框面积</span></span><br><span class="line">    area1 = (xmax1 - xmin1) * (ymax1 - ymin1)</span><br><span class="line">    area2 = (xmax2 - xmin2) * (ymax2 - ymin2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 获取矩形框交集对应的左上角和右下角的坐标（intersection）</span></span><br><span class="line">    inter_x1 = np.max([xmin1, xmin2])</span><br><span class="line">    inter_y1 = np.max([ymin1, ymin2])</span><br><span class="line">    inter_x2 = np.min([xmax1, xmax2])</span><br><span class="line">    inter_y2 = np.min([ymax1, ymax2])</span><br><span class="line"></span><br><span class="line">    inter_area = (np.max([0, inter_x2 - inter_x1])) * (np.max([0, inter_y2 - inter_y1]))　<span class="comment"># 计算交集面积</span></span><br><span class="line">    iou = inter_area / (area1 + area2 - inter_area + 1e-6)　＃ 计算交并比</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> iou</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 目标检测与定位 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IOU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Git基本常用命令</title>
      <link href="/%E5%B7%A5%E5%85%B7/Git%E5%9F%BA%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/%E5%B7%A5%E5%85%B7/Git%E5%9F%BA%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul><li><strong>git init</strong> 把当前的目录变成可以管理的git仓库，生成隐藏.git文件。</li><li><strong>git add XX</strong> 把xx文件添加到暂存区去。</li><li><strong>git commit -m ‘XX’</strong> 提交文件， –m 后面的是注释。</li><li><strong>git status</strong> 查看本地仓库状态。</li><li><strong>git diff XX</strong> 查看XX文件修改了那些内容。</li><li><strong>git log</strong> 查看历史记录。</li><li><strong>git reset -hard HEAD^</strong> 或者 <strong>git reset –hard HEAD~</strong> 回退到上一个版本(如果想回退到100个版本，使用<strong>git reset –hard HEAD~100</strong> )。</li><li><strong>cat XX</strong> 查看XX文件内容。</li><li><strong>git reflog</strong> 查看历史记录的版本号id。</li><li><strong>git checkout – XX</strong> 把XX文件在工作区的修改全部撤销。</li><li><strong>git rm XX</strong> 删除XX文件。</li><li><strong>git remote add origin <a href="https://github.com/zhaopeng0103/test.git" target="_blank" rel="noopener">https://github.com/zhaopeng0103/test.git</a></strong> 关联一个远程库。</li><li><strong>git push –u(第一次要用-u 以后不需要) origin master</strong> 把当前master分支推送到远程库。</li><li><strong>git clone <a href="https://github.com/zhaopeng0103/test.git" target="_blank" rel="noopener">https://github.com/zhaopeng0103/test.git</a></strong> 从远程库中克隆。</li><li><strong>git checkout –b dev</strong> 创建dev分支，并切换到dev分支上。</li><li><strong>git branch</strong> 查看当前所有的分支。</li><li><strong>git checkout master</strong> 切换回master分支。</li><li><strong>git merge dev</strong> 在当前的分支上合并dev分支。</li><li><strong>git branch –d dev</strong> 删除dev分支。</li><li><strong>git branch name</strong> 创建分支。</li><li><strong>git stash</strong> 把当前的工作隐藏起来 等以后恢复现场后继续工作。</li><li><strong>git stash list</strong> 查看所有被隐藏的文件列表。</li><li><strong>git stash apply</strong> 恢复被隐藏的文件，但是内容不删除。</li><li><strong>git stash drop</strong> 删除文件。</li><li><strong>git stash pop</strong> 恢复文件的同时 也删除文件。</li><li><strong>git remote</strong> 查看远程库的信息。</li><li><strong>git remote –v</strong> 查看远程库的详细信息。</li><li><strong>git push origin master</strong> Git会把master分支推送到远程库对应的远程分支上。</li></ul>]]></content>
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git使用 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>好听的歌曲</title>
      <link href="/music/%E5%A5%BD%E5%90%AC%E7%9A%84%E6%AD%8C%E6%9B%B2/"/>
      <url>/music/%E5%A5%BD%E5%90%AC%E7%9A%84%E6%AD%8C%E6%9B%B2/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>        <div id="aplayer-BZjPaMYv" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;"></div>  <script>  var options = {"narrow":false,"autoplay":false,"showlrc":3,"mode":"random","music":[{"title":"小白兔遇上卡布奇诺","author":"兔子牙","url":"/music/小白兔遇上卡布奇诺.mp3","pic":"/images/小白兔1.jpg","lrc":"/documents/小白兔.txt"}]};  options.element = document.getElementById("aplayer-BZjPaMYv");  var ap = new APlayer(options);    window.aplayers || (window.aplayers = []);  window.aplayers.push(ap);  </script><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","video":{"url":"/videos/小白兔.mp4","pic":"/images/小白兔.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>]]></content>
      
      <categories>
          
          <category> music </category>
          
      </categories>
      
      
        <tags>
            
            <tag> music </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:五子棋</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E4%BA%94%E5%AD%90%E6%A3%8B/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E4%BA%94%E5%AD%90%E6%A3%8B/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-E-五子棋"><a href="#Problem-E-五子棋" class="headerlink" title="Problem E. 五子棋"></a>Problem E. 五子棋</h2><p>时间限制 1000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>在一个nxn的棋盘上，有一些黑色的棋子和白色的棋子，如果能找出任意五个同色的棋子连成直线（横着、竖着、斜着都可以），那么该颜色方加1分。求黑色方得分和白色方得分。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行为一个正整数n，代表棋盘的大小。 接下来为一个nxn的矩阵，’#’代表没有棋子，’B’代表黑色棋子，’W’代表白色棋子 n&lt;=20</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>两个正整数，分别代表黑色方得分和白色方得分</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">WBBBBB</span><br><span class="line">WBB<span class="comment">###</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br><span class="line">W<span class="comment">###B#</span></span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 2</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>直接遍历每一个棋子，如果在下图中的任一个方向连成5个，则对应方加1分。<br><img src="/images/wuziqi.png" alt=""></p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = 40;</span><br><span class="line">int n;</span><br><span class="line">int a[maxN][maxN], b_score, w_score;</span><br><span class="line">string s;</span><br><span class="line">int i, j;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    memset(a, 0, sizeof(a));</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 3; i &lt; n + 3; i++) &#123;</span><br><span class="line">        cin &gt;&gt; s;</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; s.length(); j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s[j] == <span class="string">'B'</span>) &#123;</span><br><span class="line">                a[i][j + 3] = 1;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (s[j] == <span class="string">'W'</span>) &#123;</span><br><span class="line">                a[i][j + 3] = 2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = 3; i &lt; n + 3; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 3; j &lt; n + 3; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (a[i][j] == 1) &#123;</span><br><span class="line">                <span class="keyword">if</span> (a[i][j - 1] == a[i][j] &amp;&amp; a[i][j - 2] == a[i][j] &amp;&amp; a[i][j + 1] == a[i][j] &amp;&amp; a[i][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i - 1][j] == a[i][j] &amp;&amp; a[i - 2][j] == a[i][j] &amp;&amp; a[i + 1][j] == a[i][j] &amp;&amp; a[i + 2][j] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j + 1] == a[i][j] &amp;&amp; a[i + 2][j + 2] == a[i][j] &amp;&amp; a[i - 1][j - 1] == a[i][j] &amp;&amp; a[i - 2][j - 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j - 1] == a[i][j] &amp;&amp; a[i + 2][j - 2] == a[i][j] &amp;&amp; a[i - 1][j + 1] == a[i][j] &amp;&amp; a[i - 2][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    b_score++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (a[i][j] == 2) &#123;</span><br><span class="line">                <span class="keyword">if</span> (a[i][j - 1] == a[i][j] &amp;&amp; a[i][j - 2] == a[i][j] &amp;&amp; a[i][j + 1] == a[i][j] &amp;&amp; a[i][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i - 1][j] == a[i][j] &amp;&amp; a[i - 2][j] == a[i][j] &amp;&amp; a[i + 1][j] == a[i][j] &amp;&amp; a[i + 2][j] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j + 1] == a[i][j] &amp;&amp; a[i + 2][j + 2] == a[i][j] &amp;&amp; a[i - 1][j - 1] == a[i][j] &amp;&amp; a[i - 2][j - 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (a[i + 1][j - 1] == a[i][j] &amp;&amp; a[i + 2][j - 2] == a[i][j] &amp;&amp; a[i - 1][j + 1] == a[i][j] &amp;&amp; a[i - 2][j + 2] == a[i][j]) &#123;</span><br><span class="line">                    w_score++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; b_score &lt;&lt; <span class="string">" "</span> &lt;&lt; w_score &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:讨厌的数字</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E8%AE%A8%E5%8E%8C%E7%9A%84%E6%95%B0%E5%AD%97/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E8%AE%A8%E5%8E%8C%E7%9A%84%E6%95%B0%E5%AD%97/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-D-讨厌的数字"><a href="#Problem-D-讨厌的数字" class="headerlink" title="Problem D. 讨厌的数字"></a>Problem D. 讨厌的数字</h2><p>时间限制 1000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>奶牛的生日快到了，你准备送给他一个数x作为生日礼物，x是十进制下的一个n位数，但是奶牛向你提出了一些要求。 1 奶牛准备了一个数字d，他希望x是d的倍数 2 奶牛不喜欢0和3，他不希望x中有0或3 请问有多少个不同的n位数可以作为奶牛的生日礼物呢？ 答案mod1000000007输出。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>两个数字n和d，代表数字位数和奶牛给出的数字d<br>0 &lt;= n &lt;= 1000<br>0 &lt;= d &lt;= 1000</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>一个1000000007之内的整数代表答案</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 3</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">22</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p><code>dp[i][j]</code>表示<code>i</code>位数中模<code>d</code>等于<code>j</code>的方案数。首先计算只有一位数时，满足条件的方案数作为初始值。然后依次遍历<code>i</code>位数下对<code>d</code>求余为<code>j</code>的方案个数；每增加一位数，就在其最后加<code>k</code>，因为要求数字中不能出现<code>0</code>和<code>3</code>，那么遍历时直接去除这两个数字就可以了。最后<code>n</code>位数下是<code>d</code>的倍数的方案个数就是<code>dp[n][0]</code>。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = 1010;</span><br><span class="line">int n, d, dp[maxN][maxN];</span><br><span class="line">int i, j, k;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; d;</span><br><span class="line">    // 计算一位数的方案数</span><br><span class="line">    <span class="keyword">for</span> (k = 1; k &lt;= 9; k++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (k == 3) &#123;</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dp[1][k % d]++;</span><br><span class="line">    &#125;</span><br><span class="line">    // dp[i][j]表示i位数中模d等于j的方案数</span><br><span class="line">    <span class="keyword">for</span> (i = 2; i &lt;= n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = 0; j &lt; d; j++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (k = 1; k &lt;= 9; k++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (k == 3) &#123;</span><br><span class="line">                    <span class="built_in">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                dp[i][(j * 10 + k) % d] += dp[i - 1][j];</span><br><span class="line">                dp[i][(j * 10 + k) % d] %= 1000000007;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; dp[n][0] &lt;&lt; endl;// 输出n位数中能被d整除的满足条件的方案数</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 程序设计竞赛 </tag>
            
            <tag> 动态规划dp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:约瑟夫环plus</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AFplus/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AFplus/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-C-约瑟夫环plus"><a href="#Problem-C-约瑟夫环plus" class="headerlink" title="Problem C. 约瑟夫环plus"></a>Problem C. 约瑟夫环plus</h2><p>时间限制 2000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>考虑经典的约瑟夫环模型：n个人按顺序围成一圈，从第一个人开始报数，从1开始报，报到k这个数的人会被移出去，然后下一个人从1开始重新报数，第n个人报完数之后第1个人接着报数，问整个过程中第1个人报了几次数。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>两个正整数n，k<br>1 &lt;= n &lt;= 1000000000000000000<br>1 &lt;= k &lt;= 200</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>第1个人被移除之前一共报了几次数</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4 4</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="样例说明"><a href="#样例说明" class="headerlink" title="样例说明"></a>样例说明</h3><p>注意n需要用long long存</p><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p><code>cur_number</code>存储第一个人每次轮到他时所报的号，最开始时，第一个人报号的次数<code>res</code>为<code>1</code>，<code>cur_number</code>也为<code>1</code>；从上一次这个人报号到下一次轮到他报号为止为一个周期，在这个周期内有<code>(n + cur_number) / k</code>个人被移出去，这个人报的号更新为<code>(n + cur_number) % k</code>；所以当<code>(n + cur_number) % k = 0</code>时，第一个人会被移出去，也就是下一次轮到他时<code>cur_number = 0</code>。</p><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">long long n, k, cur_number, res, temp;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; k;</span><br><span class="line">    res = 1;</span><br><span class="line">    cur_number = 1;</span><br><span class="line">    <span class="keyword">while</span> (cur_number != 0) &#123;</span><br><span class="line">        temp = n + cur_number;</span><br><span class="line">        n -= temp / k;</span><br><span class="line">        cur_number = temp % k;</span><br><span class="line">        res++;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序设计竞赛:魔法师排队</title>
      <link href="/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E9%AD%94%E6%B3%95%E5%B8%88%E6%8E%92%E9%98%9F/"/>
      <url>/%E7%AE%97%E6%B3%95%E9%A2%98/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AB%9E%E8%B5%9B-%E9%AD%94%E6%B3%95%E5%B8%88%E6%8E%92%E9%98%9F/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Problem-B-魔法师排队"><a href="#Problem-B-魔法师排队" class="headerlink" title="Problem B. 魔法师排队"></a>Problem B. 魔法师排队</h2><p>时间限制 2000 ms<br>内存限制 64 MB</p><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>有n个魔法师在排队买魔法面包，每个魔法师都有自己的魔力值，用一个正整数表示。 魔法师都不喜欢排队，如果任意时刻某个魔法师发现前面的魔法师的魔力值比自己小，那么这个魔法师就会用法术把前面的人传送到异空间。 请输出有多少个魔法师会被传送到异空间。</p><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>第一行为一个正整数n，代表魔法师的人数。 接下来一行位n个正整数，第i个正整数ai代表队伍中第i个魔法师的魔力值。（第1个魔法师在队头，第n个魔法师在队尾）<br>1 &lt;= n &lt;= 1000000<br>1 &lt;= ai &lt;= 100000000</p><h3 id="输出数据"><a href="#输出数据" class="headerlink" title="输出数据"></a>输出数据</h3><p>被传送到异空间的魔法师个数</p><h3 id="样例输入"><a href="#样例输入" class="headerlink" title="样例输入"></a>样例输入</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5</span><br><span class="line">4 5 1 3 2</span><br></pre></td></tr></table></figure><h3 id="样例输出"><a href="#样例输出" class="headerlink" title="样例输出"></a>样例输出</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2</span><br></pre></td></tr></table></figure><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><p>一开始的想法是：找从第一个魔法师到最后一个魔法师中的拥有最大魔力值的魔法师<code>max_index</code>，那么位于它之前的魔法师都将会被传送走，此具有最大魔力值的魔法师会留下来；接着寻找从<code>max_index + 1</code>到最后一个魔法师之间的拥有最大魔力值的魔法师，进行同样的操作，依次循环下去，直到剩下最后一个魔法师为止（最后一个魔法师肯定会留下来）；然而结果却超时了。于是换了种思维方式，既然是位于魔法师前面且比其魔力值小的魔法师会被传送走，那么最后一个魔法师肯定会留下来；直接定义一个存储最大魔力值的变量<code>max_num</code>，初始化为最后一个魔法师的魔力值，从后向前倒序遍历，如果当前魔法师的魔力值比<code>max_num</code>小，那么就把他传送走；否则，更新最大魔力值。</p><h3 id="TLE代码"><a href="#TLE代码" class="headerlink" title="TLE代码"></a>TLE代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = int(1e6 + 10);</span><br><span class="line">int n, a[maxN], l, r, max_index, cont;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 0; i &lt; n; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    l = 0; r = n;</span><br><span class="line">    <span class="keyword">while</span>(l &lt; r) &#123;</span><br><span class="line">        vector&lt;int&gt; v(a + l, a + r);</span><br><span class="line">        auto max_value = max_element(v.begin(), v.end());</span><br><span class="line">        max_index = distance(begin(v), max_value);</span><br><span class="line">        cont += max_index;</span><br><span class="line">        l = l + max_index + 1;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cont &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="AC代码"><a href="#AC代码" class="headerlink" title="AC代码"></a>AC代码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="comment">#include &lt;algorithm&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstdio&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cstring&gt;</span></span><br><span class="line"><span class="comment">#include &lt;cmath&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int maxN = int(1e6 + 10);</span><br><span class="line">int n, a[maxN], max_num, cont;</span><br><span class="line">int i;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">for</span> (i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">        scanf(<span class="string">"%d"</span>, &amp;a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    max_num = a[n];</span><br><span class="line">    <span class="keyword">for</span> (i = n - 1; i &gt; 0; i--) &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &lt; max_num) &#123;</span><br><span class="line">            cont++;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            max_num = a[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; cont &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> 算法题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模拟 </tag>
            
            <tag> 程序设计竞赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/default/hello-world/"/>
      <url>/default/hello-world/</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h2><h3 id="创建一篇新文章"><a href="#创建一篇新文章" class="headerlink" title="创建一篇新文章"></a>创建一篇新文章</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>更多信息请查看： </p><ul><li><a href="https://hexo.io/zh-cn/docs/writing.html" target="_blank" rel="noopener">Writing</a> </li><li><a href="https://hexo.io/zh-cn/docs/tag-plugins" target="_blank" rel="noopener">标签插件（Tag Plugins）</a></li><li><a href="https://blog.csdn.net/zhuzhuyule/article/details/58347687" target="_blank" rel="noopener">Markdown语法(GFM)写博客</a></li><li><a href="http://www.cnblogs.com/youngwilliam/articles/youngwilliam.html" target="_blank" rel="noopener">HexoEditor, 一个写 Hexo 非常好用的 Markdown 编辑器</a></li><li><a href="https://github.com/zhuzhuyule/HexoEditor" target="_blank" rel="noopener">HexoEditor</a></li></ul><h3 id="运行服务"><a href="#运行服务" class="headerlink" title="运行服务"></a>运行服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="生成静态文件"><a href="#生成静态文件" class="headerlink" title="生成静态文件"></a>生成静态文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="发布到远程站点"><a href="#发布到远程站点" class="headerlink" title="发布到远程站点"></a>发布到远程站点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>更多信息请查看： <a href="https://hexo.io/zh-cn/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g</span><br><span class="line">$ gulp</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure><p>or</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h3 id="关于图片素材"><a href="#关于图片素材" class="headerlink" title="关于图片素材"></a>关于图片素材</h3><p>图片素材按官方教程说法，可统一放置在source/images目录中，并以<code>![](/images/image.jpg)</code> 方式引用。或者在<code>_config.yml</code>打开 post_asset_folder 功能，将当前文章所用的图片放置到source目录下的文章同名资源目录下，以<code>![](image.jpg)</code>方式引用</p><h3 id="使用-Hexo-Admin-插件"><a href="#使用-Hexo-Admin-插件" class="headerlink" title="使用 Hexo Admin 插件"></a>使用 Hexo Admin 插件</h3><p>Hexo Admin是一个本地在线式文章管理器，可以用直观可视化的方式新建、编辑博客文章、page页面，添加标签、分类等，并且支持剪贴板粘贴图片（自动在source_images_目录中创建文件）。<br><img src="/images/hexoadmin.png" alt=""></p><ul><li><p>在Hexo网站目录下，安装 Hexo Admin 插件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --save hexo-admin</span><br></pre></td></tr></table></figure></li><li><p>启动本地服务器并打开管理界面，即可使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server -d</span><br><span class="line">$ open http://localhost:4000/admin/</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用HexoEditor-Markdown-编辑器"><a href="#使用HexoEditor-Markdown-编辑器" class="headerlink" title="使用HexoEditor Markdown 编辑器"></a>使用HexoEditor Markdown 编辑器</h3><blockquote><p>设置 npm 缓存路径</p><blockquote><p>Windows 下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">"C:/Program Files/nodejs/npm_global"</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">"C:/Program Files/nodejs/npm_cache"</span></span><br></pre></td></tr></table></figure></p></blockquote></blockquote><blockquote><blockquote><p>Linux\Mac 下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">"~/nodejs/npm_global"</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">"~/nodejs/npm_cache"</span></span><br></pre></td></tr></table></figure></p></blockquote></blockquote><blockquote><blockquote><p>注意：这里的路径是你安装 nodejs 的子目录下对应的路径</p></blockquote></blockquote><blockquote><p>设置下载来源（镜像），加速下载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry <span class="string">"https://registry.npm.taobao.org/"</span></span><br><span class="line">npm config <span class="built_in">set</span> electron_mirror <span class="string">"https://npm.taobao.org/mirrors/electron/"</span></span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>下载 GitHub 上最新的版本并安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/zhuzhuyule/HexoEditor.git</span><br><span class="line"><span class="built_in">cd</span> HexoEditor</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm start</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="使用github-pages服务搭建博客的好处"><a href="#使用github-pages服务搭建博客的好处" class="headerlink" title="使用github pages服务搭建博客的好处"></a>使用github pages服务搭建博客的好处</h3><ol><li>全是静态文件，访问速度快；</li><li>免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；</li><li>可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；</li><li>数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；</li><li>博客内容可以轻松打包、转移、发布到其它平台。</li></ol>]]></content>
      
      <categories>
          
          <category> default </category>
          
      </categories>
      
      
        <tags>
            
            <tag> default </tag>
            
        </tags>
      
    </entry>
    
  
  
    
    <entry>
      <title>关于我</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h2><ul><li>我叫赵鹏</li><li>男</li><li>石家庄人</li><li>现居北京</li><li>学生</li></ul><h2 id="联系我"><a href="#联系我" class="headerlink" title="联系我"></a>联系我</h2><ul><li>Email：<a href="mailto:424107420@qq.com" target="_blank" rel="noopener">424107420@qq.com</a></li><li>GitHub：zhaopeng0103</li><li>WeChat：zp18713598785</li><li>QQ：424107420</li></ul>]]></content>
    </entry>
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
    </entry>
    
    <entry>
      <title>标签云</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
    </entry>
    
  
</search>
